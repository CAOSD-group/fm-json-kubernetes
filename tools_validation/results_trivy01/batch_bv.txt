
Report Summary

┌────────────────────────────────────────────────────────┬────────────┬───────────────────┐
│                         Target                         │    Type    │ Misconfigurations │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterAutoScaler.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterAutoScaler_1.yaml                               │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterAutoScaler_2.yaml                               │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterAutoScaler_3.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterAutoScaler_4.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterAutoScaler_5.yaml                               │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP(without selector).yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-Headless_1.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-Headless_2.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-images-api.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-quotes-api.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-quotesDB.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-svc.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP-svc_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP1.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP18.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP21.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP24.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP4.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP41.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIPService.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_1.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_11.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_2.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_21.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_3.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_4.yaml                                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_5.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_6.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIP_7.yaml                                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIp26.yaml                                       │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIp26_1.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIpMysql.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterIpMysql_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess.yaml                        │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess1.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess2.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess3.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess4.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess5.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess6.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess7.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-ReadOnlyAccess8.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-argocd-application-controller.yaml         │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-argocd-notifications-controller.yaml       │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-argocd-server.yaml                         │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-cilium-operator.yaml                       │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-cilium.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-hubble-ui.yaml                             │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-k8s-gateway.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-nfs-external-provisioner-role.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-onepassword-connect-operator.yaml          │ kubernetes │         6         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-tailscale-operator.yaml                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole-traefik-traefik.yaml                       │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole.pod-reader.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole173.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole343.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole344.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole345.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole346.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole347.yaml                                    │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole348.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole349.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole350.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole351.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole425.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole440.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole517.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole555.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ClusterRole593.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role203.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role204.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role205.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role206.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role207.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role208.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role209.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role21.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role210.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role211.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role212.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role213.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role214.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role215.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role216.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role217.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role218.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role218_1.yaml                                 │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role218_2.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role219.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role22.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role220.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role221.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role222.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role223.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role224.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role225.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role226.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role227.yaml                                   │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role228.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role229.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role230.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role231.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role232.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role233.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role234.yaml                                   │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role235.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role237.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role24.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role241.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role243.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role244.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role245.yaml                                   │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role246.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role247.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role248.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role25.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role250.yaml                                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role251.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role25_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role26.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role26_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role27.yaml                                    │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role27_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role28.yaml                                    │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role28_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role29.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role3.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role30.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role31.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role32.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role33.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role34.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role35.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role36.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role37.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role39.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role4.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role40.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role41.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role42.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role43.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role44.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role45.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role46.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role47.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role48.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role49.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role5.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role50.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role51.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role52.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role54.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role55.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role55_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role56.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role56_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role57.yaml                                    │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role57_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role58.yaml                                    │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role58_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role59.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role6.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role60.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role61.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role62.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role63.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role64.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role64_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role65.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role66.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role66_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role68.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role69.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role7.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role70.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role71.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role72.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role73.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role74.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role75.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role76.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role77.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role78.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role79.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role80.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role81.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role82.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role83.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role84.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role85.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role86.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role87.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role88.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role89.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role9.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role90.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role91.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role92.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role93.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role94.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role95.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role96.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role97.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role98.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-role99.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-rolebinding-sa-demo.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-rolebinding.yaml                               │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles10.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles10_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles11.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles11_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles12.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles12_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles13.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles13_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles21.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles21_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles23.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles23_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles24.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles24_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles25.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles25_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles26.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles26_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles27.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles27_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles28.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles28_1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles9.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-roles9_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secret-vars.sops.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets-user.sops.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets-user.sops1.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets-user.sops2.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.secret.sops.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.secret.sops1.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops1.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops10.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops11.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops12.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops13.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops14.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops15.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops16.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops17.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops18.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops19.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops2.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops20.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops21.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops22.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops3.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops4.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops5.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops6.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops7.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops8.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets.sops9.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets12.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-secrets5.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-service.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings-user.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings-user1.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings-user2.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings1.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings10.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings11.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings12.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings13.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings14.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings15.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings16.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings17.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings18.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings19.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings2.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings20.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings21.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings22.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings23.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings24.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings25.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings26.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings27.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings29.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings3.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings4.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings5.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings6.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings7.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings8.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-settings9.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-to-rolebind.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-to-rolebind1.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-to-rolebind2.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-user.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-user_1.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-vars.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-vars1.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-vars2.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-vars3.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-viewer.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-viewer_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster-viewer_2.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1100.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1100_1.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1100_2.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1100_3.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1103.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1103_1.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1103_2.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster1103_3.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster112.yaml                                        │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster112_1.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster115_1.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster208.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster215.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster233.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster233_1.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster233_2.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster233_3.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster26.yaml                                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster263.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster263_1.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster263_2.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster263_3.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_1.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_2.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_3.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_4.yaml                                      │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_5.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_6.yaml                                      │ kubernetes │        14         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster264_7.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster312.yaml                                        │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster312_1.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster323.yaml                                        │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster323_1.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster4.yaml                                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster42.yaml                                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ cluster42_1.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP16.yaml                                       │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP16_1.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP16_2.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP19.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP25.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP33.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP44.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIP7.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIp-service10.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIp20.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterIp23.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole-binding.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole-binding1.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole12.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole12_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole13.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole134.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole134_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole13_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole14.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole14_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole19.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole19_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole20.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole201.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole201_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole204.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole205.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole205_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole206.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole206_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole206_2.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole20_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole260.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole260_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole29.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole320.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole323.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole323_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole355.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole355_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole384.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole384_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole397.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole398.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole398_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole420.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole431.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole431_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole441.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole441_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole442.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole45.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole454.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole454_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole45_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole486.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole486_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole488.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole488_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole516.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole516_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole56.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole56_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole59.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole59_1.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterRole60.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusteradmin.yaml                                      │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterbpfapplication_editor_role.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterbpfapplication_viewer_role.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterclaim_viewer_role.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clustereventbus_editor_role.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clustereventbus_viewer_role.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterinfoimport_editor_role.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterinfoimport_viewer_role.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-1.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-example.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-example_1.yaml                               │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-example_2.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-nginx.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-nginx1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-nginx2.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-nginx3.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-sample.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service-apache.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service-definition.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service-definition1.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service-tomcat.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service1.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service2.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service3.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service4.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service5.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service5_1.yaml                              │ kubernetes │        34         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service5_2.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service6.yaml                                │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service6_1.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service7.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service8.yaml                                │ kubernetes │        35         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service8_1.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service9.yaml                                │ kubernetes │        31         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-service9_1.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip-svc-nginx.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip.yaml                                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip10.yaml                                       │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip10_1.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip10_2.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip10_4.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip11.yaml                                       │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip11_1.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip11_2.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip11_4.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip12.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip13.yaml                                       │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip13_1.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip13_2.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip13_4.yaml                                     │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip14.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip15.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip17.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip17_1.yaml                                     │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip2.yaml                                        │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip22.yaml                                       │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip22_1.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip27.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip27_1.yaml                                     │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip28.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip29.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip2_1.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip2_2.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip2_4.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip3.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip30.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip30_1.yaml                                     │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip31.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip32.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip34.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip35.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip37.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip38.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip39.yaml                                       │ kubernetes │        20         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip39_1.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip40.yaml                                       │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip40_1.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip42.yaml                                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip43.yaml                                       │ kubernetes │        14         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip43_1.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip5.yaml                                        │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip5_1.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip5_2.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip5_4.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip6.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip8.yaml                                        │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip8_1.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip9.yaml                                        │ kubernetes │        19         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip9_1.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip9_2.yaml                                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip9_4.yaml                                      │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterip_service.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_deployment.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_deployment_1.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_deployment_2.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_deployment_3.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_deployment_4.yaml                     │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_rbac.yaml                             │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_rbac_1.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_rbac_2.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_rbac_3.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_rbac_4.yaml                           │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_agent_secret.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_bootstrap_rbac.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_bootstrap_rbac_1.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_bootstrap_rbac_2.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_bootstrap_rbac_3.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_clusterapi_secret.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_controller_manager_deployment.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_controller_manager_deployment_1.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_controller_manager_deployment_2.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_controller_manager_deployment_3.yaml        │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_controller_manager_rbac.yaml                │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_apiservice.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_apiservice_1.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_1.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_2.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_3.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_4.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_5.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_6.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_deployment_7.yaml                       │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_rbac.yaml                               │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_hub_rbac_1.yaml                             │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_scheduler_deployment.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_scheduler_deployment_1.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_scheduler_deployment_2.yaml                 │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_scheduler_rbac.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_scheduler_rbac_1.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusternet_scheduler_rbac_2.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterole.yaml                                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterolebinding.yaml                                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpackage_editor_role.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpackage_viewer_role.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_apiservice.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_apiservice1.yaml                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment1.yaml                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment1_1.yaml              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment1_2.yaml              │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment1_3.yaml              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment_1.yaml               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment_2.yaml               │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_deployment_3.yaml               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_rbac.yaml                       │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_apiserver_rbac_1.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_binding_apiserver_apiservice.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_binding_apiserver_deployment.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_binding_apiserver_deployment_1.yaml       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_binding_apiserver_deployment_2.yaml       │ kubernetes │        18         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_binding_apiserver_rbac.yaml               │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_binding_apiserver_rbac_1.yaml             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_clustersynchro_manager_deployment.yaml    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_clustersynchro_manager_deployment1.yaml   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_clustersynchro_manager_deployment1_1.yaml │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_clustersynchro_manager_deployment_1.yaml  │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_controller_manager_deployment.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_controller_manager_deployment1.yaml       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_controller_manager_deployment1_1.yaml     │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_controller_manager_deployment_1.yaml      │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_configmap.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_configmap1.yaml           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_configmap1_1.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_configmap2.yaml           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_configmap3.yaml           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_configmap_1.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment.yaml           │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment1.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment1_1.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment1_2.yaml        │ kubernetes │        16         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment2.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment2_1.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment2_2.yaml        │ kubernetes │        16         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment3.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment3_1.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment3_2.yaml        │ kubernetes │        16         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment_1.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_deployment_2.yaml         │ kubernetes │        16         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_local_pv.yaml             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_local_pv1.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_local_pv_check_job.yaml   │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_local_pv_check_job1.yaml  │ kubernetes │        17         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_secret.yaml               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_secret1.yaml              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_secret2.yaml              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_internalstorage_secret3.yaml              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_namespace.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_synchro_rbac.yaml                         │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_synchro_rbac_1.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterpedia_synchro_rbac_2.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-db-backup-pv.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-db-backup-pvc.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-media-pv.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-media-pvc.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-orchestrator-config.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-orchestrator.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-orchestrator1.yaml                         │ kubernetes │        14         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-pms-config-pvc.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-pms-config.yaml                            │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-pms.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-pms1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-pms2.yaml                                  │ kubernetes │        30         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-transcode-pvc.yaml                         │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-worker-config.yaml                         │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-worker.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterplex-worker1.yaml                               │ kubernetes │        45         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterresources.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterresources_1.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrip-service.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-0.yaml                                     │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-01.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-02.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-03.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-04.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-1.yaml                                     │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-11.yaml                                    │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-12.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-2.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-3.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-4.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-anvesh.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-attacher2.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-core-star.yaml                             │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-cr-star.yaml                               │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-demo.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-eks-user.yaml                              │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-garnet-operator.yaml                       │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-juno.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-juno_1.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-kcp-admin-maximal-permission-policy.yaml   │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-node-provider-labeler.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-pod-reader.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-podviewer.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-provisioner2.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-qdrant-operator.yaml                       │ kubernetes │         6         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-qdrant-operator1.yaml                      │ kubernetes │         6         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-ricardo.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-ricardo_1.yaml                             │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-tenancy-apiexport-bind.yaml                │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-tenancy-maximal-permission-policy.yaml     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-topology-apiexport-bind.yaml               │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-topology-maximal-permission-policy.yaml    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-union.yaml                                 │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-workspace-home-create.yaml                 │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-workspacetype-use.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole-workspacetype-use1.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole11.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole117.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole133.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole135.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole136.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole138.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole139.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole140.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole163.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole17.yaml                                     │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole187.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole191.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole203.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole21.yaml                                     │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole22.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole23.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole24.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole243.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole244.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole25.yaml                                     │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole256.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole258.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole259.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole26.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole262.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole265.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole28.yaml                                     │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole30.yaml                                     │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole306.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole31.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole32.yaml                                     │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole321.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole326.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole328.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole33.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole334.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole335.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole336.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole337.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole338.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole34.yaml                                     │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole352.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole354.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole374.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole375.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole376.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole377.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole378.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole378_1.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole379.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole379_1.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole380.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole380_1.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole381.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole381_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole382.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole395.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole396.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole396_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole405.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole407.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole408.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole413.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole414.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole414_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole424.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole426.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole432.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole432_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole435.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole437.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole438.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole444.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole445.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole446.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole446_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole452.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole461.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole480.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole481.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole482.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole483.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole483_1.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole484.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole484_1.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole485.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole485_1.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole487.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole497.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole504.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole505.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole518.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole519.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole520.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole521.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole522.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole532.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole532_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole534.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole535.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole539.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole55.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole556.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole564.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole565.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole566.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole567.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole569.yaml                                    │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole570.yaml                                    │ kubernetes │         4         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole571.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole572.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole573.yaml                                    │ kubernetes │         6         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole574.yaml                                    │ kubernetes │         5         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole58.yaml                                     │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole580.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole581.yaml                                    │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole584.yaml                                    │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole585.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole585_1.yaml                                  │ kubernetes │         6         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole587.yaml                                    │ kubernetes │         8         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole587_1.yaml                                  │ kubernetes │         5         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole588.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole588_1.yaml                                  │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole588_2.yaml                                  │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole589.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole589_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole590.yaml                                    │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole591.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole591_1.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole595.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole596.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole598.yaml                                    │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole598_1.yaml                                  │ kubernetes │         1         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole598_2.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole602.yaml                                    │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole603.yaml                                    │ kubernetes │         7         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole603_1.yaml                                  │ kubernetes │         3         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole603_2.yaml                                  │ kubernetes │         2         │
├────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ clusterrole604.yaml                                    │ kubernetes │         1         │
└────────────────────────────────────────────────────────┴────────────┴───────────────────┘
Legend:
- '-': Not scanned
- '0': Clean (no security findings detected)


ClusterAutoScaler_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 2, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'cluster-autoscaler' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterAutoScaler_1.yaml:97-106
────────────────────────────────────────
  97 ┌ - apiGroups:
  98 │   - batch
  99 │   - extensions
 100 │   resources:
 101 │   - jobs
 102 │   verbs:
 103 │   - get
 104 │   - list
 105 │   - watch
 106 └   - patch
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'cluster-autoscaler' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterAutoScaler_1.yaml:9-16
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ''
  11 │   resources:
  12 │   - events
  13 │   - endpoints
  14 │   verbs:
  15 │   - create
  16 └   - patch
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'cluster-autoscaler' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterAutoScaler_1.yaml:29-37
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - ''
  31 │   resources:
  32 │   - endpoints
  33 │   resourceNames:
  34 │   - cluster-autoscaler
  35 │   verbs:
  36 │   - get
  37 └   - update
────────────────────────────────────────



ClusterAutoScaler_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'cluster-autoscaler' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 ClusterAutoScaler_2.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - configmaps
  14 │   verbs:
  15 │   - create
  16 │   - list
  17 └   - watch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'cluster-autoscaler' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 ClusterAutoScaler_2.yaml:18-29
────────────────────────────────────────
  18 ┌ - apiGroups:
  19 │   - ''
  20 │   resources:
  21 │   - configmaps
  22 │   resourceNames:
  23 │   - cluster-autoscaler-status
  24 │   - cluster-autoscaler-priority-expander
  25 │   verbs:
  26 └   - delete
  ..   
────────────────────────────────────────



ClusterAutoScaler_5.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 1, MEDIUM: 3, HIGH: 0, CRITICAL: 0)

AVD-KSV-0021 (LOW): Container 'cluster-autoscaler' of Deployment 'cluster-autoscaler' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 ClusterAutoScaler_5.yaml:31-61
────────────────────────────────────────
  31 ┌       - image: registry.k8s.io/autoscaling/cluster-autoscaler:v1.29.4
  32 │         name: cluster-autoscaler
  33 │         resources:
  34 │           limits:
  35 │             cpu: 100m
  36 │             memory: 300Mi
  37 │           requests:
  38 │             cpu: 50m
  39 └             memory: 50Mi
  ..   
────────────────────────────────────────


AVD-KSV-0023 (MEDIUM): Deployment 'cluster-autoscaler' should not set 'spec.template.volumes.hostPath'
════════════════════════════════════════
According to pod security standard 'HostPath Volumes', HostPath volumes must be forbidden.

See https://avd.aquasec.com/misconfig/ksv023
────────────────────────────────────────
 ClusterAutoScaler_5.yaml:9-65
────────────────────────────────────────
   9 ┌   replicas: 1
  10 │   selector:
  11 │     matchLabels:
  12 │       app: cluster-autoscaler
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app: cluster-autoscaler
  17 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): Deployment 'cluster-autoscaler' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 ClusterAutoScaler_5.yaml:9-65
────────────────────────────────────────
   9 ┌   replicas: 1
  10 │   selector:
  11 │     matchLabels:
  12 │       app: cluster-autoscaler
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app: cluster-autoscaler
  17 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container cluster-autoscaler in deployment cluster-autoscaler (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 ClusterAutoScaler_5.yaml:31-61
────────────────────────────────────────
  31 ┌       - image: registry.k8s.io/autoscaling/cluster-autoscaler:v1.29.4
  32 │         name: cluster-autoscaler
  33 │         resources:
  34 │           limits:
  35 │             cpu: 100m
  36 │             memory: 300Mi
  37 │           requests:
  38 │             cpu: 50m
  39 └             memory: 50Mi
  ..   
────────────────────────────────────────



ClusterIP-svc.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'webapp1' of Pod 'webapp1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'webapp1' of Pod 'webapp1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'webapp1' of 'pod' 'webapp1' in 'test-ns' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'webapp1' of Pod 'webapp1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'webapp1' of Pod 'webapp1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'webapp1' of Pod 'webapp1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'webapp1' of Pod 'webapp1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'webapp1' of Pod 'webapp1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'webapp1' of Pod 'webapp1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'webapp1' of Pod 'webapp1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'webapp1' of Pod 'webapp1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'webapp1' of Pod 'webapp1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "webapp1" of pod "webapp1" in "test-ns" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container webapp1 in test-ns namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod webapp1 in test-ns namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 ClusterIP-svc.yaml:9-13
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container webapp1 in pod webapp1 (namespace: test-ns) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 ClusterIP-svc.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: webapp1
  11 │     image: lokeshnagam121/javaproject
  12 │     ports:
  13 └     - containerPort: 8761
────────────────────────────────────────



ClusterIP_4.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0037 (MEDIUM): Service 'kube-dns' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 ClusterIP_4.yaml:11-23
────────────────────────────────────────
  11 ┌   clusterIP: 10.96.0.10
  12 │   ports:
  13 │   - name: dns
  14 │     port: 53
  15 │     protocol: UDP
  16 │     targetPort: 53
  17 │   - name: dns-tcp
  18 │     port: 53
  19 └     protocol: TCP
  ..   
────────────────────────────────────────



ClusterIP_7.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0108 (HIGH): Service 'my-service' in 'default' namespace should not set external IPs or external Name
════════════════════════════════════════
Services with external IP addresses allows direct access from the internet and might expose risk for CVE-2020-8554

See https://avd.aquasec.com/misconfig/avd-ksv-0108
────────────────────────────────────────



ClusterIp26.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'web' of Deployment 'mydep' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web' of Deployment 'mydep' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web' of 'deployment' 'mydep' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'web' of Deployment 'mydep' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web' of Deployment 'mydep' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web' of Deployment 'mydep' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web' of Deployment 'mydep' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web' of Deployment 'mydep' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'web' of Deployment 'mydep' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web' of Deployment 'mydep' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web' of Deployment 'mydep' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web" of deployment "mydep" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydep in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 ClusterIp26.yaml:4
────────────────────────────────────────
   4 [   name: mydep
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydep in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydep in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydep in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 ClusterIp26.yaml:15-21
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container web in deployment mydep (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 ClusterIp26.yaml:16-21
────────────────────────────────────────
  16 ┌       - name: web
  17 │         image: kubedevio/web-color:green
  18 │         ports:
  19 │         - name: http
  20 │           containerPort: 80
  21 └           protocol: TCP
────────────────────────────────────────



ClusterRole-ReadOnlyAccess.yaml (kubernetes)
============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess1.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess1.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess2.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess2.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess3.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess3.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess4.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess4.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess5.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess5.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess6.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess6.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess7.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess7.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-ReadOnlyAccess8.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'aks-cluster-readonly-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-ReadOnlyAccess8.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "extensions", "apps"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



ClusterRole-argocd-application-controller.yaml (kubernetes)
===========================================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 ClusterRole-argocd-application-controller.yaml:11-16
────────────────────────────────────────
  11 ┌   - apiGroups:
  12 │       - '*'
  13 │     resources:
  14 │       - '*'
  15 │     verbs:
  16 └       - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-argocd-application-controller.yaml:11-16
────────────────────────────────────────
  11 ┌   - apiGroups:
  12 │       - '*'
  13 │     resources:
  14 │       - '*'
  15 │     verbs:
  16 └       - '*'
────────────────────────────────────────



ClusterRole-argocd-notifications-controller.yaml (kubernetes)
=============================================================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'argocd-notifications-controller' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole-argocd-notifications-controller.yaml:22-29
────────────────────────────────────────
  22 ┌   - apiGroups:
  23 │       - ""
  24 │     resources:
  25 │       - configmaps
  26 │       - secrets
  27 │     verbs:
  28 │       - list
  29 └       - watch
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'argocd-notifications-controller' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole-argocd-notifications-controller.yaml:38-45
────────────────────────────────────────
  38 ┌   - apiGroups:
  39 │       - ""
  40 │     resourceNames:
  41 │       - argocd-notifications-secret
  42 │     resources:
  43 │       - secrets
  44 │     verbs:
  45 └       - get
────────────────────────────────────────



ClusterRole-argocd-server.yaml (kubernetes)
===========================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-argocd-server.yaml:11-18
────────────────────────────────────────
  11 ┌   - apiGroups:
  12 │       - '*'
  13 │     resources:
  14 │       - '*'
  15 │     verbs:
  16 │       - delete
  17 │       - get
  18 └       - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole-argocd-server.yaml:43-48
────────────────────────────────────────
  43 ┌   - apiGroups:
  44 │       - batch
  45 │     resources:
  46 │       - jobs
  47 │     verbs:
  48 └       - create
────────────────────────────────────────



ClusterRole-cilium-operator.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'cilium-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole-cilium-operator.yaml:54-62
────────────────────────────────────────
  54 ┌   - apiGroups:
  55 │       - ""
  56 │     resources:
  57 │       - namespaces
  58 │       - secrets
  59 │     verbs:
  60 │       - get
  61 │       - list
  62 └       - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'cilium-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole-cilium-operator.yaml:8-16
────────────────────────────────────────
   8 ┌   - apiGroups:
   9 │       - ""
  10 │     resources:
  11 │       - pods
  12 │     verbs:
  13 │       - get
  14 │       - list
  15 │       - watch
  16 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'cilium-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 ClusterRole-cilium-operator.yaml:17-24
────────────────────────────────────────
  17 ┌   - apiGroups:
  18 │       - ""
  19 │     resourceNames:
  20 │       - cilium-config
  21 │     resources:
  22 │       - configmaps
  23 │     verbs:
  24 └       - patch
────────────────────────────────────────



ClusterRole-hubble-ui.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'hubble-ui' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-hubble-ui.yaml:37-44
────────────────────────────────────────
  37 ┌   - apiGroups:
  38 │       - cilium.io
  39 │     resources:
  40 │       - '*'
  41 │     verbs:
  42 │       - get
  43 │       - list
  44 └       - watch
────────────────────────────────────────



ClusterRole-nfs-external-provisioner-role.yaml (kubernetes)
===========================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'nfs-external-provisioner-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole-nfs-external-provisioner-role.yaml:102-107
────────────────────────────────────────
 102 ┌   - apiGroups:
 103 │       - ""
 104 │     resources:
 105 │       - secrets
 106 │     verbs:
 107 └       - get
────────────────────────────────────────



ClusterRole-onepassword-connect-operator.yaml (kubernetes)
==========================================================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'onepassword-connect-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole-onepassword-connect-operator.yaml:9-28
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - pods
  13 │       - services
  14 │       - services/finalizers
  15 │       - endpoints
  16 │       - persistentvolumeclaims
  17 └       - events
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'onepassword-connect-operator' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole-onepassword-connect-operator.yaml:72-83
────────────────────────────────────────
  72 ┌   - apiGroups:
  73 │       - onepassword.com
  74 │     resources:
  75 │       - '*'
  76 │     verbs:
  77 │       - create
  78 │       - delete
  79 │       - get
  80 └       - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'onepassword-connect-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole-onepassword-connect-operator.yaml:9-28
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - pods
  13 │       - services
  14 │       - services/finalizers
  15 │       - endpoints
  16 │       - persistentvolumeclaims
  17 └       - events
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'onepassword-connect-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole-onepassword-connect-operator.yaml:29-43
────────────────────────────────────────
  29 ┌   - apiGroups:
  30 │       - apps
  31 │     resources:
  32 │       - deployments
  33 │       - daemonsets
  34 │       - replicasets
  35 │       - statefulsets
  36 │     verbs:
  37 └       - create
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'onepassword-connect-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 ClusterRole-onepassword-connect-operator.yaml:9-28
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - pods
  13 │       - services
  14 │       - services/finalizers
  15 │       - endpoints
  16 │       - persistentvolumeclaims
  17 └       - events
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'onepassword-connect-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterRole-onepassword-connect-operator.yaml:9-28
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - pods
  13 │       - services
  14 │       - services/finalizers
  15 │       - endpoints
  16 │       - persistentvolumeclaims
  17 └       - events
  ..   
────────────────────────────────────────



ClusterRole-tailscale-operator.yaml (kubernetes)
================================================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 2, CRITICAL: 0)

AVD-KSV-0056 (HIGH): ClusterRole 'tailscale-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterRole-tailscale-operator.yaml:6-20
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - events
  10 │       - services
  11 │       - services/status
  12 │     verbs:
  13 │       - create
  14 └       - delete
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'tailscale-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterRole-tailscale-operator.yaml:21-34
────────────────────────────────────────
  21 ┌   - apiGroups:
  22 │       - networking.k8s.io
  23 │     resources:
  24 │       - ingresses
  25 │       - ingresses/status
  26 │     verbs:
  27 │       - create
  28 │       - delete
  29 └       - deletecollection
  ..   
────────────────────────────────────────



ClusterRole-traefik-traefik.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'traefik-traefik' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole-traefik-traefik.yaml:32-39
────────────────────────────────────────
  32 ┌   - apiGroups:
  33 │       - ""
  34 │     resources:
  35 │       - secrets
  36 │     verbs:
  37 │       - get
  38 │       - list
  39 └       - watch
────────────────────────────────────────



ClusterRole173.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'custom-scheduler' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole173.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["pods", "pods/binding", "nodes", "events"]
   8 └   verbs: ["get", "list", "watch", "create", "update"]
────────────────────────────────────────



ClusterRole347.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'api-cluster-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole347.yaml:7-37
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │         - ""
   9 │         - apps
  10 │         - autoscaling
  11 │         - batch
  12 │         - extensions
  13 │         - policy
  14 │         - rbac.authorization.k8s.io
  15 └     resources:
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'api-cluster-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 ClusterRole347.yaml:7-37
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │         - ""
   9 │         - apps
  10 │         - autoscaling
  11 │         - batch
  12 │         - extensions
  13 │         - policy
  14 │         - rbac.authorization.k8s.io
  15 └     resources:
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'api-cluster-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterRole347.yaml:7-37
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │         - ""
   9 │         - apps
  10 │         - autoscaling
  11 │         - batch
  12 │         - extensions
  13 │         - policy
  14 │         - rbac.authorization.k8s.io
  15 └     resources:
  ..   
────────────────────────────────────────



ClusterRole349.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'superuser' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole349.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources: ["*"]
   9 │   verbs:
  10 │   - get
  11 │   - list
  12 │   - watch
  13 │   - create
  14 └   - update
  ..   
────────────────────────────────────────



ClusterRole350.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secret-reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole350.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["secrets"]
   8 └   verbs: ["get", "watch", "list"]
────────────────────────────────────────



ClusterRole517.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 ClusterRole517.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["*"]
   7 │   resources: ["*"]
   8 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'full-access' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 ClusterRole517.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["*"]
   7 │   resources: ["*"]
   8 └   verbs: ["*"]
────────────────────────────────────────



ClusterRole555.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 ClusterRole555.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""] # "" indicates the core API group
   8 │   resources: ["pods"]
   9 └   verbs: ["get", "watch", "list", "update", "escalate", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'developer' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 ClusterRole555.yaml:10-12
────────────────────────────────────────
  10 ┌ - apiGroups: [""] # "" indicates the core API group
  11 │   resources: ["services"]
  12 └   verbs: ["get", "watch", "list", "update"]
────────────────────────────────────────



ClusterRole593.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'my-release' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 ClusterRole593.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""] # "" indicates the core API group
   8 │     resources: ["services", "endpoints", "secrets"]
   9 └     verbs: ["get", "watch", "list"]
────────────────────────────────────────



cluster-role204.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role204.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role204.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role204.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role204.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role204.yaml:41-47
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - pods
  45 │   verbs:
  46 │   - list
  47 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role204.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role204.yaml:48-58
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ""
  50 │   resources:
  51 │   - services
  52 │   - services/finalizers
  53 │   - endpoints
  54 │   verbs:
  55 │   - get
  56 └   - create
  ..   
────────────────────────────────────────



cluster-role206.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role206.yaml:6-23
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - secrets
  11 │   - nodes
  12 │   - pods
  13 │   - services
  14 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role209.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role209.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role209.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role209.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role209.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role209.yaml:41-47
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - pods
  45 │   verbs:
  46 │   - list
  47 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role209.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role209.yaml:48-58
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ""
  50 │   resources:
  51 │   - services
  52 │   - services/finalizers
  53 │   - endpoints
  54 │   verbs:
  55 │   - get
  56 └   - create
  ..   
────────────────────────────────────────



cluster-role21.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'nginx-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role21.yaml:6-16
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - endpoints
  11 │       - nodes
  12 │       - pods
  13 │       - secrets
  14 └     verbs:
  ..   
────────────────────────────────────────



cluster-role210.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role210.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role213.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role213.yaml:30-36
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - configmaps
  34 │   - secrets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role213.yaml:24-29
────────────────────────────────────────
  24 ┌ - apiGroups:
  25 │   - apps
  26 │   resources:
  27 │   - statefulsets
  28 │   verbs:
  29 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role213.yaml:30-36
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - configmaps
  34 │   - secrets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role213.yaml:24-29
────────────────────────────────────────
  24 ┌ - apiGroups:
  25 │   - apps
  26 │   resources:
  27 │   - statefulsets
  28 │   verbs:
  29 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role213.yaml:37-43
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ""
  39 │   resources:
  40 │   - pods
  41 │   verbs:
  42 │   - list
  43 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role213.yaml:30-36
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - configmaps
  34 │   - secrets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role213.yaml:44-54
────────────────────────────────────────
  44 ┌ - apiGroups:
  45 │   - ""
  46 │   resources:
  47 │   - services
  48 │   - services/finalizers
  49 │   - endpoints
  50 │   verbs:
  51 │   - get
  52 └   - create
  ..   
────────────────────────────────────────



cluster-role215.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role215.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role217.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role217.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role217.yaml:34-39
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - apps
  36 │     resources:
  37 │       - statefulsets
  38 │     verbs:
  39 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role217.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role217.yaml:34-39
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - apps
  36 │     resources:
  37 │       - statefulsets
  38 │     verbs:
  39 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role217.yaml:47-53
────────────────────────────────────────
  47 ┌   - apiGroups:
  48 │       - ""
  49 │     resources:
  50 │       - pods
  51 │     verbs:
  52 │       - list
  53 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role217.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role217.yaml:54-64
────────────────────────────────────────
  54 ┌   - apiGroups:
  55 │       - ""
  56 │     resources:
  57 │       - services
  58 │       - services/finalizers
  59 │       - endpoints
  60 │     verbs:
  61 │       - get
  62 └       - create
  ..   
────────────────────────────────────────



cluster-role218_1.yaml (kubernetes)
===================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0114 (CRITICAL): ClusterRole 'kube-sidecar-injector' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 cluster-role218_1.yaml:8-15
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - admissionregistration.k8s.io
  10 │   resources:
  11 │   - mutatingwebhookconfigurations
  12 │   verbs:
  13 │   - create
  14 │   - get
  15 └   - update
────────────────────────────────────────



cluster-role22.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role22.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role220.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role220.yaml:33-39
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - ""
  35 │   resources:
  36 │   - configmaps
  37 │   - secrets
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role220.yaml:27-32
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - apps
  29 │   resources:
  30 │   - statefulsets
  31 │   verbs:
  32 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role220.yaml:33-39
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - ""
  35 │   resources:
  36 │   - configmaps
  37 │   - secrets
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role220.yaml:27-32
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - apps
  29 │   resources:
  30 │   - statefulsets
  31 │   verbs:
  32 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role220.yaml:40-46
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ""
  42 │   resources:
  43 │   - pods
  44 │   verbs:
  45 │   - list
  46 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role220.yaml:33-39
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - ""
  35 │   resources:
  36 │   - configmaps
  37 │   - secrets
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role220.yaml:47-57
────────────────────────────────────────
  47 ┌ - apiGroups:
  48 │   - ""
  49 │   resources:
  50 │   - services
  51 │   - services/finalizers
  52 │   - endpoints
  53 │   verbs:
  54 │   - get
  55 └   - create
  ..   
────────────────────────────────────────



cluster-role224.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role224.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role224.yaml:34-39
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - apps
  36 │     resources:
  37 │       - statefulsets
  38 │     verbs:
  39 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role224.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role224.yaml:34-39
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - apps
  36 │     resources:
  37 │       - statefulsets
  38 │     verbs:
  39 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role224.yaml:47-53
────────────────────────────────────────
  47 ┌   - apiGroups:
  48 │       - ""
  49 │     resources:
  50 │       - pods
  51 │     verbs:
  52 │       - list
  53 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role224.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role224.yaml:54-64
────────────────────────────────────────
  54 ┌   - apiGroups:
  55 │       - ""
  56 │     resources:
  57 │       - services
  58 │       - services/finalizers
  59 │       - endpoints
  60 │     verbs:
  61 │       - get
  62 └       - create
  ..   
────────────────────────────────────────



cluster-role225.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role225.yaml:6-24
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - secrets
  11 │       - nodes
  12 │       - pods
  13 │       - services
  14 └       - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role227.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role227.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role227.yaml:34-39
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - apps
  36 │     resources:
  37 │       - statefulsets
  38 │     verbs:
  39 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role227.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role227.yaml:34-39
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - apps
  36 │     resources:
  37 │       - statefulsets
  38 │     verbs:
  39 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role227.yaml:47-53
────────────────────────────────────────
  47 ┌   - apiGroups:
  48 │       - ""
  49 │     resources:
  50 │       - pods
  51 │     verbs:
  52 │       - list
  53 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role227.yaml:40-46
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - configmaps
  44 │       - secrets
  45 │     verbs:
  46 └       - "*"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role227.yaml:54-64
────────────────────────────────────────
  54 ┌   - apiGroups:
  55 │       - ""
  56 │     resources:
  57 │       - services
  58 │       - services/finalizers
  59 │       - endpoints
  60 │     verbs:
  61 │       - get
  62 └       - create
  ..   
────────────────────────────────────────



cluster-role228.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role228.yaml:6-24
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - secrets
  11 │       - nodes
  12 │       - pods
  13 │       - services
  14 └       - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role229.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role229.yaml:6-24
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - secrets
  11 │       - nodes
  12 │       - pods
  13 │       - services
  14 └       - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role231.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role231.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role232.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role232.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role234.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 cluster-role234.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 cluster-role234.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



cluster-role235.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role235.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role243.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'my-cluster-role-binding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 cluster-role243.yaml:4
────────────────────────────────────────
   4 [   name: my-cluster-role-binding
────────────────────────────────────────



cluster-role244.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'my-cluster-role-binding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 cluster-role244.yaml:4-7
────────────────────────────────────────
   4 ┌   namespace: cert-manager
   5 │   name: my-cluster-role-binding
   6 │   annotations:
   7 └     argocd.argoproj.io/hook: PreSync
────────────────────────────────────────



cluster-role245.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'cluster-admin' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role245.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: [""]
   7 │     resources: ["pods"]
   8 └     verbs: ["get", "watch", "list", "create", "delete"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'cluster-admin' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role245.yaml:9-11
────────────────────────────────────────
   9 ┌   - apiGroups: ["apps"]
  10 │     resources: ["deployments"]
  11 └     verbs: ["get", "watch", "list", "create", "delete"]
────────────────────────────────────────



cluster-role247.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role247.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources:
   8 │   - namespaces
   9 │   - nodes
  10 │   - services
  11 │   - configmaps
  12 │   - pods
  13 │   - replicationcontrollers
  14 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role248.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0056 (HIGH): ClusterRole 'sheraz-cluster-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role248.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["nodes", "services"] #what resources the user can access in the cluster
   9 └   verbs: ["get", "list", "create"] #what the user can do in the cluster
────────────────────────────────────────



cluster-role25.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'argocd-repo-server' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role25.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - get
  12 └   - watch
────────────────────────────────────────



cluster-role250.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role250.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role27.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role27.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'reader' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role27.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'reader' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role27.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'reader' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role27.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────



cluster-role28.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role28.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'reader' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role28.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'reader' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role28.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'reader' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role28.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────



cluster-role29.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role29.yaml:10-28
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role30.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role30.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role31.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'application-controller' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role31.yaml:20-22
────────────────────────────────────────
  20 ┌   - apiGroups: ["apps"]
  21 │     resources: ["deployments"]
  22 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'application-controller' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role31.yaml:24-26
────────────────────────────────────────
  24 ┌   - apiGroups: [""]
  25 │     resources: ["services"]
  26 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────



cluster-role32.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'nginx-ingress-clusterrole' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role32.yaml:6-16
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - endpoints
  11 │       - nodes
  12 │       - pods
  13 │       - secrets
  14 └     verbs:
  ..   
────────────────────────────────────────



cluster-role34.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role34.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role35.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role35.yaml:11-26
────────────────────────────────────────
  11 ┌   - apiGroups: ['']
  12 │     resources:
  13 │       - configmaps
  14 │       - secrets
  15 │       - nodes
  16 │       - pods
  17 │       - services
  18 │       - serviceaccounts
  19 └       - resourcequotas
  ..   
────────────────────────────────────────



cluster-role36.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secrets-store-csi-driver-sync' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role36.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: [""]
   7 │     resources: ["secrets"]
   8 └     verbs: ["get", "list", "create", "update", "patch", "watch"]
────────────────────────────────────────



cluster-role37.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'nginx-ingress-clusterrole' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role37.yaml:6-16
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - endpoints
  11 │       - nodes
  12 │       - pods
  13 │       - secrets
  14 └     verbs:
  ..   
────────────────────────────────────────



cluster-role39.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role39.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role4.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role4.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role41.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role41.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role41.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role41.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role41.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role41.yaml:41-47
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - pods
  45 │   verbs:
  46 │   - list
  47 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role41.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role41.yaml:48-58
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ""
  50 │   resources:
  51 │   - services
  52 │   - services/finalizers
  53 │   - endpoints
  54 │   verbs:
  55 │   - get
  56 └   - create
  ..   
────────────────────────────────────────



cluster-role43.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role43.yaml:6-23
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - secrets
  11 │   - nodes
  12 │   - pods
  13 │   - services
  14 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role46.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role46.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role46.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role46.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role46.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role46.yaml:41-47
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - pods
  45 │   verbs:
  46 │   - list
  47 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role46.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role46.yaml:48-58
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ""
  50 │   resources:
  51 │   - services
  52 │   - services/finalizers
  53 │   - endpoints
  54 │   verbs:
  55 │   - get
  56 └   - create
  ..   
────────────────────────────────────────



cluster-role47.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role47.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role5.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role5.yaml:11-26
────────────────────────────────────────
  11 ┌   - apiGroups: ['']
  12 │     resources:
  13 │       - configmaps
  14 │       - secrets
  15 │       - nodes
  16 │       - pods
  17 │       - services
  18 │       - serviceaccounts
  19 └       - resourcequotas
  ..   
────────────────────────────────────────



cluster-role50.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role50.yaml:30-36
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - configmaps
  34 │   - secrets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role50.yaml:24-29
────────────────────────────────────────
  24 ┌ - apiGroups:
  25 │   - apps
  26 │   resources:
  27 │   - statefulsets
  28 │   verbs:
  29 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role50.yaml:30-36
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - configmaps
  34 │   - secrets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role50.yaml:24-29
────────────────────────────────────────
  24 ┌ - apiGroups:
  25 │   - apps
  26 │   resources:
  27 │   - statefulsets
  28 │   verbs:
  29 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role50.yaml:37-43
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ""
  39 │   resources:
  40 │   - pods
  41 │   verbs:
  42 │   - list
  43 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role50.yaml:30-36
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - configmaps
  34 │   - secrets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role50.yaml:44-54
────────────────────────────────────────
  44 ┌ - apiGroups:
  45 │   - ""
  46 │   resources:
  47 │   - services
  48 │   - services/finalizers
  49 │   - endpoints
  50 │   verbs:
  51 │   - get
  52 └   - create
  ..   
────────────────────────────────────────



cluster-role51.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'nginx-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role51.yaml:6-16
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - endpoints
  11 │       - nodes
  12 │       - pods
  13 │       - secrets
  14 └     verbs:
  ..   
────────────────────────────────────────



cluster-role52.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role52.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role55.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'argocd-repo-server' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role55.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - get
  12 └   - watch
────────────────────────────────────────



cluster-role57.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role57.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'reader' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role57.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'reader' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role57.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'reader' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role57.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────



cluster-role58.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role58.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'reader' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role58.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'reader' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role58.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'reader' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role58.yaml:6-19
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - deployments
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 └   - namespaces
  ..   
────────────────────────────────────────



cluster-role59.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role59.yaml:10-28
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role6.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secrets-store-csi-driver-sync' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role6.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: [""]
   7 │     resources: ["secrets"]
   8 └     verbs: ["get", "list", "create", "update", "patch", "watch"]
────────────────────────────────────────



cluster-role60.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role60.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role61.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role61.yaml:10-28
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role63.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role63.yaml:11-28
────────────────────────────────────────
  11 ┌ - apiGroups:
  12 │   - ""
  13 │   resources:
  14 │   - configmaps
  15 │   - secrets
  16 │   - nodes
  17 │   - pods
  18 │   - services
  19 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role64.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 cluster-role64.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



cluster-role65.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role65.yaml:11-28
────────────────────────────────────────
  11 ┌ - apiGroups:
  12 │   - ""
  13 │   resources:
  14 │   - configmaps
  15 │   - secrets
  16 │   - nodes
  17 │   - pods
  18 │   - services
  19 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role66.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 cluster-role66.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



cluster-role68.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role68.yaml:10-28
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - serviceaccounts
  ..   
────────────────────────────────────────



cluster-role7.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'nginx-ingress-clusterrole' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role7.yaml:6-16
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - endpoints
  11 │       - nodes
  12 │       - pods
  13 │       - secrets
  14 └     verbs:
  ..   
────────────────────────────────────────



cluster-role70.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role70.yaml:39-45
────────────────────────────────────────
  39 ┌ - apiGroups:
  40 │   - ""
  41 │   resources:
  42 │   - configmaps
  43 │   - secrets
  44 │   verbs:
  45 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role70.yaml:33-38
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - apps
  35 │   resources:
  36 │   - statefulsets
  37 │   verbs:
  38 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role70.yaml:39-45
────────────────────────────────────────
  39 ┌ - apiGroups:
  40 │   - ""
  41 │   resources:
  42 │   - configmaps
  43 │   - secrets
  44 │   verbs:
  45 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role70.yaml:33-38
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - apps
  35 │   resources:
  36 │   - statefulsets
  37 │   verbs:
  38 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role70.yaml:46-52
────────────────────────────────────────
  46 ┌ - apiGroups:
  47 │   - ""
  48 │   resources:
  49 │   - pods
  50 │   verbs:
  51 │   - list
  52 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role70.yaml:39-45
────────────────────────────────────────
  39 ┌ - apiGroups:
  40 │   - ""
  41 │   resources:
  42 │   - configmaps
  43 │   - secrets
  44 │   verbs:
  45 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role70.yaml:53-63
────────────────────────────────────────
  53 ┌ - apiGroups:
  54 │   - ""
  55 │   resources:
  56 │   - services
  57 │   - services/finalizers
  58 │   - endpoints
  59 │   verbs:
  60 │   - get
  61 └   - create
  ..   
────────────────────────────────────────



cluster-role71.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'pod-lister' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role71.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   #
   9 │   # at the HTTP level, the name of the resource for accessing Secret
  10 │   # objects is "secrets"
  11 │   resources: ["pods", "services"]
  12 └   verbs: ["create", "get", "watch", "list"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'pod-lister' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role71.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   #
   9 │   # at the HTTP level, the name of the resource for accessing Secret
  10 │   # objects is "secrets"
  11 │   resources: ["pods", "services"]
  12 └   verbs: ["create", "get", "watch", "list"]
────────────────────────────────────────



cluster-role73.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role73.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ""
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role74.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role74.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role75.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role75.yaml:9-26
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - configmaps
  13 │       - secrets
  14 │       - nodes
  15 │       - pods
  16 │       - services
  17 └       - resourcequotas
  ..   
────────────────────────────────────────



cluster-role77.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role77.yaml:34-40
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - ""
  36 │     resources:
  37 │       - configmaps
  38 │       - secrets
  39 │     verbs:
  40 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role77.yaml:28-33
────────────────────────────────────────
  28 ┌   - apiGroups:
  29 │       - apps
  30 │     resources:
  31 │       - statefulsets
  32 │     verbs:
  33 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role77.yaml:34-40
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - ""
  36 │     resources:
  37 │       - configmaps
  38 │       - secrets
  39 │     verbs:
  40 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role77.yaml:28-33
────────────────────────────────────────
  28 ┌   - apiGroups:
  29 │       - apps
  30 │     resources:
  31 │       - statefulsets
  32 │     verbs:
  33 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role77.yaml:41-47
────────────────────────────────────────
  41 ┌   - apiGroups:
  42 │       - ""
  43 │     resources:
  44 │       - pods
  45 │     verbs:
  46 │       - list
  47 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role77.yaml:34-40
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - ""
  36 │     resources:
  37 │       - configmaps
  38 │       - secrets
  39 │     verbs:
  40 └       - "*"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role77.yaml:48-58
────────────────────────────────────────
  48 ┌   - apiGroups:
  49 │       - ""
  50 │     resources:
  51 │       - services
  52 │       - services/finalizers
  53 │       - endpoints
  54 │     verbs:
  55 │       - get
  56 └       - create
  ..   
────────────────────────────────────────



cluster-role79.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role79.yaml:6-23
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - configmaps
  10 │       - secrets
  11 │       - nodes
  12 │       - pods
  13 │       - services
  14 └       - resourcequotas
  ..   
────────────────────────────────────────



cluster-role82.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role82.yaml:34-40
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - ""
  36 │     resources:
  37 │       - configmaps
  38 │       - secrets
  39 │     verbs:
  40 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role82.yaml:28-33
────────────────────────────────────────
  28 ┌   - apiGroups:
  29 │       - apps
  30 │     resources:
  31 │       - statefulsets
  32 │     verbs:
  33 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role82.yaml:34-40
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - ""
  36 │     resources:
  37 │       - configmaps
  38 │       - secrets
  39 │     verbs:
  40 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role82.yaml:28-33
────────────────────────────────────────
  28 ┌   - apiGroups:
  29 │       - apps
  30 │     resources:
  31 │       - statefulsets
  32 │     verbs:
  33 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role82.yaml:41-47
────────────────────────────────────────
  41 ┌   - apiGroups:
  42 │       - ""
  43 │     resources:
  44 │       - pods
  45 │     verbs:
  46 │       - list
  47 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role82.yaml:34-40
────────────────────────────────────────
  34 ┌   - apiGroups:
  35 │       - ""
  36 │     resources:
  37 │       - configmaps
  38 │       - secrets
  39 │     verbs:
  40 └       - "*"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role82.yaml:48-58
────────────────────────────────────────
  48 ┌   - apiGroups:
  49 │       - ""
  50 │     resources:
  51 │       - services
  52 │       - services/finalizers
  53 │       - endpoints
  54 │     verbs:
  55 │       - get
  56 └       - create
  ..   
────────────────────────────────────────



cluster-role83.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role83.yaml:9-26
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - configmaps
  13 │       - secrets
  14 │       - nodes
  15 │       - pods
  16 │       - services
  17 └       - resourcequotas
  ..   
────────────────────────────────────────



cluster-role86.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role86.yaml:30-36
────────────────────────────────────────
  30 ┌   - apiGroups:
  31 │       - ""
  32 │     resources:
  33 │       - configmaps
  34 │       - secrets
  35 │     verbs:
  36 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role86.yaml:24-29
────────────────────────────────────────
  24 ┌   - apiGroups:
  25 │       - apps
  26 │     resources:
  27 │       - statefulsets
  28 │     verbs:
  29 └       - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role86.yaml:30-36
────────────────────────────────────────
  30 ┌   - apiGroups:
  31 │       - ""
  32 │     resources:
  33 │       - configmaps
  34 │       - secrets
  35 │     verbs:
  36 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role86.yaml:24-29
────────────────────────────────────────
  24 ┌   - apiGroups:
  25 │       - apps
  26 │     resources:
  27 │       - statefulsets
  28 │     verbs:
  29 └       - "*"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role86.yaml:37-43
────────────────────────────────────────
  37 ┌   - apiGroups:
  38 │       - ""
  39 │     resources:
  40 │       - pods
  41 │     verbs:
  42 │       - list
  43 └       - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role86.yaml:30-36
────────────────────────────────────────
  30 ┌   - apiGroups:
  31 │       - ""
  32 │     resources:
  33 │       - configmaps
  34 │       - secrets
  35 │     verbs:
  36 └       - "*"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role86.yaml:44-54
────────────────────────────────────────
  44 ┌   - apiGroups:
  45 │       - ""
  46 │     resources:
  47 │       - services
  48 │       - services/finalizers
  49 │       - endpoints
  50 │     verbs:
  51 │       - get
  52 └       - create
  ..   
────────────────────────────────────────



cluster-role88.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role88.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role9.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role9.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role90.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role90.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role92.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role92.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role92.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role92.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role92.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role92.yaml:41-47
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - pods
  45 │   verbs:
  46 │   - list
  47 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role92.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role92.yaml:48-58
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ""
  50 │   resources:
  51 │   - services
  52 │   - services/finalizers
  53 │   - endpoints
  54 │   verbs:
  55 │   - get
  56 └   - create
  ..   
────────────────────────────────────────



cluster-role94.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role94.yaml:6-23
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - secrets
  11 │   - nodes
  12 │   - pods
  13 │   - services
  14 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-role97.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'prometheus-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role97.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role97.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 cluster-role97.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role97.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   resources:
  31 │   - statefulsets
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 cluster-role97.yaml:41-47
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - pods
  45 │   verbs:
  46 │   - list
  47 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'prometheus-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster-role97.yaml:34-40
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - ""
  36 │   resources:
  37 │   - configmaps
  38 │   - secrets
  39 │   verbs:
  40 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'prometheus-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 cluster-role97.yaml:48-58
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ""
  50 │   resources:
  51 │   - services
  52 │   - services/finalizers
  53 │   - endpoints
  54 │   verbs:
  55 │   - get
  56 └   - create
  ..   
────────────────────────────────────────



cluster-role98.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster-role98.yaml:9-26
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ""
  11 │   resources:
  12 │   - configmaps
  13 │   - secrets
  14 │   - nodes
  15 │   - pods
  16 │   - services
  17 └   - resourcequotas
  ..   
────────────────────────────────────────



cluster-rolebinding.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-admin-binding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 cluster-rolebinding.yaml:4
────────────────────────────────────────
   4 [   name: cluster-admin-binding
────────────────────────────────────────



cluster-user_1.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'loja-admin' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 cluster-user_1.yaml:4
────────────────────────────────────────
   4 [   name: loja-admin
────────────────────────────────────────



cluster-vars1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'cluster-vars' in 'flux-system' namespace stores sensitive contents in key(s) or value(s) '{"ipv6LbPrefix"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



cluster-vars2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'cluster-vars' in 'flux-system' namespace stores sensitive contents in key(s) or value(s) '{"ipv6LbPrefix"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



cluster-vars3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'cluster-vars' in 'flux-system' namespace stores sensitive contents in key(s) or value(s) '{"ipv6LbPrefix", "rgwPort"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



cluster-viewer.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'cluster-role-test-viewer' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 cluster-viewer.yaml:15-22
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - chaos-mesh.org
  17 │   resources:
  18 │   - '*'
  19 │   verbs:
  20 │   - get
  21 │   - list
  22 └   - watch
────────────────────────────────────────



cluster1100_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rebel-base' of 'deployment' 'rebel-base' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rebel-base" of deployment "rebel-base" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rebel-base in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster1100_1.yaml:4
────────────────────────────────────────
   4 [   name: rebel-base
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rebel-base in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rebel-base in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1100_1.yaml:15-36
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 └             path: /
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rebel-base in deployment rebel-base (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster1100_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────



cluster1100_3.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'x-wing-container' of 'deployment' 'x-wing' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "x-wing-container" of deployment "x-wing" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment x-wing in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster1100_3.yaml:4
────────────────────────────────────────
   4 [   name: x-wing
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container x-wing in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment x-wing in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1100_3.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 └             - -o
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container x-wing-container in deployment x-wing (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster1100_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────



cluster1103_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rebel-base' of 'deployment' 'rebel-base' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rebel-base" of deployment "rebel-base" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rebel-base in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster1103_1.yaml:4
────────────────────────────────────────
   4 [   name: rebel-base
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rebel-base in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rebel-base in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1103_1.yaml:15-36
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 └             path: /
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rebel-base in deployment rebel-base (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster1103_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────



cluster1103_3.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'x-wing-container' of 'deployment' 'x-wing' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "x-wing-container" of deployment "x-wing" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment x-wing in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster1103_3.yaml:4
────────────────────────────────────────
   4 [   name: x-wing
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container x-wing in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment x-wing in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster1103_3.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 └             - -o
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container x-wing-container in deployment x-wing (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster1103_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────



cluster112.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secret-reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 cluster112.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - list
────────────────────────────────────────



cluster233_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rebel-base' of 'deployment' 'rebel-base' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rebel-base" of deployment "rebel-base" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rebel-base in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster233_1.yaml:4
────────────────────────────────────────
   4 [   name: rebel-base
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rebel-base in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rebel-base in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster233_1.yaml:15-36
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 └             path: /
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rebel-base in deployment rebel-base (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster233_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────



cluster233_3.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'x-wing-container' of 'deployment' 'x-wing' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "x-wing-container" of deployment "x-wing" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment x-wing in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster233_3.yaml:4
────────────────────────────────────────
   4 [   name: x-wing
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container x-wing in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment x-wing in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster233_3.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 └             - -o
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container x-wing-container in deployment x-wing (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster233_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────



cluster263_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rebel-base' of 'deployment' 'rebel-base' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rebel-base' of Deployment 'rebel-base' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rebel-base" of deployment "rebel-base" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rebel-base in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster263_1.yaml:4
────────────────────────────────────────
   4 [   name: rebel-base
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rebel-base in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rebel-base in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster263_1.yaml:15-36
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 └             path: /
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rebel-base in deployment rebel-base (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster263_1.yaml:16-29
────────────────────────────────────────
  16 ┌       - name: rebel-base
  17 │         image: docker.io/nginx:1.15.8
  18 │         volumeMounts:
  19 │         - name: html
  20 │           mountPath: /usr/share/nginx/html/
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /
  24 └             port: 80
  ..   
────────────────────────────────────────



cluster263_3.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'x-wing-container' of 'deployment' 'x-wing' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "x-wing-container" of deployment "x-wing" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment x-wing in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster263_3.yaml:4
────────────────────────────────────────
   4 [   name: x-wing
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container x-wing in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment x-wing in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster263_3.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 └             - -o
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container x-wing-container in deployment x-wing (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster263_3.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────



cluster264_4.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'cri-o-metrics-exporter' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 cluster264_4.yaml:9-16
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ''
  11 │   resources:
  12 │   - configmaps
  13 │   verbs:
  14 │   - get
  15 │   - create
  16 └   - update
────────────────────────────────────────



cluster264_6.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 101, FAILURES: 14)
Failures: 14 (UNKNOWN: 0, LOW: 6, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'cri-o-metrics-exporter' of 'deployment' 'cri-o-metrics-exporter' in 'cri-o-metrics-exporter' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'cri-o-metrics-exporter' of Deployment 'cri-o-metrics-exporter' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "cri-o-metrics-exporter" of deployment "cri-o-metrics-exporter" in "cri-o-metrics-exporter" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container cri-o-metrics-exporter in cri-o-metrics-exporter namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment cri-o-metrics-exporter in cri-o-metrics-exporter namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster264_6.yaml:19-37
────────────────────────────────────────
  19 ┌       serviceAccountName: cri-o-metrics-exporter
  20 │       containers:
  21 │       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 └         - name: POD_NAMESPACE
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container cri-o-metrics-exporter in deployment cri-o-metrics-exporter (namespace: cri-o-metrics-exporter) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster264_6.yaml:21-37
────────────────────────────────────────
  21 ┌       - name: cri-o-metrics-exporter
  22 │         image: quay.io/crio/metrics-exporter:latest
  23 │         imagePullPolicy: Always
  24 │         env:
  25 │         - name: CRIO_METRICS_PORT
  26 │           value: '9090'
  27 │         - name: POD_NAMESPACE
  28 │           valueFrom:
  29 └             fieldRef:
  ..   
────────────────────────────────────────



cluster312.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'x-wing-container' of 'deployment' 'x-wing' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'x-wing-container' of Deployment 'x-wing' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "x-wing-container" of deployment "x-wing" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment x-wing in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster312.yaml:4
────────────────────────────────────────
   4 [   name: x-wing
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container x-wing in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment x-wing in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster312.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 └             - -o
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container x-wing-container in deployment x-wing (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 cluster312.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: x-wing-container
  17 │         image: quay.io/cilium/json-mock:v1.3.3@sha256:f26044a2b8085fcaa8146b6b8bb73556134d7ec3d5782c6a04a058c945924ca0
  18 │         livenessProbe:
  19 │           exec:
  20 │             command:
  21 │             - curl
  22 │             - -sS
  23 │             - -o
  24 └             - /dev/null
  ..   
────────────────────────────────────────



cluster323.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'deployment' 'nginx-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx' of Deployment 'nginx-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of deployment "nginx-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment nginx-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 cluster323.yaml:4
────────────────────────────────────────
   4 [   name: nginx-deployment
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment nginx-deployment in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nginx-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster323.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment nginx-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 cluster323.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: nginx
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────



clusterIP16.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Pod 'nginx' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Pod 'nginx' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'pod' 'nginx' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Pod 'nginx' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Pod 'nginx' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Pod 'nginx' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Pod 'nginx' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Pod 'nginx' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Pod 'nginx' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Pod 'nginx' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Pod 'nginx' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of pod "nginx" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nginx in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterIP16.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nginx
   5 │   labels:
   6 └     name: nginx
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod nginx in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nginx in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterIP16.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nginx in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterIP16.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nginx
  10 │     image: nginx:1.14.2
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────



clusterIP16_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'centos' of Pod 'debug' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'centos' of Pod 'debug' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'centos' of 'pod' 'debug' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'centos' of Pod 'debug' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'centos' of Pod 'debug' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'centos' of Pod 'debug' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'centos' of Pod 'debug' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'centos' of Pod 'debug' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'centos' of Pod 'debug' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'centos' of Pod 'debug' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'centos' of Pod 'debug' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "centos" of pod "debug" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod debug in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterIP16_1.yaml:4-6
────────────────────────────────────────
   4 ┌   name: debug
   5 │   labels:
   6 └     name: debug
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container debug in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod debug in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterIP16_1.yaml:8-10
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container centos in pod debug (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterIP16_1.yaml:9-10
────────────────────────────────────────
   9 ┌   - name: centos
  10 └     image: rkalluru/debug:centos8
────────────────────────────────────────



clusterRole12.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole12.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole13.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole13.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole134.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole134.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole14.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole14.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole19.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole19.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole20.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole20.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole201.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole201.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole205.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole205.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole206.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterRole206.yaml:10-27
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - configmaps
  14 │   - secrets
  15 │   - nodes
  16 │   - pods
  17 │   - services
  18 └   - resourcequotas
  ..   
────────────────────────────────────────



clusterRole260.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole260.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole29.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole29.yaml:7-14
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs: ["get", "list", "watch"]
────────────────────────────────────────



clusterRole320.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'cluster-reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterRole320.yaml:7-16
────────────────────────────────────────
   7 ┌ - apiGroup:
   8 │   - ''
   9 │   resources:
  10 │   - secrets
  11 │   - nodes
  12 │   - persistentVolume
  13 │   verbs:
  14 │   - get
  15 │   - watch
  16 └   - list
────────────────────────────────────────



clusterRole323.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole323.yaml:6-22
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   - namespaces
  ..   
────────────────────────────────────────



clusterRole355.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole355.yaml:6-21
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - nodes/metrics
  12 │   - services
  13 │   - endpoints
  14 └   - pods
  ..   
────────────────────────────────────────



clusterRole384.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole384.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole398.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole398.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole431.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole431.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole441.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole441.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole442.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterRole442.yaml:10-27
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - configmaps
  14 │       - secrets
  15 │       - nodes
  16 │       - pods
  17 │       - services
  18 └       - resourcequotas
  ..   
────────────────────────────────────────



clusterRole45.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole45.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole454.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole454.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole486.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole486.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole488.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole488.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole516.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole516.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole56.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole56.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole59.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole59.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterRole60.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterRole60.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusteradmin.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-read-custom-juno' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 clusteradmin.yaml:4
────────────────────────────────────────
   4 [   name: cluster-read-custom-juno
────────────────────────────────────────



clusterip-example_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Pod 'clusterip-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Pod 'clusterip-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'pod' 'clusterip-pod' in 'clusterip-app' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Pod 'clusterip-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Pod 'clusterip-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Pod 'clusterip-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Pod 'clusterip-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Pod 'clusterip-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Pod 'clusterip-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Pod 'clusterip-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Pod 'clusterip-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of pod "clusterip-pod" in "clusterip-app" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod clusterip-pod in clusterip-app namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterip-pod in clusterip-app namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-example_1.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod clusterip-pod in clusterip-app namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-example_1.yaml:9-14
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: nginx
  11 │     image: nginx:stable
  12 │     ports:
  13 │     - containerPort: 80
  14 └       name: http-web-svc
────────────────────────────────────────



clusterip-service5_1.yaml (kubernetes)
======================================
Tests: 131 (SUCCESSES: 97, FAILURES: 34)
Failures: 34 (UNKNOWN: 0, LOW: 20, MEDIUM: 9, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web-server-apache' of Pod 'web-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web-server-apache' of 'pod' 'web-pod' in 'exercicio-clusterip' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web-server-tomcat' of 'pod' 'web-pod' in 'exercicio-clusterip' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web-server-apache" of pod "web-pod" in "exercicio-clusterip" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web-server-tomcat" of pod "web-pod" in "exercicio-clusterip" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod web-pod in exercicio-clusterip namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container web-pod in exercicio-clusterip namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service5_1.yaml:10-13
────────────────────────────────────────
  10 ┌   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container web-pod in exercicio-clusterip namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service5_1.yaml:14-17
────────────────────────────────────────
  14 ┌   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod web-pod in exercicio-clusterip namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service5_1.yaml:9-17
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: web-server-apache
  11 │     image: httpd
  12 │     ports:
  13 │     - containerPort: 80
  14 │   - name: web-server-tomcat
  15 │     image: tomcat
  16 │     ports:
  17 └     - containerPort: 8080
────────────────────────────────────────



clusterip-service6.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'my-container' of Deployment 'my-deployment-cip' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'my-container' of 'deployment' 'my-deployment-cip' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'my-container' of Deployment 'my-deployment-cip' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'my-container' of Deployment 'my-deployment-cip' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'my-container' of Deployment 'my-deployment-cip' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'my-container' of Deployment 'my-deployment-cip' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "my-container" of deployment "my-deployment-cip" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment my-deployment-cip in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip-service6.yaml:4
────────────────────────────────────────
   4 [   name: my-deployment-cip
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment my-deployment-cip in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container my-deployment-cip in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment my-deployment-cip in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service6.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: my-container
  17 │         image: nginx:latest
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────



clusterip-service8.yaml (kubernetes)
====================================
Tests: 131 (SUCCESSES: 96, FAILURES: 35)
Failures: 35 (UNKNOWN: 0, LOW: 21, MEDIUM: 9, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web-server-apache' of Pod 'web-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web-server-apache' of 'pod' 'web-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web-server-tomcat' of 'pod' 'web-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web-server-apache" of pod "web-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web-server-tomcat" of pod "web-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod web-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip-service8.yaml:4-6
────────────────────────────────────────
   4 ┌   name: web-pod
   5 │   labels:
   6 └     type: web-app
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod web-pod in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container web-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service8.yaml:13-16
────────────────────────────────────────
  13 ┌   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container web-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service8.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod web-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service8.yaml:8-16
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: web-server-apache
  10 │     image: httpd
  11 │     ports:
  12 │     - containerPort: 80
  13 │   - name: web-server-tomcat
  14 │     image: tomcat
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────



clusterip-service9.yaml (kubernetes)
====================================
Tests: 129 (SUCCESSES: 98, FAILURES: 31)
Failures: 31 (UNKNOWN: 0, LOW: 17, MEDIUM: 9, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web-server-apache' of Pod 'web-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web-server-apache' of 'pod' 'web-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'web-server-tomcat' of 'pod' 'web-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'web-server-apache' of Pod 'web-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'web-server-tomcat' of Pod 'web-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web-server-apache' of Pod 'web-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'web-server-tomcat' of Pod 'web-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web-server-apache" of pod "web-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "web-server-tomcat" of pod "web-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod web-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip-service9.yaml:4-6
────────────────────────────────────────
   4 ┌   name: web-pod
   5 │   labels:
   6 └     type: web-app
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod web-pod in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container web-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service9.yaml:17-24
────────────────────────────────────────
  17 ┌   - name: web-server-tomcat
  18 │     image: tomcat
  19 │     resources:
  20 │       limits:
  21 │         memory: 128Mi
  22 │         cpu: 500m
  23 │     ports:
  24 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container web-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service9.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod web-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip-service9.yaml:8-24
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: web-server-apache
  10 │     image: httpd
  11 │     resources:
  12 │       limits:
  13 │         memory: 128Mi
  14 │         cpu: 500m
  15 │     ports:
  16 └     - containerPort: 80
  ..   
────────────────────────────────────────



clusterip10.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apache' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apache' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apache" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip10.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydeployments in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip10.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip10.yaml:16-20
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────



clusterip10_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'myapl' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'myapl' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "myapl" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip10_1.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip10_1.yaml:16-18
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container myapl in deployment mydeployments (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip10_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────



clusterip10_4.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nodeapp' of Pod 'nodeapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nodeapp' of 'pod' 'nodeapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nodeapp" of pod "nodeapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nodeapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip10_4.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nodeapp
   5 │   labels:
   6 └     app: nodeapp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nodeapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nodeapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip10_4.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nodeapp in pod nodeapp (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip10_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────



clusterip11.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apache' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apache' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apache" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip11.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydeployments in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip11.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip11.yaml:16-20
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────



clusterip11_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'myapl' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'myapl' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "myapl" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip11_1.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip11_1.yaml:16-18
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container myapl in deployment mydeployments (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip11_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────



clusterip11_4.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nodeapp' of Pod 'nodeapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nodeapp' of 'pod' 'nodeapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nodeapp" of pod "nodeapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nodeapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip11_4.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nodeapp
   5 │   labels:
   6 └     app: nodeapp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nodeapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nodeapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip11_4.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nodeapp in pod nodeapp (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip11_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────



clusterip13.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apache' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apache' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apache" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip13.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydeployments in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip13.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip13.yaml:16-20
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────



clusterip13_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'myapl' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'myapl' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "myapl" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip13_1.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip13_1.yaml:16-18
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container myapl in deployment mydeployments (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip13_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────



clusterip13_4.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nodeapp' of Pod 'nodeapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nodeapp' of 'pod' 'nodeapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nodeapp" of pod "nodeapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nodeapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip13_4.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nodeapp
   5 │   labels:
   6 └     app: nodeapp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nodeapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nodeapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip13_4.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nodeapp in pod nodeapp (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip13_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────



clusterip17_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'openfaas-figlet' of 'deployment' 'openfaas-figlet' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "openfaas-figlet" of deployment "openfaas-figlet" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment openfaas-figlet in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip17_1.yaml:4-6
────────────────────────────────────────
   4 ┌   name: openfaas-figlet
   5 │   labels:
   6 └     app: openfaas-figlet
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment openfaas-figlet in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container openfaas-figlet in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip17_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment openfaas-figlet in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip17_1.yaml:17-23
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────



clusterip2.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apache' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apache' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apache" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip2.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydeployments in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip2.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip2.yaml:16-20
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────



clusterip22.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Deployment 'clusterip-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'deployment' 'clusterip-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Deployment 'clusterip-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx' of Deployment 'clusterip-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Deployment 'clusterip-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Deployment 'clusterip-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of deployment "clusterip-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment clusterip-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip22.yaml:4-6
────────────────────────────────────────
   4 ┌   name: clusterip-deployment
   5 │   labels:
   6 └     app: clusterip-app
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment clusterip-deployment in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterip-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip22.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterip-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip22.yaml:17-21
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: nginx
  19 │         image: nginx
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────



clusterip27_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'openfaas-figlet' of 'deployment' 'openfaas-figlet' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "openfaas-figlet" of deployment "openfaas-figlet" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment openfaas-figlet in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip27_1.yaml:4-6
────────────────────────────────────────
   4 ┌   name: openfaas-figlet
   5 │   labels:
   6 └     app: openfaas-figlet
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment openfaas-figlet in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container openfaas-figlet in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip27_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment openfaas-figlet in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip27_1.yaml:17-23
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────



clusterip2_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'myapl' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'myapl' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "myapl" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip2_1.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip2_1.yaml:16-18
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container myapl in deployment mydeployments (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip2_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────



clusterip2_4.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nodeapp' of Pod 'nodeapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nodeapp' of 'pod' 'nodeapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nodeapp" of pod "nodeapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nodeapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip2_4.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nodeapp
   5 │   labels:
   6 └     app: nodeapp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nodeapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nodeapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip2_4.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nodeapp in pod nodeapp (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip2_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────



clusterip30_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'openfaas-figlet' of 'deployment' 'openfaas-figlet' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'openfaas-figlet' of Deployment 'openfaas-figlet' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "openfaas-figlet" of deployment "openfaas-figlet" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment openfaas-figlet in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip30_1.yaml:4-6
────────────────────────────────────────
   4 ┌   name: openfaas-figlet
   5 │   labels:
   6 └     app: openfaas-figlet
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment openfaas-figlet in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container openfaas-figlet in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip30_1.yaml:18-23
────────────────────────────────────────
  18 ┌       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment openfaas-figlet in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip30_1.yaml:17-23
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: openfaas-figlet
  19 │         image: httpd:latest
  20 │         imagePullPolicy: Always
  21 │         ports:
  22 │         - containerPort: 80
  23 └           protocol: TCP
────────────────────────────────────────



clusterip39.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 95, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Deployment 'test-clusterip' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'deployment' 'test-clusterip' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx' of Deployment 'test-clusterip' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of deployment "test-clusterip" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment test-clusterip in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip39.yaml:4
────────────────────────────────────────
   4 [   name: test-clusterip
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment test-clusterip in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test-clusterip in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment test-clusterip in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip39.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nginx in deployment test-clusterip (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip39.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────



clusterip40.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Deployment 'test-clusterip' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'deployment' 'test-clusterip' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Deployment 'test-clusterip' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of deployment "test-clusterip" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment test-clusterip in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip40.yaml:4
────────────────────────────────────────
   4 [   name: test-clusterip
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test-clusterip in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment test-clusterip in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip40.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nginx in deployment test-clusterip (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip40.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx
  17 │         image: ranchertest/mytestcontainer:unprivileged
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────



clusterip43.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 101, FAILURES: 14)
Failures: 14 (UNKNOWN: 0, LOW: 6, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'webcon2' of Pod 'webapp2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'webcon2' of Pod 'webapp2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'webcon2' of 'pod' 'webapp2' in 'devproject' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'webcon2' of Pod 'webapp2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'webcon2' of Pod 'webapp2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'webcon2' of Pod 'webapp2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'webcon2' of Pod 'webapp2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "webcon2" of pod "webapp2" in "devproject" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod webapp2 in devproject namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container webapp2 in devproject namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod webapp2 in devproject namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip43.yaml:10-24
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 └     resources:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container webcon2 in pod webapp2 (namespace: devproject) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip43.yaml:11-24
────────────────────────────────────────
  11 ┌   - name: webcon2
  12 │     image: sudarshanlnx/farmfresh:v1
  13 │     imagePullPolicy: Always
  14 │     ports:
  15 │     - containerPort: 80
  16 │       name: apache
  17 │       protocol: TCP
  18 │     resources:
  19 └       requests:
  ..   
────────────────────────────────────────



clusterip5.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apache' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apache' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apache" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip5.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydeployments in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip5.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip5.yaml:16-20
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────



clusterip5_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'myapl' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'myapl' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "myapl" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip5_1.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip5_1.yaml:16-18
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container myapl in deployment mydeployments (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip5_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────



clusterip5_4.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nodeapp' of Pod 'nodeapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nodeapp' of 'pod' 'nodeapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nodeapp" of pod "nodeapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nodeapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip5_4.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nodeapp
   5 │   labels:
   6 └     app: nodeapp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nodeapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nodeapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip5_4.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nodeapp in pod nodeapp (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip5_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────



clusterip8.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'front' of Deployment 'front' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'front' of Deployment 'front' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'front' of 'deployment' 'front' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'front' of Deployment 'front' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'front' of Deployment 'front' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'front' of Deployment 'front' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'front' of Deployment 'front' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'front' of Deployment 'front' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'front' of Deployment 'front' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'front' of Deployment 'front' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'front' of Deployment 'front' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'front' of Deployment 'front' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "front" of deployment "front" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment front in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip8.yaml:4
────────────────────────────────────────
   4 [   name: front
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container front in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip8.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: front
  17 └         image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment front in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip8.yaml:15-17
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: front
  17 └         image: nginx
────────────────────────────────────────



clusterip9.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apache' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apache' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apache' of Deployment 'mydeployments' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apache' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apache" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip9.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment mydeployments in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip9.yaml:17-20
────────────────────────────────────────
  17 ┌       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip9.yaml:16-20
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: apache
  18 │         image: httpd
  19 │         ports:
  20 └         - containerPort: 80
────────────────────────────────────────



clusterip9_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'myapl' of Deployment 'mydeployments' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'myapl' of 'deployment' 'mydeployments' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'myapl' of Deployment 'mydeployments' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "myapl" of deployment "mydeployments" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment mydeployments in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip9_1.yaml:4
────────────────────────────────────────
   4 [   name: mydeployments
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mydeployments in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment mydeployments in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip9_1.yaml:16-18
────────────────────────────────────────
  16 ┌       containers:
  17 │       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container myapl in deployment mydeployments (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip9_1.yaml:17-18
────────────────────────────────────────
  17 ┌       - name: myapl
  18 └         image: amiyaranjansahoo/myapp:v1
────────────────────────────────────────



clusterip9_4.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nodeapp' of Pod 'nodeapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nodeapp' of 'pod' 'nodeapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nodeapp' of Pod 'nodeapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nodeapp" of pod "nodeapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod nodeapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterip9_4.yaml:4-6
────────────────────────────────────────
   4 ┌   name: nodeapp
   5 │   labels:
   6 └     app: nodeapp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nodeapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod nodeapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterip9_4.yaml:8-12
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nodeapp in pod nodeapp (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterip9_4.yaml:9-12
────────────────────────────────────────
   9 ┌   - name: nodeapp
  10 │     image: kammana/nodeapp:v1
  11 │     ports:
  12 └     - containerPort: 8080
────────────────────────────────────────



clusternet_agent_deployment_4.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusternet-agent' of 'deployment' 'clusternet-agent' in 'clusternet-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusternet-agent' of Deployment 'clusternet-agent' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusternet-agent" of deployment "clusternet-agent" in "clusternet-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusternet-agent in clusternet-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusternet-agent in clusternet-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:18-53
────────────────────────────────────────
  18 ┌       serviceAccountName: clusternet-agent
  19 │       tolerations:
  20 │       - key: node-role.kubernetes.io/master
  21 │         operator: Exists
  22 │       containers:
  23 │       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusternet-agent in deployment clusternet-agent (namespace: clusternet-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusternet_agent_deployment_4.yaml:23-53
────────────────────────────────────────
  23 ┌       - name: clusternet-agent
  24 │         image: ghcr.io/clusternet/clusternet-agent:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: PARENT_URL
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 │               name: clusternet-agent-cluster-registration
  31 └               key: parentURL
  ..   
────────────────────────────────────────



clusternet_agent_rbac.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusternet_agent_rbac.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'clusternet:agent:admin' shouldn't manage all resources at the namespace 'clusternet-system'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 clusternet_agent_rbac.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



clusternet_agent_rbac_4.yaml (kubernetes)
=========================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'clusternet:app:deployer' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 clusternet_agent_rbac_4.yaml:4
────────────────────────────────────────
   4 [   name: clusternet:app:deployer
────────────────────────────────────────



clusternet_controller_manager_deployment_3.yaml (kubernetes)
============================================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusternet-controller-manager' of 'deployment' 'clusternet-controller-manager' in 'clusternet-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusternet-controller-manager' of Deployment 'clusternet-controller-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0023 (MEDIUM): Deployment 'clusternet-controller-manager' should not set 'spec.template.volumes.hostPath'
════════════════════════════════════════
According to pod security standard 'HostPath Volumes', HostPath volumes must be forbidden.

See https://avd.aquasec.com/misconfig/ksv023
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:9-56
────────────────────────────────────────
   9 ┌   replicas: 3
  10 │   selector:
  11 │     matchLabels:
  12 │       app: clusternet-controller-manager
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app: clusternet-controller-manager
  17 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusternet-controller-manager" of deployment "clusternet-controller-manager" in "clusternet-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusternet-controller-manager in clusternet-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusternet-controller-manager in clusternet-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:18-56
────────────────────────────────────────
  18 ┌       serviceAccountName: clusternet-controller-manager
  19 │       volumes:
  20 │       - hostPath:
  21 │           path: /etc/clusternet
  22 │           type: DirectoryOrCreate
  23 │         name: clusternet
  24 │       tolerations:
  25 │       - key: node-role.kubernetes.io/master
  26 └         operator: Exists
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusternet-controller-manager in deployment clusternet-controller-manager (namespace: clusternet-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusternet_controller_manager_deployment_3.yaml:28-56
────────────────────────────────────────
  28 ┌       - name: clusternet-controller-manager
  29 │         image: ghcr.io/clusternet/clusternet-controller-manager:v0.16.0
  30 │         imagePullPolicy: IfNotPresent
  31 │         env:
  32 │         - name: SYSTEM_NAMESPACE
  33 │           valueFrom:
  34 │             fieldRef:
  35 │               apiVersion: v1
  36 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────



clusternet_controller_manager_rbac.yaml (kubernetes)
====================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'clusternet:controller-manager' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 clusternet_controller_manager_rbac.yaml:4
────────────────────────────────────────
   4 [   name: clusternet:controller-manager
────────────────────────────────────────



clusternet_hub_deployment_7.yaml (kubernetes)
=============================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusternet-hub' of 'deployment' 'clusternet-hub' in 'clusternet-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusternet-hub' of Deployment 'clusternet-hub' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusternet-hub" of deployment "clusternet-hub" in "clusternet-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment clusternet-hub in clusternet-system namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusternet-hub in clusternet-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusternet-hub in clusternet-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:18-48
────────────────────────────────────────
  18 ┌       serviceAccountName: clusternet-hub
  19 │       tolerations:
  20 │       - key: node-role.kubernetes.io/master
  21 │         operator: Exists
  22 │       containers:
  23 │       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusternet-hub in deployment clusternet-hub (namespace: clusternet-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusternet_hub_deployment_7.yaml:23-48
────────────────────────────────────────
  23 ┌       - name: clusternet-hub
  24 │         image: ghcr.io/clusternet/clusternet-hub:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               apiVersion: v1
  31 └               fieldPath: metadata.namespace
  ..   
────────────────────────────────────────



clusternet_hub_rbac.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'clusternet:hub' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 clusternet_hub_rbac.yaml:4
────────────────────────────────────────
   4 [   name: clusternet:hub
────────────────────────────────────────



clusternet_hub_rbac_1.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0056 (HIGH): Role 'mcs-syncer' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusternet_hub_rbac_1.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - discovery.k8s.io
   9 │   resources:
  10 │   - endpointslices
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



clusternet_scheduler_deployment_2.yaml (kubernetes)
===================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusternet-scheduler' of 'deployment' 'clusternet-scheduler' in 'clusternet-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusternet-scheduler' of Deployment 'clusternet-scheduler' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusternet-scheduler" of deployment "clusternet-scheduler" in "clusternet-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusternet-scheduler in clusternet-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusternet-scheduler in clusternet-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:18-36
────────────────────────────────────────
  18 ┌       serviceAccountName: clusternet-scheduler
  19 │       tolerations:
  20 │       - key: node-role.kubernetes.io/master
  21 │         operator: Exists
  22 │       containers:
  23 │       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusternet-scheduler in deployment clusternet-scheduler (namespace: clusternet-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusternet_scheduler_deployment_2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: clusternet-scheduler
  24 │         image: ghcr.io/clusternet/clusternet-scheduler:v0.16.0
  25 │         imagePullPolicy: IfNotPresent
  26 │         env:
  27 │         - name: SYSTEM_NAMESPACE
  28 │           valueFrom:
  29 │             fieldRef:
  30 │               fieldPath: metadata.namespace
  31 └         command:
  ..   
────────────────────────────────────────



clusterpedia_apiserver_deployment1_2.yaml (kubernetes)
======================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apiserver' of 'deployment' 'clusterpedia-apiserver' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apiserver" of deployment "clusterpedia-apiserver" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-apiserver in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-apiserver in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:18-47
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 └         - -v=3
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container apiserver in deployment clusterpedia-apiserver (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_apiserver_deployment1_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────



clusterpedia_apiserver_deployment_2.yaml (kubernetes)
=====================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apiserver' of 'deployment' 'clusterpedia-apiserver' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apiserver' of Deployment 'clusterpedia-apiserver' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apiserver" of deployment "clusterpedia-apiserver" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-apiserver in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-apiserver in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:18-47
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 └         - -v=3
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container apiserver in deployment clusterpedia-apiserver (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_apiserver_deployment_2.yaml:19-39
────────────────────────────────────────
  19 ┌       - name: apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/apiserver:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/apiserver
  23 │         - --secure-port=443
  24 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  25 │         - --tracing-config-file=/etc/clusterpedia/trace/tracing-config.yaml
  26 │         - -v=3
  27 └         env:
  ..   
────────────────────────────────────────



clusterpedia_apiserver_rbac.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterpedia_apiserver_rbac.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'clusterpedia' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterpedia_apiserver_rbac.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterpedia_binding_apiserver_deployment_2.yaml (kubernetes)
=============================================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'binding-apiserver' of 'deployment' 'clusterpedia-binding-apiserver' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'binding-apiserver' of Deployment 'clusterpedia-binding-apiserver' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "binding-apiserver" of deployment "clusterpedia-binding-apiserver" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-binding-apiserver in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-binding-apiserver in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:18-26
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 │         - -v=3
  26 └       serviceAccountName: clusterpedia-binding-apiserver
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container binding-apiserver in deployment clusterpedia-binding-apiserver (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_binding_apiserver_deployment_2.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: binding-apiserver
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/binding-apiserver:latest
  21 │         command:
  22 │         - /usr/local/bin/binding-apiserver
  23 │         - --secure-port=443
  24 │         - --storage-name=memory
  25 └         - -v=3
────────────────────────────────────────



clusterpedia_binding_apiserver_rbac.yaml (kubernetes)
=====================================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterpedia_binding_apiserver_rbac.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'clusterpedia' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterpedia_binding_apiserver_rbac.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterpedia_clustersynchro_manager_deployment1_1.yaml (kubernetes)
===================================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'manager' of 'deployment' 'clusterpedia-clustersynchro-manager' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "manager" of deployment "clusterpedia-clustersynchro-manager" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-clustersynchro-manager in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-clustersynchro-manager in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:18-39
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 └         - name: DB_PASSWORD
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment clusterpedia-clustersynchro-manager (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment1_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────



clusterpedia_clustersynchro_manager_deployment_1.yaml (kubernetes)
==================================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'manager' of 'deployment' 'clusterpedia-clustersynchro-manager' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'clusterpedia-clustersynchro-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "manager" of deployment "clusterpedia-clustersynchro-manager" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-clustersynchro-manager in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-clustersynchro-manager in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:18-39
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 └         - name: DB_PASSWORD
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment clusterpedia-clustersynchro-manager (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_clustersynchro_manager_deployment_1.yaml:19-34
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/clustersynchro-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/clustersynchro-manager
  23 │         - --storage-config=/etc/clusterpedia/storage/internalstorage-config.yaml
  24 │         - --feature-gates=PruneManagedFields=true,PruneLastAppliedConfiguration=true
  25 │         env:
  26 │         - name: DB_PASSWORD
  27 └           valueFrom:
  ..   
────────────────────────────────────────



clusterpedia_controller_manager_deployment1_1.yaml (kubernetes)
===============================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'manager' of 'deployment' 'clusterpedia-controller-manager' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "manager" of deployment "clusterpedia-controller-manager" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-controller-manager in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-controller-manager in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:18-23
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/controller-manager
  23 └       serviceAccountName: clusterpedia-controller-manager
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment clusterpedia-controller-manager (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_controller_manager_deployment1_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────



clusterpedia_controller_manager_deployment_1.yaml (kubernetes)
==============================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'manager' of 'deployment' 'clusterpedia-controller-manager' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'clusterpedia-controller-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "manager" of deployment "clusterpedia-controller-manager" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-controller-manager in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-controller-manager in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:18-23
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 │         - /usr/local/bin/controller-manager
  23 └       serviceAccountName: clusterpedia-controller-manager
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment clusterpedia-controller-manager (namespace: clusterpedia-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterpedia_controller_manager_deployment_1.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: manager
  20 │         image: ghcr.io/clusterpedia-io/clusterpedia/controller-manager:v0.8.0
  21 │         command:
  22 └         - /usr/local/bin/controller-manager
────────────────────────────────────────



clusterpedia_internalstorage_deployment1_2.yaml (kubernetes)
============================================================
Tests: 115 (SUCCESSES: 99, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 10, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'postgres' of 'deployment' 'clusterpedia-internalstorage-postgres' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "postgres" of deployment "clusterpedia-internalstorage-postgres" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-internalstorage-postgres in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-internalstorage-postgres in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment1_2.yaml:21-45
────────────────────────────────────────
  21 ┌       containers:
  22 │       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 └             secretKeyRef:
  ..   
────────────────────────────────────────



clusterpedia_internalstorage_deployment2_2.yaml (kubernetes)
============================================================
Tests: 115 (SUCCESSES: 99, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 10, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'mysql' of 'deployment' 'clusterpedia-internalstorage-mysql' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "mysql" of deployment "clusterpedia-internalstorage-mysql" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-internalstorage-mysql in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-internalstorage-mysql in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment2_2.yaml:21-47
────────────────────────────────────────
  21 ┌       containers:
  22 │       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 └         - name: MYSQL_ROOT_PASSWORD
  ..   
────────────────────────────────────────



clusterpedia_internalstorage_deployment3_2.yaml (kubernetes)
============================================================
Tests: 115 (SUCCESSES: 99, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 10, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'postgres' of 'deployment' 'clusterpedia-internalstorage-postgres' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'postgres' of Deployment 'clusterpedia-internalstorage-postgres' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "postgres" of deployment "clusterpedia-internalstorage-postgres" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-internalstorage-postgres in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:22-37
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: internalstorage-password
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-internalstorage-postgres in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment3_2.yaml:21-45
────────────────────────────────────────
  21 ┌       containers:
  22 │       - name: postgres
  23 │         image: postgres:12
  24 │         env:
  25 │         - name: POSTGRES_DB
  26 │           value: clusterpedia
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 └             secretKeyRef:
  ..   
────────────────────────────────────────



clusterpedia_internalstorage_deployment_2.yaml (kubernetes)
===========================================================
Tests: 115 (SUCCESSES: 99, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 10, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'mysql' of 'deployment' 'clusterpedia-internalstorage-mysql' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'mysql' of Deployment 'clusterpedia-internalstorage-mysql' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "mysql" of deployment "clusterpedia-internalstorage-mysql" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterpedia-internalstorage-mysql in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:22-39
────────────────────────────────────────
  22 ┌       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 │         - name: MYSQL_ROOT_PASSWORD
  30 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterpedia-internalstorage-mysql in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_deployment_2.yaml:21-47
────────────────────────────────────────
  21 ┌       containers:
  22 │       - name: mysql
  23 │         image: mysql:8
  24 │         args:
  25 │         - --default-authentication-plugin=mysql_native_password
  26 │         env:
  27 │         - name: MYSQL_DATABASE
  28 │           value: clusterpedia
  29 └         - name: MYSQL_ROOT_PASSWORD
  ..   
────────────────────────────────────────



clusterpedia_internalstorage_local_pv_check_job.yaml (kubernetes)
=================================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'check-dir' of 'job' 'check-__NODE_NAME__-mysql-local-pv-dir' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-mysql-local-pv-dir' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0023 (MEDIUM): Job 'check-__NODE_NAME__-mysql-local-pv-dir' should not set 'spec.template.volumes.hostPath'
════════════════════════════════════════
According to pod security standard 'HostPath Volumes', HostPath volumes must be forbidden.

See https://avd.aquasec.com/misconfig/ksv023
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:11-35
────────────────────────────────────────
  11 ┌   ttlSecondsAfterFinished: 600
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: clusterpedia-internalstorage
  16 │         internalstorage.clusterpedia.io/type: mysql
  17 │         job: check-node-local-pv-dir
  18 │     spec:
  19 └       restartPolicy: Never
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "check-dir" of job "check-__NODE_NAME__-mysql-local-pv-dir" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container check-__NODE_NAME__-mysql-local-pv-dir in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0118 (HIGH): job check-__NODE_NAME__-mysql-local-pv-dir in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job.yaml:19-35
────────────────────────────────────────
  19 ┌       restartPolicy: Never
  20 │       nodeName: __NODE_NAME__
  21 │       containers:
  22 │       - name: check-dir
  23 │         image: mysql:8
  24 │         command: ['sh', '-c', 'stat /var/lib/mysql']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/mysql
  ..   
────────────────────────────────────────



clusterpedia_internalstorage_local_pv_check_job1.yaml (kubernetes)
==================================================================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'check-dir' of 'job' 'check-__NODE_NAME__-postgres-local-pv-dir' in 'clusterpedia-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'check-dir' of Job 'check-__NODE_NAME__-postgres-local-pv-dir' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0023 (MEDIUM): Job 'check-__NODE_NAME__-postgres-local-pv-dir' should not set 'spec.template.volumes.hostPath'
════════════════════════════════════════
According to pod security standard 'HostPath Volumes', HostPath volumes must be forbidden.

See https://avd.aquasec.com/misconfig/ksv023
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:11-35
────────────────────────────────────────
  11 ┌   ttlSecondsAfterFinished: 600
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: clusterpedia-internalstorage
  16 │         internalstorage.clusterpedia.io/type: postgres
  17 │         job: check-node-local-pv-dir
  18 │     spec:
  19 └       restartPolicy: Never
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "check-dir" of job "check-__NODE_NAME__-postgres-local-pv-dir" in "clusterpedia-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container check-__NODE_NAME__-postgres-local-pv-dir in clusterpedia-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
────────────────────────────────────────


AVD-KSV-0118 (HIGH): job check-__NODE_NAME__-postgres-local-pv-dir in clusterpedia-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterpedia_internalstorage_local_pv_check_job1.yaml:19-35
────────────────────────────────────────
  19 ┌       restartPolicy: Never
  20 │       nodeName: __NODE_NAME__
  21 │       containers:
  22 │       - name: check-dir
  23 │         image: postgres:12
  24 │         command: ['sh', '-c', 'stat /var/lib/postgresql/data']
  25 │         volumeMounts:
  26 │         - name: pv-dir
  27 └           mountPath: /var/lib/postgresql/data
  ..   
────────────────────────────────────────



clusterpedia_synchro_rbac.yaml (kubernetes)
===========================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterpedia_synchro_rbac.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'clusterpedia-synchro' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterpedia_synchro_rbac.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterplex-orchestrator-config.yaml (kubernetes)
=================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'clusterplex-orchestrator-config' in 'default' namespace stores sensitive contents in key(s) or value(s) '{"LISTENING_PORT"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



clusterplex-orchestrator1.yaml (kubernetes)
===========================================
Tests: 115 (SUCCESSES: 101, FAILURES: 14)
Failures: 14 (UNKNOWN: 0, LOW: 7, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusterplex-orchestrator' of Deployment 'clusterplex-orchestrator' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusterplex-orchestrator' of Deployment 'clusterplex-orchestrator' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusterplex-orchestrator' of 'deployment' 'clusterplex-orchestrator' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusterplex-orchestrator' of Deployment 'clusterplex-orchestrator' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusterplex-orchestrator' of Deployment 'clusterplex-orchestrator' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusterplex-orchestrator' of Deployment 'clusterplex-orchestrator' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusterplex-orchestrator' of Deployment 'clusterplex-orchestrator' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusterplex-orchestrator" of deployment "clusterplex-orchestrator" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment clusterplex-orchestrator in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:4-7
────────────────────────────────────────
   4 ┌   name: clusterplex-orchestrator
   5 │   labels:
   6 │     app.kubernetes.io/instance: clusterplex
   7 └     app.kubernetes.io/name: orchestrator
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterplex-orchestrator in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterplex-orchestrator in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:23-65
────────────────────────────────────────
  23 ┌       nodeSelector: {}
  24 │       serviceAccountName: default
  25 │       automountServiceAccountToken: true
  26 │       dnsPolicy: ClusterFirst
  27 │       enableServiceLinks: true
  28 │       containers:
  29 │         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 └           imagePullPolicy: IfNotPresent
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusterplex-orchestrator in deployment clusterplex-orchestrator (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterplex-orchestrator1.yaml:29-65
────────────────────────────────────────
  29 ┌         - name: clusterplex-orchestrator
  30 │           image: ghcr.io/pabloromeo/clusterplex_orchestrator:1.4.11
  31 │           imagePullPolicy: IfNotPresent
  32 │           envFrom:
  33 │             - configMapRef:
  34 │                 name: clusterplex-orchestrator-config
  35 │           ports:
  36 │             - name: http
  37 └               containerPort: 3500
  ..   
────────────────────────────────────────



clusterplex-pms-config.yaml (kubernetes)
========================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'clusterplex-pms-config' in 'default' namespace stores sensitive contents in key(s) or value(s) '{"LOCAL_RELAY_PORT", "PGID", "PMS_PORT", "PUID"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



clusterplex-pms2.yaml (kubernetes)
==================================
Tests: 126 (SUCCESSES: 96, FAILURES: 30)
Failures: 30 (UNKNOWN: 0, LOW: 17, MEDIUM: 8, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusterplex-pms' of 'deployment' 'clusterplex-pms' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'set-transcode-permissions' of 'deployment' 'clusterplex-pms' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusterplex-pms' of Deployment 'clusterplex-pms' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'set-transcode-permissions' of Deployment 'clusterplex-pms' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusterplex-pms" of deployment "clusterplex-pms" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "set-transcode-permissions" of deployment "clusterplex-pms" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment clusterplex-pms in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterplex-pms2.yaml:4-7
────────────────────────────────────────
   4 ┌   name: clusterplex-pms
   5 │   labels:
   6 │     app.kubernetes.io/instance: clusterplex
   7 └     app.kubernetes.io/name: pms
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterplex-pms in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-pms2.yaml:29-38
────────────────────────────────────────
  29 ┌         - command:
  30 │           - sh
  31 │           - -c
  32 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  33 │             /transcode permissions"
  34 │           image: busybox:1.36.1
  35 │           name: set-transcode-permissions
  36 │           volumeMounts:
  37 │           - mountPath: /transcode
  38 └             name: transcode
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterplex-pms in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment clusterplex-pms in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-pms2.yaml:23-116
────────────────────────────────────────
  23 ┌       nodeSelector: {}
  24 │       serviceAccountName: default
  25 │       automountServiceAccountToken: true
  26 │       dnsPolicy: ClusterFirst
  27 │       enableServiceLinks: true
  28 │       initContainers:
  29 │         - command:
  30 │           - sh
  31 └           - -c
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusterplex-pms in deployment clusterplex-pms (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterplex-pms2.yaml:40-103
────────────────────────────────────────
  40 ┌         - name: clusterplex-pms
  41 │           image: linuxserver/plex:latest
  42 │           imagePullPolicy: Always
  43 │           env:
  44 │             - name: PLEX_CLAIM
  45 │               valueFrom:
  46 │                 secretKeyRef:
  47 │                   name: plex-claim-token
  48 └                   key: claim_token
  ..   
────────────────────────────────────────



clusterplex-worker-config.yaml (kubernetes)
===========================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'clusterplex-worker-config' in 'default' namespace stores sensitive contents in key(s) or value(s) '{"LISTENING_PORT", "PGID", "PUID", "STAT_CPU_INTERVAL"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



clusterplex-worker1.yaml (kubernetes)
=====================================
Tests: 141 (SUCCESSES: 96, FAILURES: 45)
Failures: 45 (UNKNOWN: 0, LOW: 27, MEDIUM: 11, HIGH: 7, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'clusterplex-worker' of 'statefulset' 'clusterplex-worker' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'set-codec-permissions' of 'statefulset' 'clusterplex-worker' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'set-transcode-permissions' of 'statefulset' 'clusterplex-worker' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'clusterplex-worker' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'set-codec-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'set-transcode-permissions' of StatefulSet 'clusterplex-worker' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "clusterplex-worker" of statefulset "clusterplex-worker" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "set-codec-permissions" of statefulset "clusterplex-worker" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "set-transcode-permissions" of statefulset "clusterplex-worker" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0110 (LOW): statefulset clusterplex-worker in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 clusterplex-worker1.yaml:4-7
────────────────────────────────────────
   4 ┌   name: clusterplex-worker
   5 │   labels:
   6 │     app.kubernetes.io/instance: clusterplex
   7 └     app.kubernetes.io/name: worker
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterplex-worker in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-worker1.yaml:41-50
────────────────────────────────────────
  41 ┌         - command:
  42 │           - sh
  43 │           - -c
  44 │           - chown -R 1000:1000 /transcode && chmod 0755 -R /transcode && echo "Configured
  45 │             /transcode permissions"
  46 │           image: busybox:1.36.1
  47 │           name: set-transcode-permissions
  48 │           volumeMounts:
  49 │           - mountPath: /transcode
  50 └             name: transcode
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterplex-worker in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container clusterplex-worker in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-worker1.yaml:31-40
────────────────────────────────────────
  31 ┌         - command:
  32 │           - sh
  33 │           - -c
  34 │           - chown -R 1000:1000 /codecs && chmod 0755 -R /codecs && echo "Configured /codecs
  35 │             permissions"
  36 │           image: busybox:1.36.1
  37 │           name: set-codec-permissions
  38 │           volumeMounts:
  39 │           - mountPath: /codecs
  40 └             name: codecs
────────────────────────────────────────


AVD-KSV-0118 (HIGH): statefulset clusterplex-worker in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 clusterplex-worker1.yaml:25-111
────────────────────────────────────────
  25 ┌       nodeSelector: {}
  26 │       serviceAccountName: default
  27 │       automountServiceAccountToken: true
  28 │       dnsPolicy: ClusterFirst
  29 │       enableServiceLinks: true
  30 │       initContainers:
  31 │         - command:
  32 │           - sh
  33 └           - -c
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container clusterplex-worker in statefulset clusterplex-worker (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 clusterplex-worker1.yaml:52-95
────────────────────────────────────────
  52 ┌         - name: clusterplex-worker
  53 │           image: linuxserver/plex:latest
  54 │           imagePullPolicy: Always
  55 │           envFrom:
  56 │             - configMapRef:
  57 │                 name: clusterplex-worker-config
  58 │           ports:
  59 │             - name: http
  60 └               containerPort: 3501
  ..   
────────────────────────────────────────



clusterrole-0.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'capi-kubeadm-bootstrap-manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-0.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ''
  10 │   resources:
  11 │   - configmaps
  12 │   - secrets
  13 │   verbs:
  14 │   - create
  15 │   - delete
  16 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'capi-kubeadm-bootstrap-manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole-0.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ''
  10 │   resources:
  11 │   - configmaps
  12 │   - secrets
  13 │   verbs:
  14 │   - create
  15 │   - delete
  16 └   - get
  ..   
────────────────────────────────────────



clusterrole-03.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'capo-manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-03.yaml:19-26
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ''
  21 │   resources:
  22 │   - secrets
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 └   - watch
────────────────────────────────────────



clusterrole-1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'capi-kubeadm-control-plane-manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-1.yaml:73-83
────────────────────────────────────────
  73 ┌ - apiGroups:
  74 │   - ''
  75 │   resources:
  76 │   - secrets
  77 │   verbs:
  78 │   - create
  79 │   - get
  80 │   - list
  81 └   - patch
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'capi-kubeadm-control-plane-manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole-1.yaml:29-42
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - bootstrap.cluster.x-k8s.io
  31 │   - controlplane.cluster.x-k8s.io
  32 │   - infrastructure.cluster.x-k8s.io
  33 │   resources:
  34 │   - '*'
  35 │   verbs:
  36 │   - create
  37 └   - delete
  ..   
────────────────────────────────────────



clusterrole-11.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'capi-manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-11.yaml:126-137
────────────────────────────────────────
 126 ┌ - apiGroups:
 127 │   - ''
 128 │   resources:
 129 │   - secrets
 130 │   verbs:
 131 │   - create
 132 │   - delete
 133 │   - get
 134 └   - list
 ...   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'capi-manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole-11.yaml:26-40
────────────────────────────────────────
  26 ┌ - apiGroups:
  27 │   - addons.cluster.x-k8s.io
  28 │   - bootstrap.cluster.x-k8s.io
  29 │   - controlplane.cluster.x-k8s.io
  30 │   - infrastructure.cluster.x-k8s.io
  31 │   resources:
  32 │   - '*'
  33 │   verbs:
  34 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'capi-manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole-11.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - get
 115 │   - list
 116 │   - patch
 117 │   - update
 118 └   - watch
────────────────────────────────────────



clusterrole-2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'orc-manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - get
  12 │   - list
  13 └   - watch
────────────────────────────────────────



clusterrole-core-star.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'clusterrole-core-star' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole-core-star.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - "*"
  10 │   verbs:
  11 │   - create
  12 │   - delete
  13 │   - get
  14 └   - list
  ..   
────────────────────────────────────────



clusterrole-cr-star.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole-cr-star.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - rbac.authorization.k8s.io
   8 │   resources:
   9 │   - clusterroles
  10 │   verbs:
  11 └   - "*"
────────────────────────────────────────



clusterrole-garnet-operator.yaml (kubernetes)
=============================================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole-garnet-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - configmaps/status
  11 │   - pods
  12 │   - pods/status
  13 │   - services
  14 └   - services/status
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'garnet-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole-garnet-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - configmaps/status
  11 │   - pods
  12 │   - pods/status
  13 │   - services
  14 └   - services/status
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'garnet-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole-garnet-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - configmaps/status
  11 │   - pods
  12 │   - pods/status
  13 │   - services
  14 └   - services/status
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'garnet-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole-garnet-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - configmaps/status
  11 │   - pods
  12 │   - pods/status
  13 │   - services
  14 └   - services/status
  ..   
────────────────────────────────────────



clusterrole-kcp-admin-maximal-permission-policy.yaml (kubernetes)
=================================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'system:kcp:apiexport:kcp-admin:maximal-permission-policy' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole-kcp-admin-maximal-permission-policy.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["tenancy.kcp.io"]
   7 │     verbs: ["*"]
   8 └     resources: ["*"]
────────────────────────────────────────



clusterrole-qdrant-operator.yaml (kubernetes)
=============================================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'qdrant-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-qdrant-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole-qdrant-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole-qdrant-operator.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - apps
  19 │   resources:
  20 │   - statefulsets
  21 │   verbs:
  22 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'qdrant-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole-qdrant-operator.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - apps
  19 │   resources:
  20 │   - statefulsets
  21 │   verbs:
  22 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'qdrant-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole-qdrant-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'qdrant-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole-qdrant-operator.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────



clusterrole-qdrant-operator1.yaml (kubernetes)
==============================================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'qdrant-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole-qdrant-operator1.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole-qdrant-operator1.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole-qdrant-operator1.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - apps
  19 │   resources:
  20 │   - statefulsets
  21 │   verbs:
  22 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'qdrant-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole-qdrant-operator1.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - apps
  19 │   resources:
  20 │   - statefulsets
  21 │   verbs:
  22 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'qdrant-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole-qdrant-operator1.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'qdrant-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole-qdrant-operator1.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resources:
   9 │   - configmaps
  10 │   - persistentvolumeclaims
  11 │   - persistentvolumeclaims/status
  12 │   - secrets
  13 │   - serviceaccounts
  14 └   - services
  ..   
────────────────────────────────────────



clusterrole-union.yaml (kubernetes)
===================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'union-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole-union.yaml:9-11
────────────────────────────────────────
   9 ┌   - apiGroups: [ "" ]
  10 │     resources: [ "pods" ]
  11 └     verbs: [ "get", "list", "watch", "create", "delete", "update" ]
────────────────────────────────────────



clusterrole135.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole135.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole135.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole136.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole136.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole136.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole138.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole138.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole138.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole140.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole140.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole140.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole17.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole17.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole17.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole187.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'velero-ui' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole187.yaml:19-22
────────────────────────────────────────
  19 ┌   - apiGroups: ["velero.io"]
  20 │     resources: ["*"]
  21 │     verbs:
  22 └       - "*"
────────────────────────────────────────



clusterrole21.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'traefik-ingress-traefik' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole21.yaml:40-47
────────────────────────────────────────
  40 ┌   - apiGroups:
  41 │       - ""
  42 │     resources:
  43 │       - secrets
  44 │     verbs:
  45 │       - get
  46 │       - list
  47 └       - watch
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'traefik-ingress-traefik' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole21.yaml:82-92
────────────────────────────────────────
  82 ┌   - apiGroups:
  83 │       - ""
  84 │     resources:
  85 │       - namespaces
  86 │       - secrets
  87 │       - services
  88 │       - configmaps
  89 │     verbs:
  90 └       - get
  ..   
────────────────────────────────────────



clusterrole23.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-prometheus-stack-plutono-clusterrole' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole23.yaml:18-20
────────────────────────────────────────
  18 ┌   - apiGroups: [""] # "" indicates the core API group
  19 │     resources: ["configmaps", "secrets"]
  20 └     verbs: ["get", "watch", "list"]
────────────────────────────────────────



clusterrole243.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole243.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'all-your-base' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole243.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────



clusterrole244.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole244.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'all-your-base' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole244.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────



clusterrole25.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-prometheus-stack-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole25.yaml:51-57
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - ""
  53 │   resources:
  54 │   - configmaps
  55 │   - secrets
  56 │   verbs:
  57 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole25.yaml:45-50
────────────────────────────────────────
  45 ┌ - apiGroups:
  46 │   - apps
  47 │   resources:
  48 │   - statefulsets
  49 │   verbs:
  50 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole25.yaml:51-57
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - ""
  53 │   resources:
  54 │   - configmaps
  55 │   - secrets
  56 │   verbs:
  57 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kube-prometheus-stack-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole25.yaml:45-50
────────────────────────────────────────
  45 ┌ - apiGroups:
  46 │   - apps
  47 │   resources:
  48 │   - statefulsets
  49 │   verbs:
  50 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kube-prometheus-stack-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole25.yaml:58-64
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ""
  60 │   resources:
  61 │   - pods
  62 │   verbs:
  63 │   - list
  64 └   - delete
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'kube-prometheus-stack-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole25.yaml:51-57
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - ""
  53 │   resources:
  54 │   - configmaps
  55 │   - secrets
  56 │   verbs:
  57 └   - '*'
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kube-prometheus-stack-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole25.yaml:65-75
────────────────────────────────────────
  65 ┌ - apiGroups:
  66 │   - ""
  67 │   resources:
  68 │   - services
  69 │   - services/finalizers
  70 │   - endpoints
  71 │   verbs:
  72 │   - get
  73 └   - create
  ..   
────────────────────────────────────────



clusterrole256.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'NameSpaceApp1-FullAccess' shouldn't manage all resources at the namespace 'app1'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 clusterrole256.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 │   - watch
  15 └   - create
  ..   
────────────────────────────────────────



clusterrole259.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole259.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'all-your-base' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole259.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────



clusterrole26.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0114 (CRITICAL): ClusterRole 'kube-prometheus-stack-admission' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole26.yaml:24-31
────────────────────────────────────────
  24 ┌   - apiGroups:
  25 │       - admissionregistration.k8s.io
  26 │     resources:
  27 │       - validatingwebhookconfigurations
  28 │       - mutatingwebhookconfigurations
  29 │     verbs:
  30 │       - get
  31 └       - update
────────────────────────────────────────



clusterrole262.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'admin-user' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 clusterrole262.yaml:4
────────────────────────────────────────
   4 [   name: admin-user
────────────────────────────────────────



clusterrole28.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 113, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 3)

AVD-KSV-0046 (CRITICAL): ClusterRole 'kubequery-cluster-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole28.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: ["", "admissionregistration.k8s.io", "apps", "autoscaling", "batch", "events.k8s.io", "networking.k8s.io", "policy", "rbac.authorization.k8s.io", "storage.k8s.io", "apiextensions.k8s.io", "templates.gatekeeper.sh", "constraints.gatekeeper.sh"]
   7 │   resources: ["*"]
   8 └   verbs: ["get", "watch"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'kubequery-cluster-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole28.yaml:18-20
────────────────────────────────────────
  18 ┌ - apiGroups: ["constraints.gatekeeper.sh"]
  19 │   resources: ["*"]
  20 └   verbs: ["create", "patch", "update", "watch"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'kubequery-cluster-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole28.yaml:21-23
────────────────────────────────────────
  21 ┌ - apiGroups: ["*"]
  22 │   resources: ["*"]
  23 └   verbs: ["list"]
────────────────────────────────────────



clusterrole30.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 112, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterrole30.yaml:15-17
────────────────────────────────────────
  15 ┌   - apiGroups: [""]
  16 │     resources: ["nodes/proxy"]
  17 └     verbs: ["get"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'otel-ci-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole30.yaml:18-20
────────────────────────────────────────
  18 ┌   - apiGroups: [""]
  19 │     resources: ["nodes/stats", "configmaps", "events"]
  20 └     verbs: ["create", "get"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'otel-ci-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole30.yaml:21-23
────────────────────────────────────────
  21 ┌   - apiGroups: [""]
  22 │     resources: ["configmaps"]
  23 └     verbs: ["update"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'otel-ci-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole30.yaml:24-27
────────────────────────────────────────
  24 ┌   - apiGroups: [""]
  25 │     resources: ["configmaps"]
  26 │     resourceNames: ["otel-container-insight-clusterleader"]
  27 └     verbs: ["get","update", "create"]
────────────────────────────────────────



clusterrole306.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'gobackup-operator-cluster-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole306.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



clusterrole31.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterrole31.yaml:6-17
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - nodes
  10 │       - nodes/proxy
  11 │       - services
  12 │       - endpoints
  13 │       - pods
  14 └     verbs:
  ..   
────────────────────────────────────────



clusterrole32.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole32.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole32.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole321.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole321.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole321.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole326.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole326.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole326.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole328.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole328.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'all-your-base' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole328.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────



clusterrole334.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'acl-manager' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole334.yaml:6-13
────────────────────────────────────────
   6 ┌   - apiGroups: [""]
   7 │     resources:
   8 │     - secrets
   9 │     - configmaps
  10 │     verbs:
  11 │     - get
  12 │     - watch
  13 └     - list
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'acl-manager' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole334.yaml:14-25
────────────────────────────────────────
  14 ┌   - apiGroups:
  15 │     - networking.k8s.io
  16 │     resources:
  17 │     - ingresses
  18 │     verbs:
  19 │     - create
  20 │     - delete
  21 │     - get
  22 └     - list
  ..   
────────────────────────────────────────



clusterrole336.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole336.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'all-your-base' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole336.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────



clusterrole337.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secret-reader' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole337.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   #
   9 │   # at the HTTP level, the name of the resource for accessing Secret
  10 │   # objects is "secrets"
  11 │   resources: ["secrets"]
  12 └   verbs: ["get", "watch", "list"]
────────────────────────────────────────



clusterrole338.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole338.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole338.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole34.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secret-access-cr' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole34.yaml:6-12
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - secrets
  10 │     verbs:
  11 │       - get
  12 └       - list
────────────────────────────────────────



clusterrole352.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0056 (HIGH): ClusterRole 'system:kube-scheduler' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole352.yaml:26-37
────────────────────────────────────────
  26 ┌   - apiGroups:
  27 │       - ""
  28 │     resourceNames:
  29 │       - kube-scheduler
  30 │       - my-scheduler
  31 │     resources:
  32 │       - endpoints
  33 │     verbs:
  34 └       - delete
  ..   
────────────────────────────────────────



clusterrole375.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'my-ing-ingress-nginx' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole375.yaml:14-24
────────────────────────────────────────
  14 ┌   - apiGroups:
  15 │       - ""
  16 │     resources:
  17 │       - configmaps
  18 │       - endpoints
  19 │       - nodes
  20 │       - pods
  21 │       - secrets
  22 └     verbs:
  ..   
────────────────────────────────────────



clusterrole376.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0114 (CRITICAL): ClusterRole 'my-ing-ingress-nginx-admission' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole376.yaml:18-24
────────────────────────────────────────
  18 ┌   - apiGroups:
  19 │       - admissionregistration.k8s.io
  20 │     resources:
  21 │       - validatingwebhookconfigurations
  22 │     verbs:
  23 │       - get
  24 └       - update
────────────────────────────────────────



clusterrole378.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole378.yaml:177-184
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - ''
 179 │   resources:
 180 │   - secrets
 181 │   verbs:
 182 │   - get
 183 │   - watch
 184 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole378.yaml:28-41
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   - extensions.istio.io
  36 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole378.yaml:151-159
────────────────────────────────────────
 151 ┌ - apiGroups:
 152 │   - networking.x-k8s.io
 153 │   - gateway.networking.k8s.io
 154 │   resources:
 155 │   - '*'
 156 │   verbs:
 157 │   - get
 158 │   - watch
 159 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole378.yaml:160-167
────────────────────────────────────────
 160 ┌ - apiGroups:
 161 │   - networking.x-k8s.io
 162 │   - gateway.networking.k8s.io
 163 │   resources:
 164 │   - '*'
 165 │   verbs:
 166 │   - update
 167 └   - patch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole378.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - create
 115 │   - get
 116 │   - list
 117 │   - watch
 118 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole378.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole378.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole378_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole378_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   verbs:
  12 │   - get
  13 │   - watch
  14 │   - list
  15 │   - update
  16 │   - patch
  17 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole378_1.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   verbs:
  24 │   - get
  25 │   - watch
  26 │   - list
  27 │   - update
  28 │   - patch
  29 └   - create
  ..   
────────────────────────────────────────



clusterrole379.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole379.yaml:177-184
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - ''
 179 │   resources:
 180 │   - secrets
 181 │   verbs:
 182 │   - get
 183 │   - watch
 184 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole379.yaml:28-41
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   - extensions.istio.io
  36 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole379.yaml:151-159
────────────────────────────────────────
 151 ┌ - apiGroups:
 152 │   - networking.x-k8s.io
 153 │   - gateway.networking.k8s.io
 154 │   resources:
 155 │   - '*'
 156 │   verbs:
 157 │   - get
 158 │   - watch
 159 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole379.yaml:160-167
────────────────────────────────────────
 160 ┌ - apiGroups:
 161 │   - networking.x-k8s.io
 162 │   - gateway.networking.k8s.io
 163 │   resources:
 164 │   - '*'
 165 │   verbs:
 166 │   - update
 167 └   - patch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole379.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - create
 115 │   - get
 116 │   - list
 117 │   - watch
 118 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole379.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole379.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole379_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole379_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   verbs:
  12 │   - get
  13 │   - watch
  14 │   - list
  15 │   - update
  16 │   - patch
  17 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole379_1.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   verbs:
  24 │   - get
  25 │   - watch
  26 │   - list
  27 │   - update
  28 │   - patch
  29 └   - create
  ..   
────────────────────────────────────────



clusterrole380.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole380.yaml:177-184
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - ''
 179 │   resources:
 180 │   - secrets
 181 │   verbs:
 182 │   - get
 183 │   - watch
 184 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole380.yaml:28-41
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   - extensions.istio.io
  36 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole380.yaml:151-159
────────────────────────────────────────
 151 ┌ - apiGroups:
 152 │   - networking.x-k8s.io
 153 │   - gateway.networking.k8s.io
 154 │   resources:
 155 │   - '*'
 156 │   verbs:
 157 │   - get
 158 │   - watch
 159 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole380.yaml:160-167
────────────────────────────────────────
 160 ┌ - apiGroups:
 161 │   - networking.x-k8s.io
 162 │   - gateway.networking.k8s.io
 163 │   resources:
 164 │   - '*'
 165 │   verbs:
 166 │   - update
 167 └   - patch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole380.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - create
 115 │   - get
 116 │   - list
 117 │   - watch
 118 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole380.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole380.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole380_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole380_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   verbs:
  12 │   - get
  13 │   - watch
  14 │   - list
  15 │   - update
  16 │   - patch
  17 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole380_1.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   verbs:
  24 │   - get
  25 │   - watch
  26 │   - list
  27 │   - update
  28 │   - patch
  29 └   - create
  ..   
────────────────────────────────────────



clusterrole395.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole395.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole395.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole396.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterrole396.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   - nodes
  12 │   - nodes/proxy
  13 │   verbs:
  14 └   - get
  ..   
────────────────────────────────────────



clusterrole405.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'sweeper' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole405.yaml:8-15
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - "pods"
  12 │   verbs:
  13 │   - "get"
  14 │   - "list"
  15 └   - "delete"
────────────────────────────────────────



clusterrole407.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manage-pods' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole407.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 │   - watch
  15 └   - create
  ..   
────────────────────────────────────────



clusterrole408.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manage-pods' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole408.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 │   - watch
  15 └   - create
  ..   
────────────────────────────────────────



clusterrole414.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterrole414.yaml:6-17
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - nodes
  10 │   - nodes/proxy
  11 │   - services
  12 │   - endpoints
  13 │   - pods
  14 └   verbs:
  ..   
────────────────────────────────────────



clusterrole424.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'my-cluster-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole424.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["pods", "services", "deployments"] # Add more resources as needed
   8 └   verbs: ["get", "list", "create", "update", "delete"] # Adjust verbs based on required permissions
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'my-cluster-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole424.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["pods", "services", "deployments"] # Add more resources as needed
   8 └   verbs: ["get", "list", "create", "update", "delete"] # Adjust verbs based on required permissions
────────────────────────────────────────



clusterrole426.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole426.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'jx-boot-job' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole426.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



clusterrole435.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'simulation-operator' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole435.yaml:9-11
────────────────────────────────────────
   9 ┌ - apiGroups: [""]
  10 │   resources: ["secrets"]
  11 └   verbs: ["patch", "create", "delete", "get", "list", "update"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'simulation-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole435.yaml:12-14
────────────────────────────────────────
  12 ┌ - apiGroups: ["apps"]
  13 │   resources: ["statefulsets"]
  14 └   verbs: ["patch", "create", "delete", "get", "list", "update"]
────────────────────────────────────────



clusterrole437.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0114 (CRITICAL): ClusterRole 'ingress-nginx-admission' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole437.yaml:10-16
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - admissionregistration.k8s.io
  12 │     resources:
  13 │       - validatingwebhookconfigurations
  14 │     verbs:
  15 │       - get
  16 └       - update
────────────────────────────────────────



clusterrole438.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'ingress-nginx' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole438.yaml:10-22
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - configmaps
  14 │       - endpoints
  15 │       - nodes
  16 │       - pods
  17 │       - secrets
  18 └       - namespaces
  ..   
────────────────────────────────────────



clusterrole444.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'restarter' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole444.yaml:8-14
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   verbs:
  13 │   - list
  14 └   - delete
────────────────────────────────────────



clusterrole445.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole445.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'all-your-base' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole445.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ["*"]
   7 │     resources: ["*"]
   8 └     verbs: ["*"]
────────────────────────────────────────



clusterrole452.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'release-name-traefik-default' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole452.yaml:23-32
────────────────────────────────────────
  23 ┌   - apiGroups:
  24 │       - ""
  25 │     resources:
  26 │       - services
  27 │       - endpoints
  28 │       - secrets
  29 │     verbs:
  30 │       - get
  31 │       - list
  32 └       - watch
────────────────────────────────────────



clusterrole480.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'my-ing-ingress-nginx' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole480.yaml:14-24
────────────────────────────────────────
  14 ┌   - apiGroups:
  15 │       - ""
  16 │     resources:
  17 │       - configmaps
  18 │       - endpoints
  19 │       - nodes
  20 │       - pods
  21 │       - secrets
  22 └     verbs:
  ..   
────────────────────────────────────────



clusterrole481.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0114 (CRITICAL): ClusterRole 'my-ing-ingress-nginx-admission' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole481.yaml:18-24
────────────────────────────────────────
  18 ┌   - apiGroups:
  19 │       - admissionregistration.k8s.io
  20 │     resources:
  21 │       - validatingwebhookconfigurations
  22 │     verbs:
  23 │       - get
  24 └       - update
────────────────────────────────────────



clusterrole483.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole483.yaml:177-184
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - ''
 179 │   resources:
 180 │   - secrets
 181 │   verbs:
 182 │   - get
 183 │   - watch
 184 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole483.yaml:28-41
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   - extensions.istio.io
  36 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole483.yaml:151-159
────────────────────────────────────────
 151 ┌ - apiGroups:
 152 │   - networking.x-k8s.io
 153 │   - gateway.networking.k8s.io
 154 │   resources:
 155 │   - '*'
 156 │   verbs:
 157 │   - get
 158 │   - watch
 159 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole483.yaml:160-167
────────────────────────────────────────
 160 ┌ - apiGroups:
 161 │   - networking.x-k8s.io
 162 │   - gateway.networking.k8s.io
 163 │   resources:
 164 │   - '*'
 165 │   verbs:
 166 │   - update
 167 └   - patch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole483.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - create
 115 │   - get
 116 │   - list
 117 │   - watch
 118 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole483.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole483.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole483_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole483_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   verbs:
  12 │   - get
  13 │   - watch
  14 │   - list
  15 │   - update
  16 │   - patch
  17 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole483_1.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   verbs:
  24 │   - get
  25 │   - watch
  26 │   - list
  27 │   - update
  28 │   - patch
  29 └   - create
  ..   
────────────────────────────────────────



clusterrole484.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole484.yaml:177-184
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - ''
 179 │   resources:
 180 │   - secrets
 181 │   verbs:
 182 │   - get
 183 │   - watch
 184 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole484.yaml:28-41
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   - extensions.istio.io
  36 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole484.yaml:151-159
────────────────────────────────────────
 151 ┌ - apiGroups:
 152 │   - networking.x-k8s.io
 153 │   - gateway.networking.k8s.io
 154 │   resources:
 155 │   - '*'
 156 │   verbs:
 157 │   - get
 158 │   - watch
 159 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole484.yaml:160-167
────────────────────────────────────────
 160 ┌ - apiGroups:
 161 │   - networking.x-k8s.io
 162 │   - gateway.networking.k8s.io
 163 │   resources:
 164 │   - '*'
 165 │   verbs:
 166 │   - update
 167 └   - patch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole484.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - create
 115 │   - get
 116 │   - list
 117 │   - watch
 118 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole484.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole484.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole484_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole484_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   verbs:
  12 │   - get
  13 │   - watch
  14 │   - list
  15 │   - update
  16 │   - patch
  17 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole484_1.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   verbs:
  24 │   - get
  25 │   - watch
  26 │   - list
  27 │   - update
  28 │   - patch
  29 └   - create
  ..   
────────────────────────────────────────



clusterrole485.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole485.yaml:177-184
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - ''
 179 │   resources:
 180 │   - secrets
 181 │   verbs:
 182 │   - get
 183 │   - watch
 184 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole485.yaml:28-41
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   - extensions.istio.io
  36 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole485.yaml:151-159
────────────────────────────────────────
 151 ┌ - apiGroups:
 152 │   - networking.x-k8s.io
 153 │   - gateway.networking.k8s.io
 154 │   resources:
 155 │   - '*'
 156 │   verbs:
 157 │   - get
 158 │   - watch
 159 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole485.yaml:160-167
────────────────────────────────────────
 160 ┌ - apiGroups:
 161 │   - networking.x-k8s.io
 162 │   - gateway.networking.k8s.io
 163 │   resources:
 164 │   - '*'
 165 │   verbs:
 166 │   - update
 167 └   - patch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole485.yaml:109-118
────────────────────────────────────────
 109 ┌ - apiGroups:
 110 │   - ''
 111 │   resources:
 112 │   - configmaps
 113 │   verbs:
 114 │   - create
 115 │   - get
 116 │   - list
 117 │   - watch
 118 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole485.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-clusterrole-istio-system' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole485.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole485_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole485_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   verbs:
  12 │   - get
  13 │   - watch
  14 │   - list
  15 │   - update
  16 │   - patch
  17 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'istiod-gateway-controller-istio-system' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole485_1.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   verbs:
  24 │   - get
  25 │   - watch
  26 │   - list
  27 │   - update
  28 │   - patch
  29 └   - create
  ..   
────────────────────────────────────────



clusterrole487.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'creditor' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole487.yaml:9-11
────────────────────────────────────────
   9 ┌ - apiGroups: ["*"]
  10 │   resources: ["*"]
  11 └   verbs: ["create"]
────────────────────────────────────────



clusterrole497.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'capacitor' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole497.yaml:7-23
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - networking.k8s.io
   9 │   - apps
  10 │   - ""
  11 │   resources:
  12 │   - pods
  13 │   - pods/log
  14 │   - ingresses
  15 └   - deployments
  ..   
────────────────────────────────────────



clusterrole518.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'ingress-nginx-1' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole518.yaml:15-26
────────────────────────────────────────
  15 ┌   - apiGroups:
  16 │       - ""
  17 │     resources:
  18 │       - configmaps
  19 │       - endpoints
  20 │       - nodes
  21 │       - pods
  22 │       - secrets
  23 └       - namespaces
  ..   
────────────────────────────────────────



clusterrole519.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'ingress-nginx-2' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole519.yaml:15-26
────────────────────────────────────────
  15 ┌   - apiGroups:
  16 │       - ""
  17 │     resources:
  18 │       - configmaps
  19 │       - endpoints
  20 │       - nodes
  21 │       - pods
  22 │       - secrets
  23 └       - namespaces
  ..   
────────────────────────────────────────



clusterrole520.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'system-ingress-ingress-nginx' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole520.yaml:15-26
────────────────────────────────────────
  15 ┌   - apiGroups:
  16 │       - ""
  17 │     resources:
  18 │       - configmaps
  19 │       - endpoints
  20 │       - nodes
  21 │       - pods
  22 │       - secrets
  23 └       - namespaces
  ..   
────────────────────────────────────────



clusterrole532.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'chainoptim-cluster-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole532.yaml:6-16
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - services
  11 │   - endpoints
  12 │   - secrets
  13 │   verbs:
  14 └   - get
  ..   
────────────────────────────────────────



clusterrole539.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole539.yaml:6-11
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - "*"
   8 │     resources:
   9 │       - "*"
  10 │     verbs:
  11 └       - "*"
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'thongdepzai-cloud-gitops-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole539.yaml:6-11
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - "*"
   8 │     resources:
   9 │       - "*"
  10 │     verbs:
  11 └       - "*"
────────────────────────────────────────



clusterrole567.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'kubevirt-dra-driver-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole567.yaml:8-14
────────────────────────────────────────
   8 ┌   - apiGroups:
   9 │       - ""
  10 │       - resource.k8s.io
  11 │       - pci.resource.kubevirt.io
  12 │       - nas.pci.resource.kubevirt.io
  13 │     resources: ["*"]
  14 └     verbs: ["*"]
────────────────────────────────────────



clusterrole569.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 4)

AVD-KSV-0041 (CRITICAL): ClusterRole 'aeraki' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole569.yaml:8-13
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ''
  10 │   resources:
  11 │   - secrets
  12 │   verbs:
  13 └   - get
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'aeraki' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole569.yaml:14-21
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - networking.istio.io
  16 │   resources:
  17 │   - '*'
  18 │   verbs:
  19 │   - get
  20 │   - watch
  21 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'aeraki' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole569.yaml:22-35
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - redis.aeraki.io
  24 │   - dubbo.aeraki.io
  25 │   - metaprotocol.aeraki.io
  26 │   resources:
  27 │   - '*'
  28 │   verbs:
  29 │   - get
  30 └   - watch
  ..   
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'aeraki' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole569.yaml:51-56
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - admissionregistration.k8s.io
  53 │   resources:
  54 │   - validatingwebhookconfigurations
  55 │   verbs:
  56 └   - '*'
────────────────────────────────────────



clusterrole570.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 4)

AVD-KSV-0041 (CRITICAL): ClusterRole 'aeraki' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole570.yaml:23-28
────────────────────────────────────────
  23 ┌   - apiGroups:
  24 │       - ""
  25 │     resources:
  26 │       - secrets
  27 │     verbs:
  28 └       - get
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'aeraki' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole570.yaml:29-36
────────────────────────────────────────
  29 ┌   - apiGroups:
  30 │       - networking.istio.io
  31 │     resources:
  32 │       - '*'
  33 │     verbs:
  34 │       - get
  35 │       - watch
  36 └       - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'aeraki' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole570.yaml:37-50
────────────────────────────────────────
  37 ┌   - apiGroups:
  38 │       - redis.aeraki.io
  39 │       - dubbo.aeraki.io
  40 │       - metaprotocol.aeraki.io
  41 │     resources:
  42 │       - '*'
  43 │     verbs:
  44 │       - get
  45 └       - watch
  ..   
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'aeraki' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole570.yaml:66-71
────────────────────────────────────────
  66 ┌   - apiGroups:
  67 │       - admissionregistration.k8s.io
  68 │     resources:
  69 │       - validatingwebhookconfigurations
  70 │     verbs:
  71 └       - '*'
────────────────────────────────────────



clusterrole573.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 110, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'antrea-controller' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole573.yaml:89-100
────────────────────────────────────────
  89 ┌   - apiGroups:
  90 │       - ""
  91 │     resources:
  92 │       - secrets
  93 │     resourceNames:
  94 │       - antrea-controller-tls
  95 │       - antrea-ipsec-ca
  96 │     verbs:
  97 └       - get
  ..   
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'antrea-controller' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole573.yaml:101-107
────────────────────────────────────────
 101 ┌   - apiGroups:
 102 │       - ""
 103 │     resources:
 104 │       - configmaps
 105 │       - secrets
 106 │     verbs:
 107 └       - create
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'antrea-controller' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole573.yaml:78-88
────────────────────────────────────────
  78 ┌   - apiGroups:
  79 │       - ""
  80 │     resources:
  81 │       - configmaps
  82 │     resourceNames:
  83 │       - antrea-ca
  84 │       - antrea-ipsec-ca
  85 │       - antrea-cluster-identity
  86 └     verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'antrea-controller' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole573.yaml:101-107
────────────────────────────────────────
 101 ┌   - apiGroups:
 102 │       - ""
 103 │     resources:
 104 │       - configmaps
 105 │       - secrets
 106 │     verbs:
 107 └       - create
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'antrea-controller' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole573.yaml:164-176
────────────────────────────────────────
 164 ┌   - apiGroups:
 165 │       - crd.antrea.io
 166 │     resources:
 167 │       - clusternetworkpolicies
 168 │       - networkpolicies
 169 │     verbs:
 170 │       - get
 171 │       - watch
 172 └       - list
 ...   
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'antrea-controller' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole573.yaml:115-122
────────────────────────────────────────
 115 ┌   - apiGroups:
 116 │       - admissionregistration.k8s.io
 117 │     resources:
 118 │       - mutatingwebhookconfigurations
 119 │       - validatingwebhookconfigurations
 120 │     verbs:
 121 │       - list
 122 └       - update
────────────────────────────────────────



clusterrole574.yaml (kubernetes)
================================
Tests: 117 (SUCCESSES: 112, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 0, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'flow-aggregator-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole574.yaml:28-31
────────────────────────────────────────
  28 ┌   - apiGroups: [""]
  29 │     resources: ["secrets"]
  30 │     resourceNames: ["flow-aggregator-client-tls"]
  31 └     verbs: ["get", "update"]
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'flow-aggregator-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole574.yaml:32-34
────────────────────────────────────────
  32 ┌   - apiGroups: [""]
  33 │     resources: ["secrets"]
  34 └     verbs: ["create"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'flow-aggregator-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole574.yaml:8-11
────────────────────────────────────────
   8 ┌   - apiGroups: [""]
   9 │     resources: ["configmaps"]
  10 │     resourceNames: ["flow-aggregator-ca"]
  11 └     verbs: ["get", "update"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'flow-aggregator-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole574.yaml:15-17
────────────────────────────────────────
  15 ┌   - apiGroups: [""]
  16 │     resources: ["configmaps"]
  17 └     verbs: ["create", "get", "list", "watch"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'flow-aggregator-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole574.yaml:35-38
────────────────────────────────────────
  35 ┌   - apiGroups: [ "" ]
  36 │     resources: [ "configmaps" ]
  37 │     resourceNames: [ "flow-aggregator-configmap" ]
  38 └     verbs: [ "update" ]
────────────────────────────────────────



clusterrole581.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 113, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'hubble-generate-certs' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole581.yaml:9-14
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ''
  11 │   resources:
  12 │   - secrets
  13 │   verbs:
  14 └   - create
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'hubble-generate-certs' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole581.yaml:15-24
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ''
  17 │   resources:
  18 │   - secrets
  19 │   resourceNames:
  20 │   - hubble-server-certs
  21 │   - hubble-relay-client-certs
  22 │   - hubble-relay-server-certs
  23 │   verbs:
  24 └   - update
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'hubble-generate-certs' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole581.yaml:25-33
────────────────────────────────────────
  25 ┌ - apiGroups:
  26 │   - ''
  27 │   resources:
  28 │   - secrets
  29 │   resourceNames:
  30 │   - cilium-ca
  31 │   verbs:
  32 │   - get
  33 └   - update
────────────────────────────────────────



clusterrole584.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 clusterrole584.yaml:19-25
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ''
  21 │   resources:
  22 │   - nodes
  23 │   - nodes/proxy
  24 │   verbs:
  25 └   - get
────────────────────────────────────────



clusterrole585_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 108, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crossplane:system:aggregate-to-crossplane' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole585_1.yaml:33-44
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - ''
  35 │   resources:
  36 │   - secrets
  37 │   verbs:
  38 │   - get
  39 │   - list
  40 │   - watch
  41 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crossplane:system:aggregate-to-crossplane' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole585_1.yaml:52-59
────────────────────────────────────────
  52 ┌ - apiGroups:
  53 │   - apiextensions.crossplane.io
  54 │   - pkg.crossplane.io
  55 │   - secrets.crossplane.io
  56 │   resources:
  57 │   - '*'
  58 │   verbs:
  59 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'crossplane:system:aggregate-to-crossplane' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole585_1.yaml:60-72
────────────────────────────────────────
  60 ┌ - apiGroups:
  61 │   - extensions
  62 │   - apps
  63 │   resources:
  64 │   - deployments
  65 │   verbs:
  66 │   - get
  67 │   - list
  68 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crossplane:system:aggregate-to-crossplane' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole585_1.yaml:73-86
────────────────────────────────────────
  73 ┌ - apiGroups:
  74 │   - ''
  75 │   - coordination.k8s.io
  76 │   resources:
  77 │   - configmaps
  78 │   - leases
  79 │   verbs:
  80 │   - get
  81 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'crossplane:system:aggregate-to-crossplane' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole585_1.yaml:45-51
────────────────────────────────────────
  45 ┌ - apiGroups:
  46 │   - ''
  47 │   resources:
  48 │   - serviceaccounts
  49 │   - services
  50 │   verbs:
  51 └   - '*'
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'crossplane:system:aggregate-to-crossplane' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole585_1.yaml:87-99
────────────────────────────────────────
  87 ┌ - apiGroups:
  88 │   - admissionregistration.k8s.io
  89 │   resources:
  90 │   - validatingwebhookconfigurations
  91 │   - mutatingwebhookconfigurations
  92 │   verbs:
  93 │   - get
  94 │   - list
  95 └   - create
  ..   
────────────────────────────────────────



clusterrole587.yaml (kubernetes)
================================
Tests: 118 (SUCCESSES: 110, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 7)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole587.yaml:202-209
────────────────────────────────────────
 202 ┌ - apiGroups:
 203 │   - ''
 204 │   resources:
 205 │   - secrets
 206 │   verbs:
 207 │   - get
 208 │   - watch
 209 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole587.yaml:28-40
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - config.istio.io
  30 │   - security.istio.io
  31 │   - networking.istio.io
  32 │   - authentication.istio.io
  33 │   - rbac.istio.io
  34 │   - telemetry.istio.io
  35 │   verbs:
  36 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole587.yaml:41-51
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - config.istio.io
  43 │   - security.istio.io
  44 │   - networking.istio.io
  45 │   - authentication.istio.io
  46 │   - rbac.istio.io
  47 │   - telemetry.istio.io
  48 │   verbs:
  49 └   - update
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole587.yaml:177-185
────────────────────────────────────────
 177 ┌ - apiGroups:
 178 │   - networking.x-k8s.io
 179 │   - gateway.networking.k8s.io
 180 │   resources:
 181 │   - '*'
 182 │   verbs:
 183 │   - get
 184 │   - watch
 185 └   - list
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole587.yaml:186-192
────────────────────────────────────────
 186 ┌ - apiGroups:
 187 │   - networking.x-k8s.io
 188 │   - gateway.networking.k8s.io
 189 │   resources:
 190 │   - '*'
 191 │   verbs:
 192 └   - update
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istiod-dynamic_parameters' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole587.yaml:135-144
────────────────────────────────────────
 135 ┌ - apiGroups:
 136 │   - ''
 137 │   resources:
 138 │   - configmaps
 139 │   verbs:
 140 │   - create
 141 │   - get
 142 │   - list
 143 │   - watch
 144 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole587.yaml:9-18
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - admissionregistration.k8s.io
  11 │   resources:
  12 │   - mutatingwebhookconfigurations
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 │   - update
  18 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istiod-dynamic_parameters' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole587.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - admissionregistration.k8s.io
  21 │   resources:
  22 │   - validatingwebhookconfigurations
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - watch
  27 └   - update
────────────────────────────────────────



clusterrole587_1.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 110, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 4)

AVD-KSV-0041 (CRITICAL): ClusterRole 'istio-reader-dynamic_parameters' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole587_1.yaml:21-34
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - endpoints
  25 │   - pods
  26 │   - services
  27 │   - nodes
  28 │   - replicationcontrollers
  29 └   - namespaces
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'istio-reader-dynamic_parameters' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole587_1.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - config.istio.io
  11 │   - security.istio.io
  12 │   - networking.istio.io
  13 │   - authentication.istio.io
  14 │   - rbac.istio.io
  15 │   resources:
  16 │   - '*'
  17 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'istio-reader-dynamic_parameters' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole587_1.yaml:95-104
────────────────────────────────────────
  95 ┌ - apiGroups:
  96 │   - ''
  97 │   resources:
  98 │   - configmaps
  99 │   verbs:
 100 │   - create
 101 │   - get
 102 │   - list
 103 │   - watch
 104 └   - update
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istio-reader-dynamic_parameters' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole587_1.yaml:105-114
────────────────────────────────────────
 105 ┌ - apiGroups:
 106 │   - admissionregistration.k8s.io
 107 │   resources:
 108 │   - mutatingwebhookconfigurations
 109 │   verbs:
 110 │   - get
 111 │   - list
 112 │   - watch
 113 │   - update
 114 └   - patch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'istio-reader-dynamic_parameters' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole587_1.yaml:115-123
────────────────────────────────────────
 115 ┌ - apiGroups:
 116 │   - admissionregistration.k8s.io
 117 │   resources:
 118 │   - validatingwebhookconfigurations
 119 │   verbs:
 120 │   - get
 121 │   - list
 122 │   - watch
 123 └   - update
────────────────────────────────────────



clusterrole588_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istio-cni-repair-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole588_1.yaml:12-22
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - ''
  14 │   resources:
  15 │   - pods
  16 │   verbs:
  17 │   - get
  18 │   - list
  19 │   - watch
  20 └   - delete
  ..   
────────────────────────────────────────



clusterrole588_2.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istio-cni-taint-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole588_2.yaml:12-20
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - ''
  14 │   resources:
  15 │   - pods
  16 │   verbs:
  17 │   - get
  18 │   - list
  19 │   - watch
  20 └   - patch
────────────────────────────────────────



clusterrole590.yaml (kubernetes)
================================
Tests: 116 (SUCCESSES: 113, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 3)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole590.yaml:50-59
────────────────────────────────────────
  50 ┌ - apiGroups:
  51 │   - apps
  52 │   - extensions
  53 │   resources:
  54 │   - daemonsets
  55 │   - deployments
  56 │   - deployments/finalizers
  57 │   - replicasets
  58 │   verbs:
  59 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole590.yaml:80-88
────────────────────────────────────────
  80 ┌ - apiGroups:
  81 │   - rbac.authorization.k8s.io
  82 │   resources:
  83 │   - clusterrolebindings
  84 │   - clusterroles
  85 │   - roles
  86 │   - rolebindings
  87 │   verbs:
  88 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 clusterrole590.yaml:97-113
────────────────────────────────────────
  97 ┌ - apiGroups:
  98 │   - ''
  99 │   resources:
 100 │   - configmaps
 101 │   - endpoints
 102 │   - events
 103 │   - namespaces
 104 │   - pods
 105 └   - pods/proxy
 ...   
────────────────────────────────────────



clusterrole595.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole595.yaml:7-10
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"]
   8 │   resources:
   9 │   - "*"
  10 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'hwameistor-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole595.yaml:7-10
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"]
   8 │   resources:
   9 │   - "*"
  10 └   verbs: ["*"]
────────────────────────────────────────



clusterrole596.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole596.yaml:6-9
────────────────────────────────────────
   6 ┌ - apiGroups: ["*"]
   7 │   resources:
   8 │   - "*"
   9 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'hwameistor-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole596.yaml:6-9
────────────────────────────────────────
   6 ┌ - apiGroups: ["*"]
   7 │   resources:
   8 │   - "*"
   9 └   verbs: ["*"]
────────────────────────────────────────



clusterrole598_1.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'istio-cni-repair-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole598_1.yaml:27-32
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - ''
  29 │   resources:
  30 │   - pods
  31 │   verbs:
  32 └   - delete
────────────────────────────────────────



clusterrole602.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 clusterrole602.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ['*']
   7 │     resources: ['*']
   8 └     verbs: ['*']
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'karmada-agent' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 clusterrole602.yaml:6-8
────────────────────────────────────────
   6 ┌   - apiGroups: ['*']
   7 │     resources: ['*']
   8 └     verbs: ['*']
────────────────────────────────────────



clusterrole603.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 108, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kubearmor-operator-clusterrole' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 clusterrole603.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - secrets
  25 │   - serviceaccounts
  26 │   - services
  27 │   - configmaps
  28 │   verbs:
  29 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kubearmor-operator-clusterrole' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole603.yaml:33-43
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - apps
  35 │   resources:
  36 │   - deployments
  37 │   - daemonsets
  38 │   verbs:
  39 │   - list
  40 │   - get
  41 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kubearmor-operator-clusterrole' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole603.yaml:52-57
────────────────────────────────────────
  52 ┌ - apiGroups:
  53 │   - batch
  54 │   verbs:
  55 │   - create
  56 │   resources:
  57 └   - jobs
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'kubearmor-operator-clusterrole' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole603.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - secrets
  25 │   - serviceaccounts
  26 │   - services
  27 │   - configmaps
  28 │   verbs:
  29 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'kubearmor-operator-clusterrole' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 clusterrole603.yaml:58-67
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - rbac.authorization.k8s.io
  60 │   resources:
  61 │   - roles
  62 │   - rolebindings
  63 │   - clusterroles
  64 │   - clusterrolebindings
  65 │   verbs:
  66 │   - create
  67 └   - get
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kubearmor-operator-clusterrole' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 clusterrole603.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - secrets
  25 │   - serviceaccounts
  26 │   - services
  27 │   - configmaps
  28 │   verbs:
  29 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'kubearmor-operator-clusterrole' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 clusterrole603.yaml:44-51
────────────────────────────────────────
  44 ┌ - apiGroups:
  45 │   - admissionregistration.k8s.io
  46 │   resources:
  47 │   - mutatingwebhookconfigurations
  48 │   verbs:
  49 │   - get
  50 │   - create
  51 └   - delete
────────────────────────────────────────



clusterrole603_1.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'kubearmor-operator-manage-kubearmor-clusterrole' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole603_1.yaml:6-18
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - nodes
  11 │   - namespaces
  12 │   - configmaps
  13 │   verbs:
  14 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kubearmor-operator-manage-kubearmor-clusterrole' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole603_1.yaml:19-31
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - apps
  21 │   resources:
  22 │   - deployments
  23 │   - replicasets
  24 │   - daemonsets
  25 │   - statefulsets
  26 │   verbs:
  27 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'kubearmor-operator-manage-kubearmor-clusterrole' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole603_1.yaml:6-18
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - nodes
  11 │   - namespaces
  12 │   - configmaps
  13 │   verbs:
  14 └   - get
  ..   
────────────────────────────────────────



clusterrole603_2.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'kubearmor-operator-manage-controller-clusterrole' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 clusterrole603_2.yaml:6-18
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'kubearmor-operator-manage-controller-clusterrole' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole603_2.yaml:6-18
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 └   - get
  ..   
────────────────────────────────────────



clusterrole604.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): ClusterRole 'custom-controller-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 clusterrole604.yaml:9-11
────────────────────────────────────────
   9 ┌ - apiGroups: [""]
  10 │   resources: ["configmaps"]
  11 └   verbs: ["create", "get", "update", "list", "watch", "delete"]
────────────────────────────────────────


