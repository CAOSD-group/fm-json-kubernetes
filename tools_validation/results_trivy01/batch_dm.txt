
Report Summary

┌────────────────────────────────────────────┬────────────┬───────────────────┐
│                   Target                   │    Type    │ Misconfigurations │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ go_loadtest_deployment.yaml                │ kubernetes │        18         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ go_loadtest_deployment1.yaml               │ kubernetes │        18         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components68_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components69_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_1.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_15.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_16.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_17.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_19.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_2.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_20.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_22.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_23.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_27.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_28.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_29.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_3.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_30.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_33.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_34.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_36.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_37.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_4.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_5.yaml                    │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_6.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_7.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_8.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components6_9.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components70_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components71_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_33.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_34.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_36.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_37.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components72_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components73_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components74_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components75_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components76_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components77_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components78_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_33.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_34.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_36.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_37.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components79_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_1.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_15.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_16.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_17.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_19.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_2.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_20.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_22.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_23.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_27.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_28.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_29.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_3.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_30.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_33.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_34.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_36.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_37.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_4.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_5.yaml                    │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_6.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_7.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_8.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components7_9.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components80_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_33.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_34.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_36.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_37.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components81_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components82_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_11.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_12.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_14.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_15.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_20.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_21.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_22.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_28.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components83_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components84_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_11.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_12.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_14.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_15.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_20.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_21.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_22.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_28.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components85_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components86_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_33.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_34.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_36.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_37.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components87_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components88_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components89_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_1.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_15.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_16.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_17.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_19.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_2.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_20.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_22.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_23.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_27.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_28.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_29.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_3.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_30.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_33.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_34.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_36.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_37.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_4.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_5.yaml                    │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_6.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_7.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_8.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components8_9.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_1.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_15.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_16.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_17.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_19.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_2.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_20.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_22.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_23.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_27.yaml                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_28.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_29.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_3.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_30.yaml                  │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_4.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_5.yaml                   │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_6.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_7.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_8.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components90_9.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_1.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_15.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_16.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_17.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_19.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_2.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_20.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_22.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_23.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_27.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_28.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_29.yaml                   │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_3.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_30.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_33.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_34.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_36.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_37.yaml                   │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_4.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_5.yaml                    │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_6.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_7.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_8.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components9_9.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_1.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_15.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_16.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_17.yaml                    │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_19.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_2.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_20.yaml                    │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_22.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_23.yaml                    │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_27.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_28.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_29.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_3.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_30.yaml                    │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_33.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_34.yaml                    │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_36.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_37.yaml                    │ kubernetes │         4         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_4.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_5.yaml                     │ kubernetes │         7         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_6.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_7.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_8.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gotk-components_9.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gowebapp-deployment.yaml                   │ kubernetes │        14         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gowebapp-ingress.yaml                      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gowebapp-mysql-deployment.yaml             │ kubernetes │        18         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gowebapp-mysql-service.yaml                │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gowebapp-mysql-sts.yaml                    │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gowebapp-service.yaml                      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gp3-sc.yaml                                │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gp3-sc1.yaml                               │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gp3-storageClass.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gp3.yaml                                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gp31.yaml                                  │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu-diagnostic-pod.yaml                    │ kubernetes │        19         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu-operator-rbac.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu-operator-rbac_1.yaml                   │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu-pod.yaml                               │ kubernetes │        19         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpuPod1.yaml                               │ kubernetes │        19         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_patch.yaml                             │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_patch1.yaml                            │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_patch2.yaml                            │ kubernetes │        19         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_patch3.yaml                            │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_patch4.yaml                            │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_patch5.yaml                            │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_test.yaml                              │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpu_test_1.yaml                            │ kubernetes │        20         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gpupod.yaml                                │ kubernetes │        19         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ graceful-termination.yaml                  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ graceful-termination_1.yaml                │ kubernetes │        18         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ graceful-termination_2.yaml                │ kubernetes │        18         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-config.yaml           │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-config1.yaml          │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-config2.yaml          │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment.yaml       │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment1.yaml      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment2.yaml      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment3.yaml      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment4.yaml      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment5.yaml      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-deployment6.yaml      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-pod.yaml              │ kubernetes │        30         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-pod1.yaml             │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-pod2.yaml             │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-secret.yaml           │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-secret1.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-secret2.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service.yaml          │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service1.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service2.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service3.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service4.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service5.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service6.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service7.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-api-service8.yaml         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-config.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-config1.yaml       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-config2.yaml       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment.yaml    │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment1.yaml   │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment2.yaml   │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment3.yaml   │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment4.yaml   │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment5.yaml   │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-deployment6.yaml   │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-hpa.yaml           │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-ingress.yaml       │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-pod.yaml           │ kubernetes │        31         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-pod1.yaml          │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-pod2.yaml          │ kubernetes │        16         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service.yaml       │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service1.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service2.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service3.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service4.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service5.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service6.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service7.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grade-submission-portal-service8.yaml      │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-classify.yaml                       │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-classify1.yaml                      │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-classify1_1.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-classify_1.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-tgi.yaml                            │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-tgi1.yaml                           │ kubernetes │        15         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-tgi1_1.yaml                         │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ gradio-tgi_1.yaml                          │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-admin-secret.sops.yaml             │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-base.yaml                          │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-base_1.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-base_2.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-base_3.yaml                        │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-chown-job.yaml                     │ kubernetes │        18         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-claim0-persistentvolumeclaim.yaml  │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-claim0-persistentvolumeclaim1.yaml │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-claim0-persistentvolumeclaim2.yaml │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-claim0-persistentvolumeclaim3.yaml │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-claim0-persistentvolumeclaim4.yaml │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-claim0-persistentvolumeclaim5.yaml │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-cm.yaml                            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-cm1.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-cm2.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-cm3.yaml                           │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-cm4.yaml                           │ kubernetes │         2         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config.yaml                        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config1.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config10.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config11.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config12.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config13.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config14.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config15.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config16.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config17.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config18.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config19.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config2.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config20.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config21.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config23.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config24.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config25.yaml                      │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config3.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config4.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config5.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config6.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config7.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config8.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-config9.yaml                       │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-configmap.yaml                     │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-configmap1.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-configmap2.yaml                    │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-configmap3.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-configmap7.yaml                    │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-daemon-set.yaml                    │ kubernetes │        17         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboard-numbers-api.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboard-numbers-api1.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboard-numbers-api2.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboard-numbers-api3.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboard.yaml                     │ kubernetes │         1         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources.yaml          │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources1.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources10.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources11.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources12.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources13.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources14.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources15.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources16.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources17.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources18.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources19.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources2.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources20.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources21.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources22.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources23.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources24.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources25.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources26.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources27.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources28.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources29.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources3.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources30.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources31.yaml        │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources4.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources5.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources6.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources7.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources8.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardDatasources9.yaml         │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources.yaml              │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources1.yaml             │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources10.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources11.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources12.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources13.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources14.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources15.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources16.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources17.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources18.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources19.yaml            │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources2.yaml             │ kubernetes │         0         │
├────────────────────────────────────────────┼────────────┼───────────────────┤
│ grafana-dashboardSources20.yaml            │ kubernetes │         0         │
└────────────────────────────────────────────┴────────────┴───────────────────┘
Legend:
- '-': Not scanned
- '0': Clean (no security findings detected)


go_loadtest_deployment.yaml (kubernetes)
========================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'app' of Deployment 'server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'app' of Deployment 'server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'app' of 'deployment' 'server' in 'px-profiler-loadtest' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'app' of Deployment 'server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'app' of Deployment 'server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'app' of Deployment 'server' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'app' of Deployment 'server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'app' of Deployment 'server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'app' of Deployment 'server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'app' of Deployment 'server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'app' of Deployment 'server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'app' of Deployment 'server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 go_loadtest_deployment.yaml:8-28
────────────────────────────────────────
   8 ┌   replicas: 1
   9 │   selector:
  10 │     matchLabels:
  11 │       name: go-app
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         name: go-app
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "app" of deployment "server" in "px-profiler-loadtest" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container server in px-profiler-loadtest namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 go_loadtest_deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment server in px-profiler-loadtest namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 go_loadtest_deployment.yaml:17-28
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 └         - name: NUM_FUNCTIONS
  ..   
────────────────────────────────────────



go_loadtest_deployment1.yaml (kubernetes)
=========================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'app' of Deployment 'server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'app' of Deployment 'server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'app' of 'deployment' 'server' in 'px-profiler-loadtest' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'app' of Deployment 'server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'app' of Deployment 'server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'app' of Deployment 'server' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'app' of Deployment 'server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'app' of Deployment 'server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'app' of Deployment 'server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'app' of Deployment 'server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'app' of Deployment 'server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'app' of Deployment 'server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 go_loadtest_deployment1.yaml:8-28
────────────────────────────────────────
   8 ┌   replicas: 1
   9 │   selector:
  10 │     matchLabels:
  11 │       name: go-app
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         name: go-app
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "app" of deployment "server" in "px-profiler-loadtest" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container server in px-profiler-loadtest namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 go_loadtest_deployment1.yaml:18-28
────────────────────────────────────────
  18 ┌       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 │         - name: NUM_FUNCTIONS
  26 └           value: "5"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment server in px-profiler-loadtest namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 go_loadtest_deployment1.yaml:17-28
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: app
  19 │         image: profiler_loadtest_golang:latest
  20 │         env:
  21 │         - name: NUM_GOROUTINES
  22 │           value: "50"
  23 │         - name: PAUSE_TIME_NS
  24 │           value: "100000"
  25 └         - name: NUM_FUNCTIONS
  ..   
────────────────────────────────────────



gotk-components68_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components68_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components68_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components68_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components68_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components68_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components68_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components68_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components68_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components68_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components68_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components68_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components68_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components68_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components68_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components68_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components68_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components68_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components68_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components68_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components68_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components68_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components68_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components68_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components68_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components68_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components68_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components68_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components68_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components68_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components68_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components68_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components69_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components69_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components69_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components69_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components69_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_17.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components69_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components69_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components69_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components69_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components69_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_20.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components69_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components69_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components69_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components69_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_23.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components69_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components69_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components69_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components69_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components69_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components69_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components69_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_30.yaml:13-87
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components69_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components69_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components69_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components69_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components69_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components69_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components69_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components69_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components69_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components69_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components69_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.2.3
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components6_1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components6_16.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components6_17.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components6_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components6_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components6_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components6_2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components6_20.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components6_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components6_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components6_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components6_23.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components6_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components6_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components6_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components6_28.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components6_29.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components6_3.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components6_30.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components6_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components6_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components6_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components6_34.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components6_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components6_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components6_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components6_37.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components6_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components6_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components6_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components6_4.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components6_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components6_5.yaml (kubernetes)
====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components6_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components6_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components6_6.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components6_7.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components6_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components6_8.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components6_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components70_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components70_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components70_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components70_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components70_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_17.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components70_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components70_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components70_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components70_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components70_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_20.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components70_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components70_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components70_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components70_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_23.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components70_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components70_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components70_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components70_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components70_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components70_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components70_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_30.yaml:13-87
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components70_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components70_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components70_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components70_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components70_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components70_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components70_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components70_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components70_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components70_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components70_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.2.3
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components71_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components71_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components71_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components71_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components71_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_17.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components71_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components71_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components71_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components71_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components71_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_20.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components71_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components71_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components71_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components71_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_23.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components71_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components71_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components71_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components71_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components71_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components71_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components71_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_30.yaml:13-87
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components71_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components71_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components71_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components71_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components71_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components71_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components71_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components71_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components71_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components71_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components71_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.2.3
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components72_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components72_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components72_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components72_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components72_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components72_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components72_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components72_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components72_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components72_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components72_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components72_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components72_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components72_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components72_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components72_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components72_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components72_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components72_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components72_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components72_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components72_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components72_34.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components72_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components72_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components72_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components72_37.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components72_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components72_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components72_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components72_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components72_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components72_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components72_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components72_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components72_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components72_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components72_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components72_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components72_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components73_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components73_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components73_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components73_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components73_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components73_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components73_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components73_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components73_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components73_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components73_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components73_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components73_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components73_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components73_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components73_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components73_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components73_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components73_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components73_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components73_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components73_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components73_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components73_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components73_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components73_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components73_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components73_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components73_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components73_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components73_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components73_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components74_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components74_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components74_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components74_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components74_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components74_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components74_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components74_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components74_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components74_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components74_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components74_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components74_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components74_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components74_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components74_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components74_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components74_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components74_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components74_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components74_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components74_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components74_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components74_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components74_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components74_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components74_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components75_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components75_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components75_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components75_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components75_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components75_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components75_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components75_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components75_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components75_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components75_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components75_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components75_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components75_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components75_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components75_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components75_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components75_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components75_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components75_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components75_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components75_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components75_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components75_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components75_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components75_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components75_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components75_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components75_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components75_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components75_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components75_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components76_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components76_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components76_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components76_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components76_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components76_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components76_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components76_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components76_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components76_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components76_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components76_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components76_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components76_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components76_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components76_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components76_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components76_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components76_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components76_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components76_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components76_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components76_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components76_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components76_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components76_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components76_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components76_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components76_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components76_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components76_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components76_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components77_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components77_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components77_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components77_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components77_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components77_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components77_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components77_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components77_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components77_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components77_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components77_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components77_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components77_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components77_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components77_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components77_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components77_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components77_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components77_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components77_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components77_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components77_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components77_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components77_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components77_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components77_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components77_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components77_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components77_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components77_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components77_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components78_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components78_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components78_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components78_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components78_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components78_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components78_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components78_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components78_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components78_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components78_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components78_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components78_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components78_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components78_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components78_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components78_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components78_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components78_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components78_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components78_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components78_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components78_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components78_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components78_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components78_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components78_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components79_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components79_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components79_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components79_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components79_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components79_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components79_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components79_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components79_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components79_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components79_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components79_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components79_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components79_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components79_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components79_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components79_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components79_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components79_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components79_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components79_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components79_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components79_34.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components79_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components79_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components79_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components79_37.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components79_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components79_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components79_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components79_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components79_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components79_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components79_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components79_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components79_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components79_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components79_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components79_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components79_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components7_1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components7_16.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components7_17.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components7_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components7_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components7_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components7_2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components7_20.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components7_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components7_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components7_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components7_23.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components7_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components7_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components7_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components7_28.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components7_29.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components7_3.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components7_30.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components7_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components7_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components7_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components7_34.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components7_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components7_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components7_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components7_37.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components7_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components7_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components7_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components7_4.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components7_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components7_5.yaml (kubernetes)
====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components7_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components7_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components7_6.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components7_7.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components7_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components7_8.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components7_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components80_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components80_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components80_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components80_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components80_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components80_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components80_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components80_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components80_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components80_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components80_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components80_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components80_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components80_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components80_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components80_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components80_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components80_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components80_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components80_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components80_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components80_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components80_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components80_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components80_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components80_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components80_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components80_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components80_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components80_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components80_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components80_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components81_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components81_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components81_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components81_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components81_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components81_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components81_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components81_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components81_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components81_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components81_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components81_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components81_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components81_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components81_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components81_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components81_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components81_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components81_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components81_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components81_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components81_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components81_34.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components81_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components81_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components81_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components81_37.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components81_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components81_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components81_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components81_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components81_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components81_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components81_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components81_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components81_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components81_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components81_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components81_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components81_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.4.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components82_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components82_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components82_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components82_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components82_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components82_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components82_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components82_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components82_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components82_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components82_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components82_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components82_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components82_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components82_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components82_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components82_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components82_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components82_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components82_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components82_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components82_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components82_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components82_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components82_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components82_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components82_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components82_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components82_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components82_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components82_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components82_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components83_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components83_12.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components83_12.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components83_12.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_12.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components83_12.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components83_15.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components83_15.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components83_15.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_15.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components83_15.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components83_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components83_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_20.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components83_21.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_21.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components83_22.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components83_22.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components83_22.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_22.yaml:13-87
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components83_22.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components83_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components83_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components83_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components83_30.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components83_30.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_30.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components83_30.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components83_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components83_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components83_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components83_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components83_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components83_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components83_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components83_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components83_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components83_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.2.3
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components84_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components84_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components84_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components84_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components84_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components84_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components84_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components84_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components84_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components84_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components84_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components84_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components84_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components84_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components84_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components84_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components84_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components84_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components84_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components84_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components84_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components84_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components84_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components84_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components84_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components84_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components84_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components84_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components84_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components84_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components84_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components84_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components85_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components85_12.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components85_12.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components85_12.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_12.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components85_12.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components85_15.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components85_15.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components85_15.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_15.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components85_15.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components85_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components85_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_20.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components85_21.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_21.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components85_22.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components85_22.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components85_22.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_22.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components85_22.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components85_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components85_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components85_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components85_30.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components85_30.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_30.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components85_30.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components85_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components85_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components85_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components85_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components85_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components85_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components85_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components85_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components85_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components85_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components86_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components86_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components86_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components86_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components86_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components86_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components86_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components86_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components86_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components86_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components86_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components86_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components86_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components86_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components86_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components86_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components86_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components86_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components86_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components86_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components86_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components86_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components86_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components86_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components86_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components86_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components86_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components86_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components86_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components86_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components86_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components86_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components87_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components87_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components87_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components87_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components87_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components87_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components87_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components87_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components87_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components87_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components87_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components87_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components87_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components87_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components87_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components87_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components87_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components87_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components87_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components87_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components87_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components87_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components87_34.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components87_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components87_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components87_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components87_37.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components87_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components87_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components87_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components87_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components87_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components87_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components87_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components87_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components87_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components87_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components87_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components87_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components87_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components88_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components88_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components88_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components88_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components88_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components88_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components88_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components88_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components88_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components88_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components88_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components88_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components88_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components88_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components88_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components88_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components88_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components88_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components88_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components88_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components88_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components88_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components88_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components88_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components88_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components88_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components88_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components88_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components88_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components88_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components88_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components88_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components89_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components89_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components89_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components89_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components89_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components89_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components89_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components89_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components89_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components89_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components89_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components89_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components89_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components89_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components89_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components89_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components89_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components89_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components89_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components89_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components89_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components89_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components89_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components89_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components89_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components89_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components89_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components89_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components89_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components89_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components89_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components89_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components8_1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components8_16.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components8_17.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components8_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components8_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components8_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components8_2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components8_20.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components8_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components8_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components8_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components8_23.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components8_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components8_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components8_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components8_28.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components8_29.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components8_3.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components8_30.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components8_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components8_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components8_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components8_34.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components8_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components8_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components8_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components8_37.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components8_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components8_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components8_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components8_4.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components8_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components8_5.yaml (kubernetes)
====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components8_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components8_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components8_6.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components8_7.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components8_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components8_8.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components8_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components90_1.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components90_16.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components90_17.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components90_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components90_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components90_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components90_2.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components90_20.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components90_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components90_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components90_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components90_23.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components90_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components90_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components90_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components90_28.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components90_29.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components90_3.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components90_30.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components90_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components90_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components90_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components90_4.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components90_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components90_5.yaml (kubernetes)
=====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components90_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components90_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components90_6.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components90_7.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components90_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components90_8.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components90_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components9_1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components9_16.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components9_17.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components9_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components9_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_17.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components9_17.yaml:28-84
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components9_2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components9_20.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components9_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components9_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_20.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components9_20.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components9_23.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components9_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components9_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_23.yaml:13-83
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components9_23.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components9_28.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components9_29.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components9_3.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components9_30.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components9_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components9_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_30.yaml:13-87
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components9_30.yaml:26-78
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components9_34.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components9_34.yaml:26-75
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components9_34.yaml:26-75
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_34.yaml:13-86
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components9_34.yaml:26-75
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components9_37.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components9_37.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components9_37.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_37.yaml:13-82
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components9_37.yaml:26-73
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components9_4.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components9_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components9_5.yaml (kubernetes)
====================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components9_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components9_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components9_6.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components9_7.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components9_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components9_8.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components9_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.1.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gotk-components_1.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



gotk-components_16.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components_17.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



gotk-components_2.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



gotk-components_20.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components_23.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components_28.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components_29.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



gotk-components_3.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



gotk-components_30.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



gotk-components_34.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components_37.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gotk-components_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gotk-components_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gotk-components_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



gotk-components_4.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gotk-components_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



gotk-components_5.yaml (kubernetes)
===================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 gotk-components_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 gotk-components_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



gotk-components_6.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



gotk-components_7.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 gotk-components_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



gotk-components_8.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 gotk-components_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.5.1
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



gowebapp-deployment.yaml (kubernetes)
=====================================
Tests: 116 (SUCCESSES: 102, FAILURES: 14)
Failures: 14 (UNKNOWN: 0, LOW: 8, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gowebapp' of Deployment 'gowebapp' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gowebapp' of Deployment 'gowebapp' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gowebapp' of 'deployment' 'gowebapp' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gowebapp' of Deployment 'gowebapp' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gowebapp' of Deployment 'gowebapp' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gowebapp' of Deployment 'gowebapp' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gowebapp' of Deployment 'gowebapp' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gowebapp-deployment.yaml:14-70
────────────────────────────────────────
  14 ┌   replicas: 2
  15 │   selector:
  16 │     matchLabels:
  17 │       app: gowebapp
  18 │       tier: frontend
  19 │   template:
  20 │     metadata:
  21 │       labels:
  22 └         app: gowebapp
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gowebapp" of deployment "gowebapp" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment gowebapp in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gowebapp-deployment.yaml:6-11
────────────────────────────────────────
   6 ┌   name: gowebapp
   7 │   labels:
   8 │     #TODO: give the Deployment a label: app: gowebapp
   9 │     #TODO: give the Deployment a label: tier: frontend
  10 │     app: gowebapp
  11 └     tier: frontend
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gowebapp in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gowebapp-deployment.yaml:26-60
────────────────────────────────────────
  26 ┌       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 │           valueFrom:
  34 └             secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment gowebapp in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gowebapp-deployment.yaml:25-70
────────────────────────────────────────
  25 ┌       containers:
  26 │       - name: gowebapp
  27 │         image: gowebapp:v2
  28 │         env:
  29 │         - #TODO: define name as DB_PASSWORD
  30 │           #TODO: define value as mypassword
  31 │           name: DB_PASSWORD
  32 │         # value: mypassword
  33 └           valueFrom:
  ..   
────────────────────────────────────────



gowebapp-ingress.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gowebapp-ingress.yaml:6-17
────────────────────────────────────────
   6 ┌   ingressClassName: nginx
   7 │   rules:
   8 │   - host: gowebapp.localdev.me # 👈
   9 │     http:
  10 │       paths:
  11 │       - pathType: Prefix # or ImplementationSpecific or Exact
  12 │         path: "/"
  13 │         backend:
  14 └           service:
  ..   
────────────────────────────────────────



gowebapp-mysql-deployment.yaml (kubernetes)
===========================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gowebapp-mysql' of 'deployment' 'gowebapp-mysql' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gowebapp-mysql' of Deployment 'gowebapp-mysql' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:14-36
────────────────────────────────────────
  14 ┌   replicas: 1
  15 │   strategy: 
  16 │     #TODO: define the type of strategy as Recreate
  17 │     type: Recreate
  18 │   selector:
  19 │     matchLabels:
  20 │       app: gowebapp-mysql
  21 │       tier: backend
  22 └   template:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gowebapp-mysql" of deployment "gowebapp-mysql" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment gowebapp-mysql in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:6-11
────────────────────────────────────────
   6 ┌   name: gowebapp-mysql
   7 │   labels:
   8 │     #TODO: give the Deployment a label: app: gowebapp-mysql
   9 │     #TODO: give the Deployment a label: tier: backend
  10 │     app: gowebapp-mysql
  11 └     tier: backend
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gowebapp-mysql in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:29-36
────────────────────────────────────────
  29 ┌       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment gowebapp-mysql in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gowebapp-mysql-deployment.yaml:28-36
────────────────────────────────────────
  28 ┌       containers:
  29 │       - name: gowebapp-mysql
  30 │         image: gowebapp-mysql:v1
  31 │         env:
  32 │         - name: MYSQL_ROOT_PASSWORD
  33 │           value: mypassword
  34 │         ports:
  35 │         - #TODO: define the container port as 3306
  36 └           containerPort: 3306
────────────────────────────────────────



gowebapp-mysql-service.yaml (kubernetes)
========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gowebapp-mysql-service.yaml:12-21
────────────────────────────────────────
  12 ┌   type: ClusterIP
  13 │   ports:
  14 │   - #TODO: expose port 3306
  15 │     port: 3306
  16 │     targetPort: 3306
  17 │   selector:
  18 │     #TODO: define a selector: app: gowebapp-mysql
  19 │     #TODO: define a selector: tier: backend
  20 │     app: gowebapp-mysql
  21 └     tier: backend
────────────────────────────────────────



gowebapp-mysql-sts.yaml (kubernetes)
====================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 10, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gowebapp-mysql' of 'statefulset' 'gowebapp-mysql' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gowebapp-mysql' of StatefulSet 'gowebapp-mysql' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:9-63
────────────────────────────────────────
   9 ┌   serviceName: gowebapp-mysql # TODO: Set serviceName to gowebapp-mysql
  10 │   replicas: 1
  11 │   selector:
  12 │     matchLabels:
  13 │       app: gowebapp-mysql
  14 │       tier: backend
  15 │   template:
  16 │     metadata:
  17 └       labels:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gowebapp-mysql" of statefulset "gowebapp-mysql" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): statefulset gowebapp-mysql in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:4-7
────────────────────────────────────────
   4 ┌   name: gowebapp-mysql
   5 │   labels:
   6 │     app: gowebapp-mysql
   7 └     tier: backend
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gowebapp-mysql in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:22-55
────────────────────────────────────────
  22 ┌       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 │               name: mysql
  30 └               key: password
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): statefulset gowebapp-mysql in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gowebapp-mysql-sts.yaml:21-55
────────────────────────────────────────
  21 ┌       containers:
  22 │       - name: gowebapp-mysql
  23 │         image: gowebapp-mysql:v1
  24 │         env:
  25 │         - name: MYSQL_ROOT_PASSWORD
  26 │         # value: mypassword
  27 │           valueFrom:
  28 │             secretKeyRef:
  29 └               name: mysql
  ..   
────────────────────────────────────────



gowebapp-service.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gowebapp-service.yaml:16-31
────────────────────────────────────────
  16 ┌   type: ClusterIP
  17 │   ports:
  18 │   - #TODO: expose port 8080
  19 │     # By default and for convenience, the `targetPort`
  20 │     # is set to the same value as the `port` field.
  21 │     #targetPort: 8080
  22 │     # `nodePort` is an optional field
  23 │     # By default and for convenience, the Kubernetes
  24 └     # control plane will allocate a port from a range (default: 30000-32767)
  ..   
────────────────────────────────────────



gpu-diagnostic-pod.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'cuda-toolkit' of 'pod' 'gpu-diagnostic-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'cuda-toolkit' of Pod 'gpu-diagnostic-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:6-20
────────────────────────────────────────
   6 ┌   containers:
   7 │     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "cuda-toolkit" of pod "gpu-diagnostic-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod gpu-diagnostic-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:4
────────────────────────────────────────
   4 [   name: gpu-diagnostic-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod gpu-diagnostic-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:6-20
────────────────────────────────────────
   6 ┌   containers:
   7 │     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container cuda-toolkit in pod gpu-diagnostic-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gpu-diagnostic-pod.yaml:7-14
────────────────────────────────────────
   7 ┌     - name: cuda-toolkit
   8 │       image: nvidia/cuda:12.1.1-base-ubuntu22.04
   9 │       command: ["sleep", "infinity"]
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1
  13 │       securityContext:
  14 └         privileged: true
────────────────────────────────────────



gpu-pod.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'cuda-container' of 'pod' 'gpu-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu-pod.yaml:7-15
────────────────────────────────────────
   7 ┌  restartPolicy: OnFailure
   8 │  runtimeClassName: nvidia
   9 │  containers:
  10 │    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "cuda-container" of pod "gpu-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod gpu-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu-pod.yaml:5
────────────────────────────────────────
   5 [  name: gpu-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gpu-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod gpu-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu-pod.yaml:7-15
────────────────────────────────────────
   7 ┌  restartPolicy: OnFailure
   8 │  runtimeClassName: nvidia
   9 │  containers:
  10 │    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container cuda-container in pod gpu-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gpu-pod.yaml:10-15
────────────────────────────────────────
  10 ┌    - name: cuda-container
  11 │      image: nvidia/cuda:11.6.2-base-ubuntu20.04
  12 │      command: ["nvidia-smi"]
  13 │      resources:
  14 │        limits:
  15 └          nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────



gpuPod1.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'cuda-vector-add' of 'pod' 'gpu-operator-test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'cuda-vector-add' of Pod 'gpu-operator-test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpuPod1.yaml:6-12
────────────────────────────────────────
   6 ┌   restartPolicy: OnFailure
   7 │   containers:
   8 │     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "cuda-vector-add" of pod "gpu-operator-test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod gpu-operator-test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpuPod1.yaml:4
────────────────────────────────────────
   4 [   name: gpu-operator-test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gpu-operator-test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod gpu-operator-test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpuPod1.yaml:6-12
────────────────────────────────────────
   6 ┌   restartPolicy: OnFailure
   7 │   containers:
   8 │     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container cuda-vector-add in pod gpu-operator-test (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gpuPod1.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-vector-add
   9 │       image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1
────────────────────────────────────────



gpu_patch.yaml (kubernetes)
===========================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Deployment 'llm1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'deployment' 'llm1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'server' of Deployment 'llm1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Deployment 'llm1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_patch.yaml:6-14
────────────────────────────────────────
   6 ┌   template:
   7 │     spec:
   8 │       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of deployment "llm1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment llm1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_patch.yaml:4
────────────────────────────────────────
   4 [   name: llm1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container llm1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment llm1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch.yaml:8-14
────────────────────────────────────────
   8 ┌       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "40"
  14 └               memory: 190Gi
────────────────────────────────────────



gpu_patch1.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Deployment 'llm1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'deployment' 'llm1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'server' of Deployment 'llm1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Deployment 'llm1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_patch1.yaml:6-14
────────────────────────────────────────
   6 ┌   template:
   7 │     spec:
   8 │       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of deployment "llm1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment llm1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_patch1.yaml:4
────────────────────────────────────────
   4 [   name: llm1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container llm1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch1.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment llm1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch1.yaml:8-14
────────────────────────────────────────
   8 ┌       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────



gpu_patch2.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Deployment 'llm1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'deployment' 'llm1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'server' of Deployment 'llm1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Deployment 'llm1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_patch2.yaml:6-12
────────────────────────────────────────
   6 ┌   template:
   7 │     spec:
   8 │       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of deployment "llm1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment llm1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_patch2.yaml:4
────────────────────────────────────────
   4 [   name: llm1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container llm1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch2.yaml:9-12
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment llm1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch2.yaml:8-12
────────────────────────────────────────
   8 ┌       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 └               nvidia.com/gpu: "2"
────────────────────────────────────────



gpu_patch3.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Deployment 'llm1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'deployment' 'llm1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'server' of Deployment 'llm1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Deployment 'llm1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_patch3.yaml:6-14
────────────────────────────────────────
   6 ┌   template:
   7 │     spec:
   8 │       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of deployment "llm1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment llm1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_patch3.yaml:4
────────────────────────────────────────
   4 [   name: llm1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container llm1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch3.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment llm1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch3.yaml:8-14
────────────────────────────────────────
   8 ┌       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────



gpu_patch4.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Deployment 'llm1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'deployment' 'llm1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'server' of Deployment 'llm1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Deployment 'llm1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_patch4.yaml:6-14
────────────────────────────────────────
   6 ┌   template:
   7 │     spec:
   8 │       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of deployment "llm1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment llm1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_patch4.yaml:4
────────────────────────────────────────
   4 [   name: llm1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container llm1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch4.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment llm1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch4.yaml:8-14
────────────────────────────────────────
   8 ┌       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "2"
  13 │               cpu: "8"
  14 └               memory: 32Gi
────────────────────────────────────────



gpu_patch5.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Deployment 'llm1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'deployment' 'llm1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'server' of Deployment 'llm1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Deployment 'llm1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Deployment 'llm1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Deployment 'llm1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_patch5.yaml:6-14
────────────────────────────────────────
   6 ┌   template:
   7 │     spec:
   8 │       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of deployment "llm1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment llm1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_patch5.yaml:4
────────────────────────────────────────
   4 [   name: llm1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container llm1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch5.yaml:9-14
────────────────────────────────────────
   9 ┌         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment llm1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_patch5.yaml:8-14
────────────────────────────────────────
   8 ┌       containers:
   9 │         - name: server
  10 │           resources:
  11 │             limits:
  12 │               nvidia.com/gpu: "8"
  13 │               cpu: "60"
  14 └               memory: 190Gi
────────────────────────────────────────



gpu_test.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_test.yaml:6-12
────────────────────────────────────────
   6 ┌   clusterIP: None
   7 │   ports:
   8 │   - name: nccl
   9 │     port: 29500
  10 │     targetPort: 29500
  11 │   selector:
  12 └     job-name: multinode-job
────────────────────────────────────────



gpu_test_1.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'multinode' of Job 'multinode-job' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'multinode' of Job 'multinode-job' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'multinode' of 'job' 'multinode-job' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'multinode' of Job 'multinode-job' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'multinode' of Job 'multinode-job' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'multinode' of Job 'multinode-job' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'multinode' of Job 'multinode-job' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'multinode' of Job 'multinode-job' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'multinode' of Job 'multinode-job' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'multinode' of Job 'multinode-job' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'multinode' of Job 'multinode-job' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'multinode' of Job 'multinode-job' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpu_test_1.yaml:6-35
────────────────────────────────────────
   6 ┌   completionMode: Indexed
   7 │   completions: 2
   8 │   parallelism: 2
   9 │   template:
  10 │     spec:
  11 │       restartPolicy: Never
  12 │       subdomain: multinode-svc
  13 │       containers:
  14 └       - image: kato0209/gpu_test:latest
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "multinode" of job "multinode-job" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): job multinode-job in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpu_test_1.yaml:4
────────────────────────────────────────
   4 [   name: multinode-job
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container multinode-job in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): job multinode-job in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpu_test_1.yaml:11-35
────────────────────────────────────────
  11 ┌       restartPolicy: Never
  12 │       subdomain: multinode-svc
  13 │       containers:
  14 │       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 └         - name: MASTER_PORT
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container multinode in job multinode-job (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gpu_test_1.yaml:14-35
────────────────────────────────────────
  14 ┌       - image: kato0209/gpu_test:latest
  15 │         name: multinode
  16 │         env:
  17 │         - name: MASTER_ADDR
  18 │           value: multinode-job-0.multinode-svc.default.svc.cluster.local
  19 │         - name: MASTER_PORT
  20 │           value: '29500'
  21 │         - name: NNODES
  22 └           value: '2'
  ..   
────────────────────────────────────────



gpupod.yaml (kubernetes)
========================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'cuda-container' of 'pod' 'gpu-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'cuda-container' of Pod 'gpu-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gpupod.yaml:6-16
────────────────────────────────────────
   6 ┌   restartPolicy: Never
   7 │   containers:
   8 │     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1 # requesting 1 GPU
  13 │   tolerations:
  14 └   - key: nvidia.com/gpu
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "cuda-container" of pod "gpu-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod gpu-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gpupod.yaml:4
────────────────────────────────────────
   4 [   name: gpu-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gpu-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod gpu-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gpupod.yaml:6-16
────────────────────────────────────────
   6 ┌   restartPolicy: Never
   7 │   containers:
   8 │     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 │           nvidia.com/gpu: 1 # requesting 1 GPU
  13 │   tolerations:
  14 └   - key: nvidia.com/gpu
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container cuda-container in pod gpu-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gpupod.yaml:8-12
────────────────────────────────────────
   8 ┌     - name: cuda-container
   9 │       image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
  10 │       resources:
  11 │         limits:
  12 └           nvidia.com/gpu: 1 # requesting 1 GPU
────────────────────────────────────────



graceful-termination.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 graceful-termination.yaml:7-10
────────────────────────────────────────
   7 ┌   ports:
   8 │   - port: 8081
   9 │   selector:
  10 └     app: graceful-term-server
────────────────────────────────────────



graceful-termination_1.yaml (kubernetes)
========================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'server' of Pod 'graceful-term-server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'server' of Pod 'graceful-term-server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'server' of 'pod' 'graceful-term-server' in 'test' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'server' of Pod 'graceful-term-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'server' of Pod 'graceful-term-server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'server' of Pod 'graceful-term-server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'server' of Pod 'graceful-term-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'server' of Pod 'graceful-term-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'server' of Pod 'graceful-term-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'server' of Pod 'graceful-term-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'server' of Pod 'graceful-term-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 graceful-termination_1.yaml:9-25
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 └     - /server
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "server" of pod "graceful-term-server" in "test" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container graceful-term-server in test namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod graceful-term-server in test namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 graceful-termination_1.yaml:9-25
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 └     - /server
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container server in pod graceful-term-server (namespace: test) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 graceful-termination_1.yaml:10-18
────────────────────────────────────────
  10 ┌   - name: server
  11 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  12 │     imagePullPolicy: IfNotPresent
  13 │     ports:
  14 │     - containerPort: 8081
  15 │       protocol: TCP
  16 │     command:
  17 │     - /server
  18 └     - '8081'
────────────────────────────────────────



graceful-termination_2.yaml (kubernetes)
========================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'client' of Pod 'graceful-term-client' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'client' of Pod 'graceful-term-client' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'client' of 'pod' 'graceful-term-client' in 'test' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'client' of Pod 'graceful-term-client' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'client' of Pod 'graceful-term-client' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'client' of Pod 'graceful-term-client' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'client' of Pod 'graceful-term-client' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'client' of Pod 'graceful-term-client' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'client' of Pod 'graceful-term-client' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'client' of Pod 'graceful-term-client' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'client' of Pod 'graceful-term-client' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 graceful-termination_2.yaml:9-17
────────────────────────────────────────
   9 ┌   restartPolicy: OnFailure
  10 │   terminationGracePeriodSeconds: 0
  11 │   containers:
  12 │   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "client" of pod "graceful-term-client" in "test" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container graceful-term-client in test namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod graceful-term-client in test namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 graceful-termination_2.yaml:9-17
────────────────────────────────────────
   9 ┌   restartPolicy: OnFailure
  10 │   terminationGracePeriodSeconds: 0
  11 │   containers:
  12 │   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container client in pod graceful-term-client (namespace: test) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 graceful-termination_2.yaml:12-17
────────────────────────────────────────
  12 ┌   - name: client
  13 │     image: docker.io/cilium/graceful-termination-test-apps:1.0.0
  14 │     imagePullPolicy: IfNotPresent
  15 │     command:
  16 │     - /client
  17 └     - graceful-term-svc.default.svc.cluster.local.:8081
────────────────────────────────────────



grade-submission-api-config.yaml (kubernetes)
=============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'grade-submission-api-config' in 'grade-submission' namespace stores sensitive contents in key(s) or value(s) '{"MONGODB_PORT"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



grade-submission-api-config1.yaml (kubernetes)
==============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'grade-submission-api-config' in 'grade-submission' namespace stores sensitive contents in key(s) or value(s) '{"MONGODB_PORT"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



grade-submission-api-config2.yaml (kubernetes)
==============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'grade-submission-api-config' in 'grade-submission' namespace stores sensitive contents in key(s) or value(s) '{"MONGODB_PORT"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



grade-submission-api-deployment.yaml (kubernetes)
=================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment.yaml:7-28
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: backend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment.yaml:18-28
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 └             memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment.yaml:19-28
────────────────────────────────────────
  19 ┌       - name: grade-submission-api
  20 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  21 │         resources:
  22 │           requests:
  23 │             memory: "128Mi"
  24 │             cpu: "128m"
  25 │           limits:
  26 │             memory: "128Mi"
  27 │         ports:
  28 └           - containerPort: 3000
────────────────────────────────────────



grade-submission-api-deployment1.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:7-33
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 50%
  15 └       maxSurge: 1 ## ensure that we do not have more than 3 pod replicas
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:23-33
────────────────────────────────────────
  23 ┌       containers:
  24 │       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 └             memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment1.yaml:24-33
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateful
  26 │         resources:
  27 │           requests:
  28 │             memory: "128Mi"
  29 │             cpu: "128m"
  30 │           limits:
  31 │             memory: "128Mi"
  32 │         ports:
  33 └           - containerPort: 3000
────────────────────────────────────────



grade-submission-api-deployment2.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:7-45
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 50%
  15 └       maxSurge: 1 ## ensure that we do not have more than 3 pod replicas
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:23-45
────────────────────────────────────────
  23 ┌       containers:
  24 │       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment2.yaml:24-45
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-api-deployment3.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:7-54
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 50%
  15 └       maxSurge: 1 ## ensure that we do not have more than 3 pod replicas
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:23-54
────────────────────────────────────────
  23 ┌       containers:
  24 │       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment3.yaml:24-54
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-api-deployment4.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:7-50
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 50%
  15 └       maxSurge: 1 ## ensure that we do not have more than 3 pod replicas
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:23-50
────────────────────────────────────────
  23 ┌       containers:
  24 │       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment4.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-api-deployment5.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:7-50
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 50%
  15 └       maxSurge: 1 ## ensure that we do not have more than 3 pod replicas
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:23-50
────────────────────────────────────────
  23 ┌       containers:
  24 │       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment5.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-api-deployment6.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'deployment' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Deployment 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:7-50
────────────────────────────────────────
   7 ┌   replicas: 2
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-api
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 50%
  15 └       maxSurge: 1 ## ensure that we do not have more than 3 pod replicas
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of deployment "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:23-50
────────────────────────────────────────
  23 ┌       containers:
  24 │       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in deployment grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-deployment6.yaml:24-50
────────────────────────────────────────
  24 ┌       - name: grade-submission-api
  25 │         image: rslim087/kubernetes-course-grade-submission-api:stateless-v3
  26 │         livenessProbe:
  27 │           httpGet:
  28 │             path: /healthz
  29 │             port: 3000
  30 │           initialDelaySeconds: 15
  31 │           periodSeconds: 5
  32 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-api-pod.yaml (kubernetes)
==========================================
Tests: 129 (SUCCESSES: 99, FAILURES: 30)
Failures: 30 (UNKNOWN: 0, LOW: 16, MEDIUM: 9, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'pod' 'grade-submission-api' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api-health-checker' of 'pod' 'grade-submission-api' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api-health-checker' of Pod 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-pod.yaml:10-28
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of pod "grade-submission-api" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api-health-checker" of pod "grade-submission-api" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod grade-submission-api in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 grade-submission-api-pod.yaml:4-8
────────────────────────────────────────
   4 ┌   name: grade-submission-api
   5 │   labels:
   6 │     app.kubernetes.io/name: grade-submission
   7 │     app.kubernetes.io/component: backend
   8 └     app.kubernetes.io/instance: grade-submission-api
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod grade-submission-api in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod.yaml:10-28
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in pod grade-submission-api (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api-health-checker in pod grade-submission-api (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-api-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-api-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────



grade-submission-api-pod1.yaml (kubernetes)
===========================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 9, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'pod' 'grade-submission-api' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-pod1.yaml:10-20
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of pod "grade-submission-api" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod grade-submission-api in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 grade-submission-api-pod1.yaml:4-8
────────────────────────────────────────
   4 ┌   name: grade-submission-api
   5 │   labels:
   6 │     app.kubernetes.io/name: grade-submission
   7 │     app.kubernetes.io/component: backend
   8 └     app.kubernetes.io/instance: grade-submission-api
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod grade-submission-api in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod1.yaml:10-20
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in pod grade-submission-api (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-pod1.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-api
  12 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "128m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 3000
────────────────────────────────────────



grade-submission-api-pod2.yaml (kubernetes)
===========================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-api' of 'pod' 'grade-submission-api' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-api' of Pod 'grade-submission-api' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-pod2.yaml:11-21
────────────────────────────────────────
  11 ┌   containers:
  12 │   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-api" of pod "grade-submission-api" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-api in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod grade-submission-api in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-api-pod2.yaml:11-21
────────────────────────────────────────
  11 ┌   containers:
  12 │   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-api in pod grade-submission-api (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-api-pod2.yaml:12-21
────────────────────────────────────────
  12 ┌   - name: grade-submission-api
  13 │     image: rslim087/kubernetes-course-grade-submission-api:stateless
  14 │     resources:
  15 │       requests:
  16 │         memory: "128Mi"
  17 │         cpu: "128m"
  18 │       limits:
  19 │         memory: "128Mi"
  20 │     ports:
  21 └       - containerPort: 3000
────────────────────────────────────────



grade-submission-api-service.yaml (kubernetes)
==============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service.yaml:6-10
────────────────────────────────────────
   6 ┌   selector:
   7 │     app.kubernetes.io/instance: grade-submission-api
   8 │   ports:
   9 │   - port: 3000
  10 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service1.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service1.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service2.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service2.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service3.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service3.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service4.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service4.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service5.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service5.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service6.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service6.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service7.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service7.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-api-service8.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-api-service8.yaml:7-11
────────────────────────────────────────
   7 ┌   selector:
   8 │     app.kubernetes.io/instance: grade-submission-api
   9 │   ports:
  10 │   - port: 3000
  11 └     targetPort: 3000
────────────────────────────────────────



grade-submission-portal-deployment.yaml (kubernetes)
====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:7-31
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:18-31
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 └             memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────



grade-submission-portal-deployment1.yaml (kubernetes)
=====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:7-31
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:18-31
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 └             memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment1.yaml:19-31
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         env:
  22 │           - name: GRADE_SERVICE_HOST
  23 │             value: grade-submission-api
  24 │         resources:
  25 │           requests:
  26 │             memory: "128Mi"
  27 └             cpu: "200m"
  ..   
────────────────────────────────────────



grade-submission-portal-deployment2.yaml (kubernetes)
=====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:7-42
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:18-42
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment2.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-portal-deployment3.yaml (kubernetes)
=====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:7-42
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:18-42
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment3.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-portal-deployment4.yaml (kubernetes)
=====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:7-42
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:18-42
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment4.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-portal-deployment5.yaml (kubernetes)
=====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:7-42
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:18-42
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment5.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-portal-deployment6.yaml (kubernetes)
=====================================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'deployment' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Deployment 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:7-42
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/instance: grade-submission-portal
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app.kubernetes.io/name: grade-submission
  15 └         app.kubernetes.io/component: frontend
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of deployment "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:18-42
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 └           periodSeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in deployment grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-deployment6.yaml:19-42
────────────────────────────────────────
  19 ┌       - name: grade-submission-portal
  20 │         image: rslim087/kubernetes-course-grade-submission-portal
  21 │         livenessProbe:
  22 │           httpGet:
  23 │             path: /healthz
  24 │             port: 5001
  25 │           initialDelaySeconds: 15
  26 │           periodSeconds: 5
  27 └         readinessProbe:
  ..   
────────────────────────────────────────



grade-submission-portal-hpa.yaml (kubernetes)
=============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-hpa.yaml:7-19
────────────────────────────────────────
   7 ┌   scaleTargetRef:
   8 │     apiVersion: apps/v1
   9 │     kind: Deployment
  10 │     name: grade-submission-portal
  11 │   minReplicas: 1
  12 │   maxReplicas: 10
  13 │   metrics:
  14 │   - type: Resource
  15 └     resource:
  ..   
────────────────────────────────────────



grade-submission-portal-ingress.yaml (kubernetes)
=================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-ingress.yaml:7-17
────────────────────────────────────────
   7 ┌   ingressClassName: nginx
   8 │   rules:     
   9 │   - http:
  10 │       paths:
  11 │       - pathType: Prefix
  12 │         path: "/"    
  13 │         backend:
  14 │           service:
  15 └             name: grade-submission-portal
  ..   
────────────────────────────────────────



grade-submission-portal-pod.yaml (kubernetes)
=============================================
Tests: 130 (SUCCESSES: 99, FAILURES: 31)
Failures: 31 (UNKNOWN: 0, LOW: 16, MEDIUM: 10, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'pod' 'grade-submission-portal' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal-health-checker' of 'pod' 'grade-submission-portal' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal-health-checker' of Pod 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-pod.yaml:10-28
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of pod "grade-submission-portal" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal-health-checker" of pod "grade-submission-portal" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod grade-submission-portal in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 grade-submission-portal-pod.yaml:4-8
────────────────────────────────────────
   4 ┌   name: grade-submission-portal
   5 │   labels:
   6 │     app.kubernetes.io/name: grade-submission
   7 │     app.kubernetes.io/component: frontend
   8 └     app.kubernetes.io/instance: grade-submission-portal
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod grade-submission-portal in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod.yaml:10-28
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in pod grade-submission-portal (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-pod.yaml:11-20
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     resources:
  14 │       requests:
  15 │         memory: "128Mi"
  16 │         cpu: "200m"
  17 │       limits:
  18 │         memory: "128Mi"
  19 │     ports:
  20 └       - containerPort: 5001  
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal-health-checker in pod grade-submission-portal (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-pod.yaml:21-28
────────────────────────────────────────
  21 ┌   - name: grade-submission-portal-health-checker
  22 │     image: rslim087/kubernetes-course-grade-submission-portal-health-checker
  23 │     resources:
  24 │       requests:
  25 │         memory: "128Mi"
  26 │         cpu: "200m"
  27 │       limits:
  28 └         memory: "128Mi"
────────────────────────────────────────



grade-submission-portal-pod1.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 9, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'pod' 'grade-submission-portal' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:10-23
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of pod "grade-submission-portal" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod grade-submission-portal in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:4-8
────────────────────────────────────────
   4 ┌   name: grade-submission-portal
   5 │   labels:
   6 │     app.kubernetes.io/name: grade-submission
   7 │     app.kubernetes.io/component: frontend
   8 └     app.kubernetes.io/instance: grade-submission-portal
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod grade-submission-portal in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:10-23
────────────────────────────────────────
  10 ┌   containers:
  11 │   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in pod grade-submission-portal (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-pod1.yaml:11-23
────────────────────────────────────────
  11 ┌   - name: grade-submission-portal
  12 │     image: rslim087/kubernetes-course-grade-submission-portal
  13 │     env:
  14 │       - name: GRADE_SERVICE_HOST
  15 │         value: grade-submission-api
  16 │     resources:
  17 │       requests:
  18 │         memory: "128Mi"
  19 └         cpu: "200m"
  ..   
────────────────────────────────────────



grade-submission-portal-pod2.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 100, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 8, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grade-submission-portal' of 'pod' 'grade-submission-portal' in 'grade-submission' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grade-submission-portal' of Pod 'grade-submission-portal' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:11-24
────────────────────────────────────────
  11 ┌   containers:
  12 │   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grade-submission-portal" of pod "grade-submission-portal" in "grade-submission" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grade-submission-portal in grade-submission namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod grade-submission-portal in grade-submission namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:11-24
────────────────────────────────────────
  11 ┌   containers:
  12 │   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 └         memory: "128Mi"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grade-submission-portal in pod grade-submission-portal (namespace: grade-submission) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grade-submission-portal-pod2.yaml:12-24
────────────────────────────────────────
  12 ┌   - name: grade-submission-portal
  13 │     image: rslim087/kubernetes-course-grade-submission-portal
  14 │     env:
  15 │       - name: GRADE_SERVICE_HOST
  16 │         value: grade-submission-api
  17 │     resources:
  18 │       requests:
  19 │         memory: "128Mi"
  20 └         cpu: "200m"
  ..   
────────────────────────────────────────



grade-submission-portal-service.yaml (kubernetes)
=================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service.yaml:6-12
────────────────────────────────────────
   6 ┌   type: NodePort
   7 │   selector:
   8 │     app.kubernetes.io/instance: grade-submission-portal
   9 │   ports:
  10 │   - port: 5001
  11 │     targetPort: 5001
  12 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service1.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service1.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service2.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service2.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service3.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service3.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service4.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service4.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service5.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service5.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service6.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service6.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service7.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service7.yaml:7-13
────────────────────────────────────────
   7 ┌   type: NodePort
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 │     targetPort: 5001
  13 └     nodePort: 32000
────────────────────────────────────────



grade-submission-portal-service8.yaml (kubernetes)
==================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grade-submission-portal-service8.yaml:7-12
────────────────────────────────────────
   7 ┌   type: ClusterIP
   8 │   selector:
   9 │     app.kubernetes.io/instance: grade-submission-portal
  10 │   ports:
  11 │   - port: 5001
  12 └     targetPort: 5001
────────────────────────────────────────



gradio-classify.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gradio' of Deployment 'gradio' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gradio' of 'deployment' 'gradio' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'gradio' of Deployment 'gradio' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gradio' of Deployment 'gradio' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-classify.yaml:6-39
────────────────────────────────────────
   6 ┌   replicas: 5
   7 │   selector:
   8 │     matchLabels:
   9 │       app: gradio
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: gradio
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gradio" of deployment "gradio" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment gradio in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gradio-classify.yaml:4
────────────────────────────────────────
   4 [   name: gradio
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gradio in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-classify.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment gradio in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-classify.yaml:15-39
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 └             secretKeyRef:
  ..   
────────────────────────────────────────



gradio-classify1.yaml (kubernetes)
==================================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gradio' of Deployment 'gradio' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gradio' of 'deployment' 'gradio' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'gradio' of Deployment 'gradio' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gradio' of Deployment 'gradio' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-classify1.yaml:6-39
────────────────────────────────────────
   6 ┌   replicas: 5
   7 │   selector:
   8 │     matchLabels:
   9 │       app: gradio
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: gradio
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gradio" of deployment "gradio" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment gradio in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gradio-classify1.yaml:4
────────────────────────────────────────
   4 [   name: gradio
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gradio in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-classify1.yaml:16-39
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 │             secretKeyRef:
  24 └               name: llm-cluster
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment gradio in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-classify1.yaml:15-39
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: gradio
  17 │         image: ${IMAGE_NAME}
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://sentiment-classification-service
  21 │         - name: OPENAI_API_KEY
  22 │           valueFrom:
  23 └             secretKeyRef:
  ..   
────────────────────────────────────────



gradio-classify1_1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-classify1_1.yaml:6-11
────────────────────────────────────────
   6 ┌   type: LoadBalancer
   7 │   selector:
   8 │     app: gradio
   9 │   ports:
  10 │   - port: 80
  11 └     targetPort: 7860
────────────────────────────────────────



gradio-classify_1.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-classify_1.yaml:6-11
────────────────────────────────────────
   6 ┌   type: LoadBalancer
   7 │   selector:
   8 │     app: gradio
   9 │   ports:
  10 │   - port: 80
  11 └     targetPort: 7860
────────────────────────────────────────



gradio-tgi.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gradio' of Deployment 'gradio' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gradio' of 'deployment' 'gradio' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gradio' of Deployment 'gradio' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-tgi.yaml:6-33
────────────────────────────────────────
   6 ┌   replicas: 3
   7 │   selector:
   8 │     matchLabels:
   9 │       app: gradio
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: gradio
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gradio" of deployment "gradio" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment gradio in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gradio-tgi.yaml:4
────────────────────────────────────────
   4 [   name: gradio
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gradio in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment gradio in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-tgi.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 └         - name: MAX_TOKENS
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container gradio in deployment gradio (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gradio-tgi.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────



gradio-tgi1.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 101, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'gradio' of Deployment 'gradio' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'gradio' of 'deployment' 'gradio' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'gradio' of Deployment 'gradio' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'gradio' of Deployment 'gradio' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-tgi1.yaml:6-33
────────────────────────────────────────
   6 ┌   replicas: 3
   7 │   selector:
   8 │     matchLabels:
   9 │       app: gradio
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: gradio
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "gradio" of deployment "gradio" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment gradio in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 gradio-tgi1.yaml:4
────────────────────────────────────────
   4 [   name: gradio
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container gradio in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment gradio in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 gradio-tgi1.yaml:15-33
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 └         - name: MAX_TOKENS
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container gradio in deployment gradio (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 gradio-tgi1.yaml:16-33
────────────────────────────────────────
  16 ┌       - name: gradio
  17 │         image: docker.io/zaffnet/namudhaj:dev
  18 │         env:
  19 │         - name: MODEL_URL
  20 │           value: http://llm-service
  21 │         - name: MODEL
  22 │           value: llama-2-70b
  23 │         - name: MAX_TOKENS
  24 └           value: '400'
  ..   
────────────────────────────────────────



gradio-tgi1_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-tgi1_1.yaml:6-11
────────────────────────────────────────
   6 ┌   type: LoadBalancer
   7 │   selector:
   8 │     app: gradio
   9 │   ports:
  10 │   - port: 80
  11 └     targetPort: 7860
────────────────────────────────────────



gradio-tgi_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 gradio-tgi_1.yaml:6-11
────────────────────────────────────────
   6 ┌   type: LoadBalancer
   7 │   selector:
   8 │     app: gradio
   9 │   ports:
  10 │   - port: 80
  11 └     targetPort: 7860
────────────────────────────────────────



grafana-base_3.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-base_3.yaml:7-11
────────────────────────────────────────
   7 ┌   accessModes:
   8 │   - ReadWriteOnce
   9 │   resources:
  10 │     requests:
  11 └       storage: 1Gi
────────────────────────────────────────



grafana-chown-job.yaml (kubernetes)
===================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grafana-chown' of Job 'grafana-chown' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grafana-chown' of 'job' 'grafana-chown' in 'kube-ops' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grafana-chown' of Job 'grafana-chown' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grafana-chown' of Job 'grafana-chown' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grafana-chown' of Job 'grafana-chown' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grafana-chown' of Job 'grafana-chown' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-chown-job.yaml:7-22
────────────────────────────────────────
   7 ┌   template:
   8 │     spec:
   9 │       restartPolicy: Never
  10 │       containers:
  11 │       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grafana-chown" of job "grafana-chown" in "kube-ops" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grafana-chown in kube-ops namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grafana-chown-job.yaml:11-18
────────────────────────────────────────
  11 ┌       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 │           subPath: grafana
  18 └           mountPath: /var/lib/grafana
────────────────────────────────────────


AVD-KSV-0118 (HIGH): job grafana-chown in kube-ops namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grafana-chown-job.yaml:9-22
────────────────────────────────────────
   9 ┌       restartPolicy: Never
  10 │       containers:
  11 │       - name: grafana-chown
  12 │         command: ["chown", "-R", "472:472", "/var/lib/grafana"]
  13 │         image: busybox
  14 │         imagePullPolicy: IfNotPresent
  15 │         volumeMounts:
  16 │         - name: storage
  17 └           subPath: grafana
  ..   
────────────────────────────────────────



grafana-claim0-persistentvolumeclaim.yaml (kubernetes)
======================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-claim0-persistentvolumeclaim.yaml:9-13
────────────────────────────────────────
   9 ┌   accessModes:
  10 │     - ReadWriteOnce
  11 │   resources:
  12 │     requests:
  13 └       storage: 100Mi
────────────────────────────────────────



grafana-claim0-persistentvolumeclaim1.yaml (kubernetes)
=======================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-claim0-persistentvolumeclaim1.yaml:9-13
────────────────────────────────────────
   9 ┌   accessModes:
  10 │     - ReadWriteOnce
  11 │   resources:
  12 │     requests:
  13 └       storage: 100Mi
────────────────────────────────────────



grafana-claim0-persistentvolumeclaim2.yaml (kubernetes)
=======================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-claim0-persistentvolumeclaim2.yaml:9-13
────────────────────────────────────────
   9 ┌   accessModes:
  10 │     - ReadWriteOnce
  11 │   resources:
  12 │     requests:
  13 └       storage: 100Mi
────────────────────────────────────────



grafana-claim0-persistentvolumeclaim3.yaml (kubernetes)
=======================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-claim0-persistentvolumeclaim3.yaml:8-12
────────────────────────────────────────
   8 ┌   accessModes:
   9 │     - ReadWriteOnce
  10 │   resources:
  11 │     requests:
  12 └       storage: 100Mi
────────────────────────────────────────



grafana-claim0-persistentvolumeclaim4.yaml (kubernetes)
=======================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-claim0-persistentvolumeclaim4.yaml:8-14
────────────────────────────────────────
   8 ┌   storageClassName: manual
   9 │   volumeName: grafana-pv
  10 │   accessModes:
  11 │     - ReadWriteOnce
  12 │   resources:
  13 │     requests:
  14 └       storage: 1Gi
────────────────────────────────────────



grafana-claim0-persistentvolumeclaim5.yaml (kubernetes)
=======================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-claim0-persistentvolumeclaim5.yaml:8-12
────────────────────────────────────────
   8 ┌   accessModes:
   9 │     - ReadWriteOnce
  10 │   resources:
  11 │     requests:
  12 └       storage: 100Mi
────────────────────────────────────────



grafana-cm4.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'grafana-config' in 'kube-ops' namespace stores sensitive contents in key(s) or value(s) '{"from_address ", "user "}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────


AVD-KSV-0109 (HIGH): ConfigMap 'grafana-config' in 'kube-ops' namespace stores secrets in key(s) or value(s) '{"password "}'
════════════════════════════════════════
Storing secrets in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-0109
────────────────────────────────────────



grafana-configmap2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0109 (HIGH): ConfigMap 'grafana-config' in 'default' namespace stores secrets in key(s) or value(s) '{"GF_SECURITY_ADMIN_PASSWORD"}'
════════════════════════════════════════
Storing secrets in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-0109
────────────────────────────────────────



grafana-daemon-set.yaml (kubernetes)
====================================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 9, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'grafana-container' of 'daemonset' 'grafana-daemon-set' in 'grafana' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'grafana-container' of DaemonSet 'grafana-daemon-set' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-daemon-set.yaml:9-27
────────────────────────────────────────
   9 ┌   selector:
  10 │     matchLabels: 
  11 │       monitor: grafana
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         monitor: grafana
  16 │     spec:
  17 └       nodeSelector: #this will select the node for which the pod will be created in
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "grafana-container" of daemonset "grafana-daemon-set" in "grafana" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container grafana-daemon-set in grafana namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): daemonset grafana-daemon-set in grafana namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 grafana-daemon-set.yaml:17-27
────────────────────────────────────────
  17 ┌       nodeSelector: #this will select the node for which the pod will be created in
  18 │         app: grafana
  19 │       containers:
  20 │       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 └             cpu: "250m"
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container grafana-container in daemonset grafana-daemon-set (namespace: grafana) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 grafana-daemon-set.yaml:20-27
────────────────────────────────────────
  20 ┌       - name: grafana-container
  21 │         image: grafana/grafana:latest
  22 │         resources:
  23 │           limits:
  24 │             memory: "128Mi"
  25 │             cpu: "250m"
  26 │         ports:
  27 └         - containerPort: 3000
────────────────────────────────────────



grafana-dashboard.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 grafana-dashboard.yaml:14-29
────────────────────────────────────────
  14 ┌   ingressClassName: traefik
  15 │   rules:
  16 │   - host: dashboard.marks.dev
  17 │     http:
  18 │       paths:
  19 │       - path: /
  20 │         pathType: Prefix
  21 │         backend:
  22 └           service:
  ..   
────────────────────────────────────────


