
Report Summary

┌───────────────────────────────────────────────────┬────────────┬───────────────────┐
│                      Target                       │    Type    │ Misconfigurations │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-Binding1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-Binding10.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-Binding4.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-Binding7.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-application-controller.yaml           │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-applicationset-controller.yaml        │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-dex-server.yaml                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-notifications-controller.yaml         │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-redis-secret-init.yaml                │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-repo-server.yaml                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-argocd-server.yaml                           │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-cilium-config-agent.yaml                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-cilium-operator-tlsinterception-secrets.yaml │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-cilium-tlsinterception-secrets.yaml          │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-hubble-generate-certs.yaml                   │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-operator.yaml                                │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role-proxies.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role.pod-reader.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role1100.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role114.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role15.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role269.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role33.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role487.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role489.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role490.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role491.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ Role492.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ re_utilize.yaml                                   │ kubernetes │        14         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews-v2-deployment.yaml                        │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews-v2.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews-v21.yaml                                  │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews-v22.yaml                                  │ kubernetes │        50         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews-v3-deployment.yaml                        │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews-v3.yaml                                   │ kubernetes │        50         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews1.yaml                                     │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews1_1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews2.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews2_1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews2_2.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews2_3.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews2_4.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews3.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews3_1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews3_2.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews3_3.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews3_4.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews5.yaml                                     │ kubernetes │        17         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews5_1.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews5_2.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews5_3.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews6.yaml                                     │ kubernetes │        13         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews7.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews7_1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews7_2.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews7_3.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews7_4.yaml                                   │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews_2.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews_3.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ reviews_4.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ revproxy-dev.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite-based-ingress.yaml                        │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite-based-ingress1.yaml                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite-based-ingress2.yaml                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite-based-ingress3.yaml                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite-coredns.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite-target-ingress.yaml                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rewrite.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rfc1918.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rfc2136-tsig-secret.yaml                          │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rfs-itframe-redis.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rgw-external_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rgw-external_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rgw-nodeport-service.yaml                         │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rh-subscription-secret.yaml                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ricardo-pods.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ricardo-pods1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ricardo-pods1_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ricardo-pods_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ right.yaml                                        │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ right_1.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ right_2.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ right_3.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rightdevops-configmap.yaml                        │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rightdevops-deployment.yaml                       │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rightdevops-secret.yaml                           │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment.yaml                    │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment1.yaml                   │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment1_1.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment1_2.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment2.yaml                   │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment2_1.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment2_2.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment3.yaml                   │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment3_1.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment3_2.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment_1.yaml                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ risk-predictor-deployment_2.yaml                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rm-reflector-ns.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP-service.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP1.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP10.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP11.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP12.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP13.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP14.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP16.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP17.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP18.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP19.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP2.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP21.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP3.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP5.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP6.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP7.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP8.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-CIP9.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-cip15.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-cip20.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-cip4.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-cluster-ip.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-configmap.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep.yaml                                      │ kubernetes │        16         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep1.yaml                                     │ kubernetes │        16         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep10.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep11.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep12.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep13.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep14.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep15.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep16.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep17.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep18.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep19.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep2.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep20.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep21.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep22.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep23.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep24.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep3.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep5.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep6.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep7.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep8.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-dep9.yaml                                     │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-deployment.yaml                               │ kubernetes │        15         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-lb.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-pv-pvc.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-pv-pvc_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-service.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-service1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-service2.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-service3.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-service4.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-svc.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmq-svc1.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmqdep.yaml                                       │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmqdep1.yaml                                      │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmqdep2.yaml                                      │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmqdep3.yaml                                      │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmqdep4.yaml                                      │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rmqsvc.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rnaseq-nf.yaml                                    │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rng-admin-user.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rng-admin-user_1.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rng-admin-user_2.yaml                             │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rng-admin-user_3.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robohash-deploy.yaml                              │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robohash-deploy1.yaml                             │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robohash-deploy2.yaml                             │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robohash-service.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robohash-service1.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robohash-service2.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ roboshop-rbac.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ roboshop-rbac_1.yaml                              │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ roboshop-rbac_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ roboshop.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ roboshop1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot-deployer-bindings.yaml                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot-deployer.yaml                               │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot-worker-discovery-deploy.yaml                │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot-worker-discovery-service.yaml               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot1-deployment.yaml                            │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot1-service.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot2-deployment.yaml                            │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot2-service.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot3-deployment.yaml                            │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot3-service.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot4-deployment.yaml                            │ kubernetes │        19         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot4-service.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot_editor_role.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ robot_viewer_role.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocketmq-console.yaml                             │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocketmq-service.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocketmqbroker-pod.yaml                           │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocketmqnamesrv-pod.yaml                          │ kubernetes │        18         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocky-nenya.yaml                                  │ kubernetes │        13         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocky-nessa.yaml                                  │ kubernetes │        13         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocky-nienna.yaml                                 │ kubernetes │        13         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ rocky.yaml                                        │ kubernetes │        13         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-0.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-01.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-02.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-03.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-04.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-all-readers.yaml                             │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-anvesh-pod-reader.yaml                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad1.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad10.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad10_1.yaml                                 │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad10_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad11.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad11_1.yaml                                 │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad11_2.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad12.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad12_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad12_2.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad13.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad13_1.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad13_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad14.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad14_1.yaml                                 │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad14_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad15.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad15_1.yaml                                 │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad15_2.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad16.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad16_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad16_2.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad17.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad17_1.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad17_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad18.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad18_1.yaml                                 │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad18_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad19.yaml                                   │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad19_1.yaml                                 │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad19_2.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad1_1.yaml                                  │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad1_2.yaml                                  │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad2.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad2_1.yaml                                  │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad2_2.yaml                                  │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad3.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad3_1.yaml                                  │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad3_2.yaml                                  │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad4.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad4_1.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad4_2.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad5.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad5_1.yaml                                  │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad5_2.yaml                                  │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad6.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad6_1.yaml                                  │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad6_2.yaml                                  │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad7.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad7_1.yaml                                  │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad7_2.yaml                                  │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad8.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad8_1.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad8_2.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad9.yaml                                    │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad9_1.yaml                                  │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad9_2.yaml                                  │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad_1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bad_2.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-auth-reader1.yaml                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-auth-reader3.yaml                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-dev.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-main.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-order-read-pod.yaml                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-reader-student.yaml                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding-user.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding.yaml.verified.yaml                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding11.yaml                               │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding12.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding13.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding14.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding15.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding16.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding17.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding18.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding19.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding2.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding20.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding21.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding22.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding27.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding3.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding31.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding32.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding33.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding34.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding35.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding36.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding37.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding38.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding39.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding41.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding42.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding46.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding47.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding48.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding49.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding5.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding52.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding53.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding54.yaml                               │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding55.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding57.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding58.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding6.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding60.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding61.yaml                               │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding61_1.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding62.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding63.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding64.yaml                               │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding64_1.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding65.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding66.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding66_1.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding6_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding8.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding9.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binding_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings1_1.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings1_2.yaml                             │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings3.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-bindings_2.yaml                              │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binfing.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-binfing_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-cluster-admin.yaml                           │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config.yaml                                  │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config1.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config10.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config10_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config10_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config11.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config11_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config11_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config12.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config12_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config12_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config13.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config13_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config13_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config14.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config14_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config14_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config15.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config15_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config15_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config16.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config16_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config16_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config17.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config17_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config17_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config18.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config18_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config18_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config19.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config19_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config19_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config1_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config1_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config20.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config20_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config20_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config21.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config21_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config21_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config22.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config22_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config22_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config23.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config23_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config23_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config24.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config24_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config24_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config25.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config25_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config25_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config26.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config26_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config26_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config27.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config27_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config27_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config28.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config28_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config28_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config29.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config29_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config29_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config2_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config2_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config3.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config30.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config30_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config30_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config31.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config31_1.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config31_2.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config3_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config3_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config4.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config4_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config4_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config5.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config5_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config5_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config6.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config6_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config6_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config7.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config7_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config7_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config8.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config8_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config8_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config9.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config9_1.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config9_2.yaml                               │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config_1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-config_2.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-create-jobs.yaml                             │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-definition.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-bind.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-namespace.yaml                           │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-namespace1.yaml                          │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-namespace2.yaml                          │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-namespace3.yaml                          │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-namespace4.yaml                          │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev-namespace5.yaml                          │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev.yaml                                     │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev1.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev2.yaml                                    │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev3.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev4.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev5.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-dev6.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-for-binding.yaml                             │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-garnet-operator.yaml                         │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-get-services.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good10.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good10_1.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good10_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good10_3.yaml                                │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good10_4.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good11.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good11_1.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good11_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good11_3.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good12.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good12_1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good13.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good13_1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good13_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good14.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good14_1.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good14_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good14_3.yaml                                │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good14_4.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good15.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good15_1.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good15_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good15_3.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good16.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good16_1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good17.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good17_1.yaml                                │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good17_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good18.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good18_1.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good18_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good18_3.yaml                                │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good18_4.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good19.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good19_1.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good19_2.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good19_3.yaml                                │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good1_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good1_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good2.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good2_1.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good2_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good2_3.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good2_4.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good3.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good3_1.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good3_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good3_3.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good4.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good4_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good5.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good5_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good5_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good6.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good6_1.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good6_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good6_3.yaml                                 │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good6_4.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good7.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good7_1.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good7_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good7_3.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good8.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good8_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good9.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good9_1.yaml                                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good9_2.yaml                                 │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-good_1.yaml                                  │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-main.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-pod-manager.yaml                             │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-pod-reader.yaml                              │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-prod.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-prod1.yaml                                   │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-qdrant-operator.yaml                         │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-qdrant-operator1.yaml                        │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-readers-bind.yaml                            │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-rolebinding-manifests.yaml                   │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-rolebinding-manifests_1.yaml                 │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-rolebinding.yaml                             │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-rolebinding_1.yaml                           │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-rolebindings.yaml                            │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-rolebindings_1.yaml                          │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-sa.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-service-account.yaml                         │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-student-readers.yaml                         │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role-with-exec.yaml                               │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role.yaml                                         │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role.yaml.verified.yaml                           │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role1.yaml                                        │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role10.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role1007.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role104.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role105.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role105_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role106.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role106_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role107.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role108.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role108_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role109.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role11.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role110.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role1101.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role111.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role112.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role115.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role116.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role117.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role123.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role123_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role14.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role146.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role148.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role149.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role153.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role159.yaml                                      │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role16.yaml                                       │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role165.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role166.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role166_1.yaml                                    │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role166_2.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role168.yaml                                      │ kubernetes │         5         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role169.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role17.yaml                                       │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role171.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role172.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role173.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role174.yaml                                      │ kubernetes │        10         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role175.yaml                                      │ kubernetes │        10         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role176.yaml                                      │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role177.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role178.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role179.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role18.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role180.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role181.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role182.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role187.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role189.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role189_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role19.yaml                                       │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role190.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role192.yaml                                      │ kubernetes │         5         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role193.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role199.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role20.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role200.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role201.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role21.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role214.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role215.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role216.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role217.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role218.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role219.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role22.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role226.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role227.yaml                                      │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role23.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role232.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role233.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role234.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role235.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role236.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role237.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role239.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role24.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role242.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role243.yaml                                      │ kubernetes │         8         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role244.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role245.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role247.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role25.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role254.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role254_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role254_2.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role255.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role256.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role257.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role258.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role259.yaml                                      │ kubernetes │         7         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role26.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role261.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role266.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role27.yaml                                       │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role270.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role28.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role281.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role282.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role283.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role284.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role285.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role289.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role29.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role30.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role309.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role31.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role310.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role311.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role312.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role314.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role319.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role32.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role320.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role321.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role322.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role323.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role330.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role34.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role340.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role341.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role342.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role343.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role344.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role345.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role346.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role348.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role349.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role34_1.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role35.yaml                                       │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role356.yaml                                      │ kubernetes │         5         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role357.yaml                                      │ kubernetes │         9         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role36.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role361.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role362.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role363.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role364.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role365.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role367.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role368.yaml                                      │ kubernetes │         7         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role369.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role37.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role370.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role371.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role374.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role375.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role379.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role38.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role380.yaml                                      │ kubernetes │        13         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role381.yaml                                      │ kubernetes │         7         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role382.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role383.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role417.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role423.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role424.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role425.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role426.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role427.yaml                                      │ kubernetes │         5         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role430.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role439.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role439_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role440.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role441.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role442.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role443.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role445.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role446.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role448.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role449.yaml                                      │ kubernetes │         5         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role453.yaml                                      │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role455.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role456.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role459.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role460.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role461.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role461_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role462.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role463.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role464.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role465.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role466.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role468.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role469.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role470.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role471.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role472.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role473.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role474.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role475.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role476.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role477.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role478.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role479.yaml                                      │ kubernetes │         7         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role480.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role49.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role494.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role495.yaml                                      │ kubernetes │        10         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role499.yaml                                      │ kubernetes │         7         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role50.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role500.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role50_1.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role51.yaml                                       │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role51_1.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role52.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role521.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role521_1.yaml                                    │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role522.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role523.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role524.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role525.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role526.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role527.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role528.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role529.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role53.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role530.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role531.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role532.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role533.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role534.yaml                                      │ kubernetes │         5         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role535.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role536.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role537.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role538.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role539.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role53_1.yaml                                     │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role54.yaml                                       │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role540.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role541.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role542.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role544.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role55.yaml                                       │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role551.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role557.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role559.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role56.yaml                                       │ kubernetes │         6         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role564.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role565.yaml                                      │ kubernetes │         3         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role566.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role567.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role572.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role573.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role574.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role575.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role576.yaml                                      │ kubernetes │         4         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role578.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role582.yaml                                      │ kubernetes │         0         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role583.yaml                                      │ kubernetes │         1         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role584.yaml                                      │ kubernetes │         2         │
├───────────────────────────────────────────────────┼────────────┼───────────────────┤
│ role585.yaml                                      │ kubernetes │         4         │
└───────────────────────────────────────────────────┴────────────┴───────────────────┘
Legend:
- '-': Not scanned
- '0': Clean (no security findings detected)


Role-argocd-application-controller.yaml (kubernetes)
====================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-application-controller.yaml:12-20
────────────────────────────────────────
  12 ┌   - apiGroups:
  13 │       - ""
  14 │     resources:
  15 │       - secrets
  16 │       - configmaps
  17 │     verbs:
  18 │       - get
  19 │       - list
  20 └       - watch
────────────────────────────────────────



Role-argocd-applicationset-controller.yaml (kubernetes)
=======================================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-applicationset-controller' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 Role-argocd-applicationset-controller.yaml:52-63
────────────────────────────────────────
  52 ┌   - apiGroups:
  53 │       - ""
  54 │     resources:
  55 │       - configmaps
  56 │     verbs:
  57 │       - create
  58 │       - update
  59 │       - delete
  60 └       - get
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-applicationset-controller.yaml:64-71
────────────────────────────────────────
  64 ┌   - apiGroups:
  65 │       - ""
  66 │     resources:
  67 │       - secrets
  68 │     verbs:
  69 │       - get
  70 │       - list
  71 └       - watch
────────────────────────────────────────



Role-argocd-dex-server.yaml (kubernetes)
========================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-dex-server.yaml:12-20
────────────────────────────────────────
  12 ┌   - apiGroups:
  13 │       - ""
  14 │     resources:
  15 │       - secrets
  16 │       - configmaps
  17 │     verbs:
  18 │       - get
  19 │       - list
  20 └       - watch
────────────────────────────────────────



Role-argocd-notifications-controller.yaml (kubernetes)
======================================================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-notifications-controller.yaml:23-30
────────────────────────────────────────
  23 ┌   - apiGroups:
  24 │       - ""
  25 │     resources:
  26 │       - configmaps
  27 │       - secrets
  28 │     verbs:
  29 │       - list
  30 └       - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-notifications-controller.yaml:39-46
────────────────────────────────────────
  39 ┌   - apiGroups:
  40 │       - ""
  41 │     resourceNames:
  42 │       - argocd-notifications-secret
  43 │     resources:
  44 │       - secrets
  45 │     verbs:
  46 └       - get
────────────────────────────────────────



Role-argocd-redis-secret-init.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-redis-secret-init' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-redis-secret-init.yaml:15-22
────────────────────────────────────────
  15 ┌   - apiGroups:
  16 │       - ""
  17 │     resourceNames:
  18 │       - argocd-redis
  19 │     resources:
  20 │       - secrets
  21 │     verbs:
  22 └       - get
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-redis-secret-init' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-redis-secret-init.yaml:23-28
────────────────────────────────────────
  23 ┌   - apiGroups:
  24 │       - ""
  25 │     resources:
  26 │       - secrets
  27 │     verbs:
  28 └       - create
────────────────────────────────────────



Role-argocd-server.yaml (kubernetes)
====================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 Role-argocd-server.yaml:12-24
────────────────────────────────────────
  12 ┌   - apiGroups:
  13 │       - ""
  14 │     resources:
  15 │       - secrets
  16 │       - configmaps
  17 │     verbs:
  18 │       - create
  19 │       - get
  20 └       - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'argocd'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-argocd-server.yaml:12-24
────────────────────────────────────────
  12 ┌   - apiGroups:
  13 │       - ""
  14 │     resources:
  15 │       - secrets
  16 │       - configmaps
  17 │     verbs:
  18 │       - create
  19 │       - get
  20 └       - list
  ..   
────────────────────────────────────────



Role-cilium-operator-tlsinterception-secrets.yaml (kubernetes)
==============================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'cilium-operator-tlsinterception-secrets' shouldn't have access to manage secrets in namespace 'cilium-secrets'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-cilium-operator-tlsinterception-secrets.yaml:9-17
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - secrets
  13 │     verbs:
  14 │       - create
  15 │       - delete
  16 │       - update
  17 └       - patch
────────────────────────────────────────



Role-cilium-tlsinterception-secrets.yaml (kubernetes)
=====================================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'cilium-tlsinterception-secrets' shouldn't have access to manage secrets in namespace 'cilium-secrets'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-cilium-tlsinterception-secrets.yaml:9-16
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - secrets
  13 │     verbs:
  14 │       - get
  15 │       - list
  16 └       - watch
────────────────────────────────────────



Role-hubble-generate-certs.yaml (kubernetes)
============================================
Tests: 116 (SUCCESSES: 113, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'hubble-generate-certs' shouldn't have access to manage secrets in namespace 'kube-system'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-hubble-generate-certs.yaml:9-14
────────────────────────────────────────
   9 ┌   - apiGroups:
  10 │       - ""
  11 │     resources:
  12 │       - secrets
  13 │     verbs:
  14 └       - create
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'hubble-generate-certs' shouldn't have access to manage secrets in namespace 'kube-system'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-hubble-generate-certs.yaml:15-26
────────────────────────────────────────
  15 ┌   - apiGroups:
  16 │       - ""
  17 │     resourceNames:
  18 │       - hubble-server-certs
  19 │       - hubble-relay-client-certs
  20 │       - hubble-relay-server-certs
  21 │       - hubble-metrics-server-certs
  22 │       - hubble-ui-client-certs
  23 └     resources:
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'hubble-generate-certs' shouldn't have access to manage secrets in namespace 'kube-system'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-hubble-generate-certs.yaml:27-35
────────────────────────────────────────
  27 ┌   - apiGroups:
  28 │       - ""
  29 │     resourceNames:
  30 │       - cilium-ca
  31 │     resources:
  32 │       - secrets
  33 │     verbs:
  34 │       - get
  35 └       - update
────────────────────────────────────────



Role-operator.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 1, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 Role-operator.yaml:22-30
────────────────────────────────────────
  22 ┌   - apiGroups:
  23 │       - ""
  24 │     resources:
  25 │       - pods
  26 │     verbs:
  27 │       - get
  28 │       - list
  29 │       - watch
  30 └       - update
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 Role-operator.yaml:37-50
────────────────────────────────────────
  37 ┌   - apiGroups:
  38 │       - apps
  39 │     resources:
  40 │       - statefulsets
  41 │       - deployments
  42 │     verbs:
  43 │       - create
  44 │       - delete
  45 └       - deletecollection
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 Role-operator.yaml:7-21
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │       - ""
   9 │     resources:
  10 │       - secrets
  11 │       - serviceaccounts
  12 │       - configmaps
  13 │     verbs:
  14 │       - create
  15 └       - delete
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): Role 'operator' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 Role-operator.yaml:62-73
────────────────────────────────────────
  62 ┌   - apiGroups:
  63 │       - rbac.authorization.k8s.io
  64 │     resources:
  65 │       - roles
  66 │       - rolebindings
  67 │     verbs:
  68 │       - get
  69 │       - create
  70 └       - patch
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 Role-operator.yaml:51-61
────────────────────────────────────────
  51 ┌   - apiGroups:
  52 │       - discovery.k8s.io
  53 │     resources:
  54 │       - endpointslices
  55 │     verbs:
  56 │       - get
  57 │       - list
  58 │       - watch
  59 └       - create
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'operator' shouldn't have access to manage secrets in namespace 'tailscale'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-operator.yaml:7-21
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │       - ""
   9 │     resources:
  10 │       - secrets
  11 │       - serviceaccounts
  12 │       - configmaps
  13 │     verbs:
  14 │       - create
  15 └       - delete
  ..   
────────────────────────────────────────



Role-proxies.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'proxies' shouldn't have access to manage secrets in namespace 'tailscale'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role-proxies.yaml:7-19
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │       - ""
   9 │     resources:
  10 │       - secrets
  11 │     verbs:
  12 │       - create
  13 │       - delete
  14 │       - deletecollection
  15 └       - get
  ..   
────────────────────────────────────────



Role114.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role '<role_name>' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 Role114.yaml:9-12
────────────────────────────────────────
   9 ┌   - apiGroups: [""] #leave it blank for core apiGroup
  10 │     resources: ["pods"]
  11 │     verbs: ["list", "create", "update", "delete", "get"]
  12 └     resourceNames: ["red", "orange"] # Optional field to restrict access to specific resources
────────────────────────────────────────



Role269.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'secrets-editor-cronjob' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 Role269.yaml:7-13
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources:
   9 │       - secrets
  10 │     verbs:
  11 │       - 'patch'
  12 │       - 'get'
  13 └       - 'create'
────────────────────────────────────────



re_utilize.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 101, FAILURES: 14)
Failures: 14 (UNKNOWN: 0, LOW: 7, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'busybox' of Pod 'resource-consuming-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'busybox' of Pod 'resource-consuming-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'busybox' of 'pod' 'resource-consuming-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'busybox' of Pod 'resource-consuming-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'busybox' of Pod 'resource-consuming-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'busybox' of Pod 'resource-consuming-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'busybox' of Pod 'resource-consuming-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'busybox' of Pod 'resource-consuming-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "busybox" of pod "resource-consuming-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod resource-consuming-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 re_utilize.yaml:4
────────────────────────────────────────
   4 [   name: resource-consuming-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container resource-consuming-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 re_utilize.yaml:7-16
────────────────────────────────────────
   7 ┌   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 │       requests:
  15 │         memory: "2.23Gi"
  16 └         cpu: "930m"
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod resource-consuming-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 re_utilize.yaml:6-16
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: busybox
   8 │     image: busybox
   9 │     command: ["/bin/sh", "-c", "while true; do openssl prime 99999999999999999999999999999999999999999999999999999999999999999999999999999999; done"]
  10 │     resources:
  11 │       limits:
  12 │         memory: "2.23Gi"
  13 │         cpu: "930m"
  14 └       requests:
  ..   
────────────────────────────────────────



reviews-v2-deployment.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 96, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 2, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews-v2-deployment.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v2-deployment.yaml:20-40
────────────────────────────────────────
  20 ┌       containers:
  21 │       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 └         - containerPort: 9080
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v2-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v2
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews-v2.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews-v2.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v2.yaml:20-26
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v2.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────



reviews-v21.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews-v21.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v21.yaml:20-26
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v21.yaml:22-26
────────────────────────────────────────
  22 ┌         - name: reviews
  23 │           image: docker.io/istio/examples-bookinfo-reviews-v2:1.15.0
  24 │           imagePullPolicy: IfNotPresent
  25 │           ports:
  26 └             - containerPort: 9080
────────────────────────────────────────



reviews-v22.yaml (kubernetes)
=============================
Tests: 145 (SUCCESSES: 95, FAILURES: 50)
Failures: 50 (UNKNOWN: 0, LOW: 31, MEDIUM: 13, HIGH: 6, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'envoy-init' of Pod 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'productpage' of Pod 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'productpage' of Pod 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'envoy-init' of 'pod' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'envoy-proxy' of 'pod' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'productpage' of 'pod' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'productpage' of Pod 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'envoy-init' of Pod 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'productpage' of Pod 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'envoy-init' of Pod 'reviews-v2' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'envoy-init' of Pod 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'productpage' of Pod 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'productpage' of Pod 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'productpage' of Pod 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'envoy-init' of Pod 'reviews-v2' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'productpage' of Pod 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'productpage' of Pod 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'envoy-init' of Pod 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'envoy-proxy' of Pod 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'productpage' of Pod 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "envoy-init" of pod "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "envoy-proxy" of pod "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "productpage" of pod "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews-v22.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   namespace: default
   6 │   labels:
   7 └     app: reviews
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v22.yaml:9-23
────────────────────────────────────────
   9 ┌   containers:
  10 │     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 │           protocol: tcp
  15 │     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 └       securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container envoy-init in pod reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v22.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container envoy-proxy in pod reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v22.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container productpage in pod reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v22.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v2:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────



reviews-v3-deployment.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 96, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 2, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews-v3-deployment.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v3
   5 │   labels:
   6 │     app: reviews
   7 └     version: v3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v3-deployment.yaml:20-40
────────────────────────────────────────
  20 ┌       containers:
  21 │       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 └         - containerPort: 9080
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v3-deployment.yaml:21-35
────────────────────────────────────────
  21 ┌       - name: reviews
  22 │         image: javierteleco/g47-reviews-v3
  23 │         imagePullPolicy: IfNotPresent
  24 │         env:
  25 │         - name: LOG_DIR
  26 │           value: /tmp/logs
  27 │         ports:
  28 │         - containerPort: 9080
  29 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews-v3.yaml (kubernetes)
============================
Tests: 145 (SUCCESSES: 95, FAILURES: 50)
Failures: 50 (UNKNOWN: 0, LOW: 31, MEDIUM: 13, HIGH: 6, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'envoy-init' of Pod 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'productpage' of Pod 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'productpage' of Pod 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'envoy-init' of 'pod' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'envoy-proxy' of 'pod' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'productpage' of 'pod' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'productpage' of Pod 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'envoy-init' of Pod 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'productpage' of Pod 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'envoy-init' of Pod 'reviews-v3' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'envoy-init' of Pod 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'productpage' of Pod 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'productpage' of Pod 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'productpage' of Pod 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'envoy-init' of Pod 'reviews-v3' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'productpage' of Pod 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'productpage' of Pod 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'envoy-init' of Pod 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'envoy-proxy' of Pod 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'productpage' of Pod 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "envoy-init" of pod "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "envoy-proxy" of pod "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "productpage" of pod "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod reviews-v3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews-v3.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v3
   5 │   namespace: default
   6 │   labels:
   7 └     app: reviews
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v3 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod reviews-v3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews-v3.yaml:9-23
────────────────────────────────────────
   9 ┌   containers:
  10 │     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 │           protocol: tcp
  15 │     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 └       securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container envoy-init in pod reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v3.yaml:20-23
────────────────────────────────────────
  20 ┌     - name: envoy-init
  21 │       image: sjtuzc/envoy-init:latest
  22 │       securityContext:
  23 └         privileged: true
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container envoy-proxy in pod reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v3.yaml:15-18
────────────────────────────────────────
  15 ┌     - name: envoy-proxy
  16 │       image: sjtuzc/envoy:1.2
  17 │       securityContext:
  18 └         runAsUser: 1337
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container productpage in pod reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews-v3.yaml:10-14
────────────────────────────────────────
  10 ┌     - name: productpage
  11 │       image: istio/examples-bookinfo-reviews-v3:1.19.1
  12 │       ports:
  13 │         - containerPort: 9080
  14 └           protocol: tcp
────────────────────────────────────────



reviews1.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'reviews' of Deployment 'reviews' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews1.yaml:4
────────────────────────────────────────
   4 [   name: reviews
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews1.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: reviews
  17 │         image: smarthotels/reviews:latest
  18 │         ports:
  19 └         - containerPort: 8080
────────────────────────────────────────



reviews2_2.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews2_2.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v1
   5 │   labels:
   6 │     app: reviews
   7 └     version: v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews2_2.yaml:20-41
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         - name: SERVICES_DOMAIN
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v1 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews2_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────



reviews2_3.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews2_3.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews2_3.yaml:20-41
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         - name: SERVICES_DOMAIN
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews2_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────



reviews2_4.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews2_4.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v3
   5 │   labels:
   6 │     app: reviews
   7 └     version: v3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v3 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews2_4.yaml:20-41
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         - name: SERVICES_DOMAIN
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews2_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────



reviews3_2.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews3_2.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v1
   5 │   labels:
   6 │     app: reviews
   7 └     version: v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews3_2.yaml:20-39
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v1 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews3_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews3_3.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews3_3.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews3_3.yaml:20-39
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews3_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews3_4.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews3_4.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v3
   5 │   labels:
   6 │     app: reviews
   7 └     version: v3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v3 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews3_4.yaml:20-39
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews3_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews5.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 98, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews-backend' of 'deployment' 'reviews-backend-deployment' in 'library-ns' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews-backend' of Deployment 'reviews-backend-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews-backend" of deployment "reviews-backend-deployment" in "library-ns" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-backend-deployment in library-ns namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-backend-deployment in library-ns namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews5.yaml:18-25
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews-backend in deployment reviews-backend-deployment (namespace: library-ns) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews5.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-backend
  20 │         image: chaphe/backend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 3000
  23 │         env:
  24 │         - name: MONGODB_HOST
  25 └           value: mongo-reviews-service
────────────────────────────────────────



reviews5_1.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews-frontend' of 'deployment' 'reviews-frontend-deployment' in 'library-ns' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews-frontend' of Deployment 'reviews-frontend-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews-frontend" of deployment "reviews-frontend-deployment" in "library-ns" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment reviews-frontend-deployment in library-ns namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-frontend-deployment in library-ns namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-frontend-deployment in library-ns namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews5_1.yaml:18-25
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews-frontend in deployment reviews-frontend-deployment (namespace: library-ns) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews5_1.yaml:19-25
────────────────────────────────────────
  19 ┌       - name: reviews-frontend
  20 │         image: chaphe/frontend-reviews-image:1.0
  21 │         ports:
  22 │         - containerPort: 80
  23 │         env:
  24 │         - name: REVIEWS_URL
  25 └           value: http://172.18.7.169:30200
────────────────────────────────────────



reviews6.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 102, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 6, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'freeln-review' of Deployment 'freeln-review' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'freeln-review' of Deployment 'freeln-review' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'freeln-review' of 'deployment' 'freeln-review' in 'production' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'freeln-review' of Deployment 'freeln-review' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'freeln-review' of Deployment 'freeln-review' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'freeln-review' of Deployment 'freeln-review' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'freeln-review' of Deployment 'freeln-review' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "freeln-review" of deployment "freeln-review" in "production" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container freeln-review in production namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment freeln-review in production namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews6.yaml:21-105
────────────────────────────────────────
  21 ┌       containers:
  22 │         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 └             requests:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container freeln-review in deployment freeln-review (namespace: production) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews6.yaml:22-105
────────────────────────────────────────
  22 ┌         - name: freeln-review
  23 │           image: datz0512/freelancer-review:stable
  24 │           imagePullPolicy: Always
  25 │           resources:
  26 │             limits:
  27 │               memory: '1Gi'
  28 │               cpu: '0.5'
  29 │             requests:
  30 └               cpu: 100m
  ..   
────────────────────────────────────────



reviews7_2.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews7_2.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v1
   5 │   labels:
   6 │     app: reviews
   7 └     version: v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews7_2.yaml:20-39
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v1 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews7_2.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews7_3.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews7_3.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews7_3.yaml:20-39
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews7_3.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews7_4.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews7_4.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v3
   5 │   labels:
   6 │     app: reviews
   7 └     version: v3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v3 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews7_4.yaml:20-39
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews7_4.yaml:22-34
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.18.0
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         ports:
  29 │         - containerPort: 9080
  30 └         volumeMounts:
  ..   
────────────────────────────────────────



reviews_2.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews_2.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v1
   5 │   labels:
   6 │     app: reviews
   7 └     version: v1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews_2.yaml:20-41
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         - name: SERVICES_DOMAIN
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v1 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews_2.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v1:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────



reviews_3.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews_3.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v2
   5 │   labels:
   6 │     app: reviews
   7 └     version: v2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews_3.yaml:20-41
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         - name: SERVICES_DOMAIN
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews_3.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────



reviews_4.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'reviews' of Deployment 'reviews-v3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'reviews' of 'deployment' 'reviews-v3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reviews' of Deployment 'reviews-v3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "reviews" of deployment "reviews-v3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment reviews-v3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 reviews_4.yaml:4-7
────────────────────────────────────────
   4 ┌   name: reviews-v3
   5 │   labels:
   6 │     app: reviews
   7 └     version: v3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container reviews-v3 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment reviews-v3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 reviews_4.yaml:20-41
────────────────────────────────────────
  20 ┌       serviceAccountName: bookinfo-reviews
  21 │       containers:
  22 │       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 └         - name: SERVICES_DOMAIN
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reviews in deployment reviews-v3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 reviews_4.yaml:22-36
────────────────────────────────────────
  22 ┌       - name: reviews
  23 │         image: docker.io/istio/examples-bookinfo-reviews-v3:1.16.2
  24 │         imagePullPolicy: IfNotPresent
  25 │         env:
  26 │         - name: LOG_DIR
  27 │           value: /tmp/logs
  28 │         - name: SERVICES_DOMAIN
  29 │           value: ratings
  30 └         ports:
  ..   
────────────────────────────────────────



right.yaml (kubernetes)
=======================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'deployment' 'nginx-deployment' in 'test' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx' of Deployment 'nginx-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Deployment 'nginx-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of deployment "nginx-deployment" in "test" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment nginx-deployment in test namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nginx-deployment in test namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 right.yaml:19-22
────────────────────────────────────────
  19 ┌       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment nginx-deployment in test namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 right.yaml:18-22
────────────────────────────────────────
  18 ┌       containers:
  19 │       - name: nginx
  20 │         image: nginx:latest
  21 │         ports:
  22 └         - containerPort: 80
────────────────────────────────────────



rightdevops-deployment.yaml (kubernetes)
========================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'right-devops' of 'deployment' 'right-devops-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'right-devops' of Deployment 'right-devops-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'right-devops' of Deployment 'right-devops-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "right-devops" of deployment "right-devops-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment right-devops-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rightdevops-deployment.yaml:4
────────────────────────────────────────
   4 [   name: right-devops-deployment
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container right-devops-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment right-devops-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rightdevops-deployment.yaml:15-37
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 └           env:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container right-devops in deployment right-devops-deployment (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 rightdevops-deployment.yaml:16-33
────────────────────────────────────────
  16 ┌         - name: right-devops
  17 │           image: localhost:5000/right-devops:1.0.0
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           volumeMounts:
  21 │             - name: config-volume
  22 │               mountPath: /config
  23 │           env:
  24 └             - name: SPRING_DATASOURCE_USERNAME
  ..   
────────────────────────────────────────



risk-predictor-deployment.yaml (kubernetes)
===========================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'risk-predictor' of 'deployment' 'risk-predictor' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "risk-predictor" of deployment "risk-predictor" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment risk-predictor in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 risk-predictor-deployment.yaml:4
────────────────────────────────────────
   4 [   name: risk-predictor
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container risk-predictor in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment risk-predictor in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container risk-predictor in deployment risk-predictor (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 risk-predictor-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────



risk-predictor-deployment1.yaml (kubernetes)
============================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'risk-predictor' of 'deployment' 'risk-predictor' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "risk-predictor" of deployment "risk-predictor" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment risk-predictor in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 risk-predictor-deployment1.yaml:4
────────────────────────────────────────
   4 [   name: risk-predictor
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container risk-predictor in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment risk-predictor in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment1.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container risk-predictor in deployment risk-predictor (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 risk-predictor-deployment1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────



risk-predictor-deployment2.yaml (kubernetes)
============================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'risk-predictor' of 'deployment' 'risk-predictor' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "risk-predictor" of deployment "risk-predictor" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment risk-predictor in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 risk-predictor-deployment2.yaml:4
────────────────────────────────────────
   4 [   name: risk-predictor
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container risk-predictor in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment risk-predictor in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment2.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container risk-predictor in deployment risk-predictor (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 risk-predictor-deployment2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────



risk-predictor-deployment3.yaml (kubernetes)
============================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'risk-predictor' of 'deployment' 'risk-predictor' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'risk-predictor' of Deployment 'risk-predictor' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'risk-predictor' of Deployment 'risk-predictor' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "risk-predictor" of deployment "risk-predictor" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment risk-predictor in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 risk-predictor-deployment3.yaml:4
────────────────────────────────────────
   4 [   name: risk-predictor
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container risk-predictor in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment risk-predictor in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 risk-predictor-deployment3.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container risk-predictor in deployment risk-predictor (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 risk-predictor-deployment3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: risk-predictor
  17 │         image: surajkarthicverticurl/risk-predictor:latest
  18 │         ports:
  19 └         - containerPort: 5002
────────────────────────────────────────



rmq-configmap.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0109 (HIGH): ConfigMap 'rmq-configmap' in 'default' namespace stores secrets in key(s) or value(s) '{"RABBITMQ_DEFAULT_PASS"}'
════════════════════════════════════════
Storing secrets in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-0109
────────────────────────────────────────



rmq-dep.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 99, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 9, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep.yaml:17-34
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 └               memory: "128Mi"
  ..   
────────────────────────────────────────



rmq-dep1.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 99, FAILURES: 16)
Failures: 16 (UNKNOWN: 0, LOW: 9, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep1.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep1.yaml:18-34
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 │               memory: "128Mi"
  26 └               cpu: "400m"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep1.yaml:17-34
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           resources:
  24 │             limits:
  25 └               memory: "128Mi"
  ..   
────────────────────────────────────────



rmq-dep10.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep10.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────



rmq-dep11.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep11.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep11.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep11.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep12.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep12.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep12.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep12.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep13.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep13.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep13.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep13.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep14.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep14.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep14.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep14.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep15.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep15.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep15.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep15.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep16.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vproqm01' of Deployment 'vproqm01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vproqm01' of 'deployment' 'vproqm01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vproqm01' of Deployment 'vproqm01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vproqm01' of Deployment 'vproqm01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vproqm01' of Deployment 'vproqm01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vproqm01' of Deployment 'vproqm01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vproqm01" of deployment "vproqm01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vproqm01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep16.yaml:4-6
────────────────────────────────────────
   4 ┌   name:  vproqm01
   5 │   labels:
   6 └     app:  vproqm01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vproqm01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep16.yaml:18-30
────────────────────────────────────────
  18 ┌       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vproqm01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep16.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name:  vproqm01
  19 │         image:  rabbitmq
  20 │         ports:
  21 │         - name: vproqm01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 └             valueFrom:
  ..   
────────────────────────────────────────



rmq-dep17.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep17.yaml:4
────────────────────────────────────────
   4 [   name: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep17.yaml:16-28
────────────────────────────────────────
  16 ┌       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 │             valueFrom:
  24 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep17.yaml:15-28
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: vpromq01
  17 │         image: rabbitmq
  18 │         ports:
  19 │           - name: vpromq01-port
  20 │             containerPort: 15672
  21 │         env:
  22 │           - name: RABBITMQ_DEFAULT_PASS
  23 └             valueFrom:
  ..   
────────────────────────────────────────



rmq-dep18.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep18.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep18.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep18.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep19.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep19.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep19.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep19.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 └            valueFrom:
  ..   
────────────────────────────────────────



rmq-dep2.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep2.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep2.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep2.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 └            valueFrom:
  ..   
────────────────────────────────────────



rmq-dep20.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep20.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └    app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep20.yaml:18-33
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 │         env:
  26 └          - name: RABBITMQ_DEFAULT-PASS
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep20.yaml:17-33
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: vpromq01
  19 │         image: rabbitmq
  20 │         
  21 │         ports:
  22 │         - name: vpromq01-port 
  23 │           containerPort: 15672
  24 │           
  25 └         env:
  ..   
────────────────────────────────────────



rmq-dep21.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep21.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep21.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep21.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 └            valueFrom:
  ..   
────────────────────────────────────────



rmq-dep22.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep22.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep22.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep22.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep23.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rmq01' of Deployment 'rmq-dep' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rmq01' of 'deployment' 'rmq-dep' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rmq01' of Deployment 'rmq-dep' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'rmq01' of Deployment 'rmq-dep' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rmq01' of Deployment 'rmq-dep' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rmq01' of Deployment 'rmq-dep' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rmq01" of deployment "rmq-dep" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rmq-dep in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep23.yaml:4-6
────────────────────────────────────────
   4 ┌   name: rmq-dep
   5 │   labels:
   6 └     app: rmq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rmq-dep in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep23.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rmq-dep in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep23.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: rmq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: rmq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep24.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'apromq01' of Deployment 'apromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'apromq01' of Deployment 'apromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'apromq01' of 'deployment' 'apromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'apromq01' of Deployment 'apromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'apromq01' of Deployment 'apromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'apromq01' of Deployment 'apromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'apromq01' of Deployment 'apromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'apromq01' of Deployment 'apromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'apromq01' of Deployment 'apromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'apromq01' of Deployment 'apromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'apromq01' of Deployment 'apromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'apromq01' of Deployment 'apromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "apromq01" of deployment "apromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment apromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep24.yaml:4-6
────────────────────────────────────────
   4 ┌   name: apromq01
   5 │   labels:
   6 └     app: apromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container apromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep24.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 │            valueFrom:
  26 └              secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment apromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep24.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: apromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: apromq01-port
  22 │           containerPort: 15672
  23 │         env: 
  24 │          - name: RABBITMQ_DEFAULT_PASS
  25 └            valueFrom:
  ..   
────────────────────────────────────────



rmq-dep3.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep3.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep3.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep3.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep5.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep5.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep5.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep5.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep6.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep6.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep6.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep6.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep7.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep7.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep7.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep7.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - containerPort: 15672
  22 │               name: vpromq01-port
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep8.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep8.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep8.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep8.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-dep9.yaml (kubernetes)
==========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-dep9.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep9.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-dep9.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │               containerPort: 15672
  23 │           env:
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmq-deployment.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 100, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 9, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rmq-deployment' of Deployment 'rmq-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rmq-deployment' of 'deployment' 'rmq-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rmq-deployment' of Deployment 'rmq-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rmq-deployment" of deployment "rmq-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rmq-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmq-deployment.yaml:4
────────────────────────────────────────
   4 [   name: rmq-deployment
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rmq-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-deployment.yaml:16-30
────────────────────────────────────────
  16 ┌         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 │               name: rmq-queue
  24 └           envFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rmq-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmq-deployment.yaml:15-34
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: rmq-deployment
  17 │           image: rabbitmq:3.8-management
  18 │           ports:
  19 │             - containerPort: 5672
  20 │             - containerPort: 15672
  21 │           volumeMounts:
  22 │             - mountPath: /data/rmqdata
  23 └               name: rmq-queue
  ..   
────────────────────────────────────────



rmqdep.yaml (kubernetes)
========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmqdep.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels: 
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep.yaml:18-30
────────────────────────────────────────
  18 ┌         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 │               valueFrom:
  26 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │         - name: vpromq01
  19 │           image: rabbitmq
  20 │           ports:
  21 │             - name: vpromq01-port
  22 │             - containerPort: 15672
  23 │           env: 
  24 │             - name: RABBITMQ_DEFAULT_PASS
  25 └               valueFrom:
  ..   
────────────────────────────────────────



rmqdep1.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rmqcontainer' of 'deployment' 'rmqdep' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'rmqcontainer' of Deployment 'rmqdep' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rmqcontainer" of deployment "rmqdep" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rmqdep in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmqdep1.yaml:4
────────────────────────────────────────
   4 [   name: rmqdep
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rmqdep in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rmqdep in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep1.yaml:15-27
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 └                 secretKeyRef:
  ..   
────────────────────────────────────────



rmqdep2.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rmqcontainer' of 'deployment' 'rmqdep' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'rmqcontainer' of Deployment 'rmqdep' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rmqcontainer' of Deployment 'rmqdep' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rmqcontainer" of deployment "rmqdep" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment rmqdep in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmqdep2.yaml:4
────────────────────────────────────────
   4 [   name: rmqdep
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rmqdep in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep2.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 │                 secretKeyRef:
  24 └                   name: secret-file
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment rmqdep in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep2.yaml:15-27
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: rmqcontainer
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - containerPort: 15672
  20 │           env:
  21 │             - name: RABBITMQ_DEFAULT_PASS
  22 │               valueFrom:
  23 └                 secretKeyRef:
  ..   
────────────────────────────────────────



rmqdep3.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmqdep3.yaml:4-6
────────────────────────────────────────
   4 ┌   name: vpromq01
   5 │   labels:
   6 └     app: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep3.yaml:18-30
────────────────────────────────────────
  18 ┌       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 │             valueFrom:
  26 └               secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep3.yaml:17-30
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: vpromq01
  19 │         image: rabbitmq
  20 │         ports:
  21 │         - name: vpromq01-port
  22 │           containerPort: 15672
  23 │         env:
  24 │           - name: RABBITMQ_DEFAULT_PASS
  25 └             valueFrom:
  ..   
────────────────────────────────────────



rmqdep4.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vpromq01' of 'deployment' 'vpromq01' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'vpromq01' of Deployment 'vpromq01' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vpromq01' of Deployment 'vpromq01' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vpromq01" of deployment "vpromq01" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment vpromq01 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rmqdep4.yaml:4
────────────────────────────────────────
   4 [   name: vpromq01
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container vpromq01 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep4.yaml:16-28
────────────────────────────────────────
  16 ┌         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 │               valueFrom:
  24 └                 secretKeyRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment vpromq01 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rmqdep4.yaml:15-28
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: vpromq01
  17 │           image: rabbitmq
  18 │           ports:
  19 │             - name: vpromq01-port
  20 │               containerPort: 15672
  21 │           env:
  22 │             - name: RABBITMQ_DEFAULT_PASS
  23 └               valueFrom:
  ..   
────────────────────────────────────────



rnaseq-nf.yaml (kubernetes)
===========================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rnaseq' of 'pod' 'rnaseq-nf-test-00' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rnaseq' of Pod 'rnaseq-nf-test-00' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rnaseq" of pod "rnaseq-nf-test-00" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod rnaseq-nf-test-00 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rnaseq-nf.yaml:4
────────────────────────────────────────
   4 [   name: rnaseq-nf-test-00
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rnaseq-nf-test-00 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rnaseq-nf-test-00 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rnaseq-nf.yaml:6-49
────────────────────────────────────────
   6 ┌   restartPolicy: Never
   7 │   containers:
   8 │   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 └       - name: ahabstorage
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rnaseq in pod rnaseq-nf-test-00 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 rnaseq-nf.yaml:8-29
────────────────────────────────────────
   8 ┌   - name: rnaseq
   9 │     image: tuplexyz/ahab-rnaseq-nf:v1.2.1
  10 │     volumeMounts:
  11 │       - name: datalake01
  12 │         mountPath: "/mnt/datalake"
  13 │         readOnly: false
  14 │       - name: ahabstorage
  15 │         mountPath: "/mnt/ahab"
  16 └         readOnly: false
  ..   
────────────────────────────────────────



rng-admin-user_2.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): RoleBinding 'rng-admin-user' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 rng-admin-user_2.yaml:4-5
────────────────────────────────────────
   4 ┌   name: rng-admin-user
   5 └   namespace: rng
────────────────────────────────────────



robohash-deploy.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robohash-container' of Deployment 'robohash' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robohash-container' of 'deployment' 'robohash' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robohash-container" of deployment "robohash" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robohash in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robohash-deploy.yaml:4
────────────────────────────────────────
   4 [   name: robohash
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robohash in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robohash in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robohash-deploy.yaml:15-17
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robohash-container in deployment robohash (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robohash-deploy.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: wdenniss/robohash:1
────────────────────────────────────────



robohash-deploy1.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robohash-container' of Deployment 'robohash' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robohash-container' of 'deployment' 'robohash' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robohash-container" of deployment "robohash" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robohash in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robohash-deploy1.yaml:4
────────────────────────────────────────
   4 [   name: robohash
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robohash in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robohash in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robohash-deploy1.yaml:15-17
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robohash-container in deployment robohash (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robohash-deploy1.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────



robohash-deploy2.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robohash-container' of Deployment 'robohash' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robohash-container' of 'deployment' 'robohash' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robohash-container' of Deployment 'robohash' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robohash-container" of deployment "robohash" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robohash in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robohash-deploy2.yaml:4
────────────────────────────────────────
   4 [   name: robohash
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robohash in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robohash in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robohash-deploy2.yaml:15-17
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robohash-container in deployment robohash (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robohash-deploy2.yaml:16-17
────────────────────────────────────────
  16 ┌       - name: robohash-container
  17 └         image: docker.io/wdenniss/robohash:1
────────────────────────────────────────



roboshop-rbac_1.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 roboshop-rbac_1.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'roboshop' shouldn't manage all resources at the namespace 'rbac'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 roboshop-rbac_1.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



robot-deployer.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'robot-deployer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 robot-deployer.yaml:7-22
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - extensions
   9 │   - apps
  10 │   - v1
  11 │   resources:
  12 │   - containers
  13 │   - endpoints
  14 │   - services
  15 └   - pods
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'robot-deployer' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 robot-deployer.yaml:7-22
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - extensions
   9 │   - apps
  10 │   - v1
  11 │   resources:
  12 │   - containers
  13 │   - endpoints
  14 │   - services
  15 └   - pods
  ..   
────────────────────────────────────────



robot-worker-discovery-deploy.yaml (kubernetes)
===============================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robot-worker-discovery-container' of 'deployment' 'robot-worker-discovery' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robot-worker-discovery-container' of Deployment 'robot-worker-discovery' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robot-worker-discovery-container" of deployment "robot-worker-discovery" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robot-worker-discovery in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:4
────────────────────────────────────────
   4 [   name: robot-worker-discovery
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robot-worker-discovery in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robot-worker-discovery in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:20-42
────────────────────────────────────────
  20 ┌       containers:
  21 │       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 └           initialDelaySeconds: 10
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robot-worker-discovery-container in deployment robot-worker-discovery (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robot-worker-discovery-deploy.yaml:21-42
────────────────────────────────────────
  21 ┌       - name: robot-worker-discovery-container
  22 │         image: mhoelzl/robot-worker-discovery:0.0.1
  23 │         readinessProbe:
  24 │           httpGet:
  25 │             path: /healthz
  26 │             port: 8080
  27 │             scheme: HTTP
  28 │           initialDelaySeconds: 10
  29 └           periodSeconds: 10
  ..   
────────────────────────────────────────



robot1-deployment.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robot1' of Deployment 'robot1' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robot1' of Deployment 'robot1' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robot1' of 'deployment' 'robot1' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robot1' of Deployment 'robot1' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robot1' of Deployment 'robot1' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'robot1' of Deployment 'robot1' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robot1' of Deployment 'robot1' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robot1' of Deployment 'robot1' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robot1' of Deployment 'robot1' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robot1' of Deployment 'robot1' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robot1' of Deployment 'robot1' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robot1' of Deployment 'robot1' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robot1" of deployment "robot1" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robot1 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robot1-deployment.yaml:4-10
────────────────────────────────────────
   4 ┌   annotations:
   5 │     kompose.cmd: C:\ProgramData\chocolatey\lib\kubernetes-kompose\tools\kompose.exe convert
   6 │     kompose.version: 1.31.2 (a92241f79)
   7 │   creationTimestamp: null
   8 │   labels:
   9 │     io.kompose.service: robot1
  10 └   name: robot1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robot1 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robot1 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot1-deployment.yaml:27-38
────────────────────────────────────────
  27 ┌       containers:
  28 │         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 └           image: yassinemh/fr2y-team-a-robot1:latest
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robot1 in deployment robot1 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robot1-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "1"
  31 │             - name: PORT
  32 │               value: "9091"
  33 │             - name: ROBOT_ID
  34 │               value: "1"
  35 │           image: yassinemh/fr2y-team-a-robot1:latest
  36 │           name: robot1
  37 └           resources: {}
────────────────────────────────────────



robot2-deployment.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robot2' of Deployment 'robot2' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robot2' of Deployment 'robot2' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robot2' of 'deployment' 'robot2' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robot2' of Deployment 'robot2' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robot2' of Deployment 'robot2' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'robot2' of Deployment 'robot2' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robot2' of Deployment 'robot2' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robot2' of Deployment 'robot2' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robot2' of Deployment 'robot2' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robot2' of Deployment 'robot2' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robot2' of Deployment 'robot2' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robot2' of Deployment 'robot2' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robot2" of deployment "robot2" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robot2 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robot2-deployment.yaml:4-10
────────────────────────────────────────
   4 ┌   annotations:
   5 │     kompose.cmd: C:\ProgramData\chocolatey\lib\kubernetes-kompose\tools\kompose.exe convert
   6 │     kompose.version: 1.31.2 (a92241f79)
   7 │   creationTimestamp: null
   8 │   labels:
   9 │     io.kompose.service: robot2
  10 └   name: robot2
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robot2 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robot2 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot2-deployment.yaml:27-38
────────────────────────────────────────
  27 ┌       containers:
  28 │         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 └           image: yassinemh/fr2y-team-a-robot2:latest
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robot2 in deployment robot2 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robot2-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9092"
  33 │             - name: ROBOT_ID
  34 │               value: "2"
  35 │           image: yassinemh/fr2y-team-a-robot2:latest
  36 │           name: robot2
  37 └           resources: {}
────────────────────────────────────────



robot3-deployment.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robot3' of Deployment 'robot3' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robot3' of Deployment 'robot3' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robot3' of 'deployment' 'robot3' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robot3' of Deployment 'robot3' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robot3' of Deployment 'robot3' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'robot3' of Deployment 'robot3' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robot3' of Deployment 'robot3' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robot3' of Deployment 'robot3' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robot3' of Deployment 'robot3' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robot3' of Deployment 'robot3' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robot3' of Deployment 'robot3' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robot3' of Deployment 'robot3' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robot3" of deployment "robot3" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robot3 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robot3-deployment.yaml:4-10
────────────────────────────────────────
   4 ┌   annotations:
   5 │     kompose.cmd: C:\ProgramData\chocolatey\lib\kubernetes-kompose\tools\kompose.exe convert
   6 │     kompose.version: 1.31.2 (a92241f79)
   7 │   creationTimestamp: null
   8 │   labels:
   9 │     io.kompose.service: robot3
  10 └   name: robot3
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robot3 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robot3 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot3-deployment.yaml:27-38
────────────────────────────────────────
  27 ┌       containers:
  28 │         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 └           image: yassinemh/fr2y-team-a-robot3:latest
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robot3 in deployment robot3 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robot3-deployment.yaml:28-37
────────────────────────────────────────
  28 ┌         - env:
  29 │             - name: INIT
  30 │               value: "0"
  31 │             - name: PORT
  32 │               value: "9093"
  33 │             - name: ROBOT_ID
  34 │               value: "3"
  35 │           image: yassinemh/fr2y-team-a-robot3:latest
  36 │           name: robot3
  37 └           resources: {}
────────────────────────────────────────



robot4-deployment.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 96, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'robot4' of Deployment 'robot4' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'robot4' of Deployment 'robot4' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'robot4' of 'deployment' 'robot4' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'robot4' of Deployment 'robot4' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'robot4' of Deployment 'robot4' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'robot4' of Deployment 'robot4' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'robot4' of Deployment 'robot4' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'robot4' of Deployment 'robot4' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'robot4' of Deployment 'robot4' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'robot4' of Deployment 'robot4' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'robot4' of Deployment 'robot4' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'robot4' of Deployment 'robot4' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "robot4" of deployment "robot4" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment robot4 in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 robot4-deployment.yaml:4-10
────────────────────────────────────────
   4 ┌   annotations:
   5 │     kompose.cmd: C:\ProgramData\chocolatey\lib\kubernetes-kompose\tools\kompose.exe convert
   6 │     kompose.version: 1.31.2 (a92241f79)
   7 │   creationTimestamp: null
   8 │   labels:
   9 │     io.kompose.service: robot4
  10 └   name: robot4
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container robot4 in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment robot4 in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 robot4-deployment.yaml:31-42
────────────────────────────────────────
  31 ┌       containers:
  32 │         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 └           image: yassinemh/fr2y-team-a-robot4:latest
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container robot4 in deployment robot4 (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 robot4-deployment.yaml:32-41
────────────────────────────────────────
  32 ┌         - env:
  33 │             - name: INIT
  34 │               value: "0"
  35 │             - name: PORT
  36 │               value: "9094"
  37 │             - name: ROBOT_ID
  38 │               value: "4"
  39 │           image: yassinemh/fr2y-team-a-robot4:latest
  40 │           name: robot4
  41 └           resources: {}
────────────────────────────────────────



rocketmq-console.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'mqconsole' of Pod 'mqconsole' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'mqconsole' of Pod 'mqconsole' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'mqconsole' of 'pod' 'mqconsole' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'mqconsole' of Pod 'mqconsole' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'mqconsole' of Pod 'mqconsole' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'mqconsole' of Pod 'mqconsole' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'mqconsole' of Pod 'mqconsole' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'mqconsole' of Pod 'mqconsole' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'mqconsole' of Pod 'mqconsole' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'mqconsole' of Pod 'mqconsole' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'mqconsole' of Pod 'mqconsole' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "mqconsole" of pod "mqconsole" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod mqconsole in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rocketmq-console.yaml:4-6
────────────────────────────────────────
   4 ┌   name: mqconsole
   5 │   labels:
   6 └     app: mqconsole
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container mqconsole in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod mqconsole in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocketmq-console.yaml:8-16
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container mqconsole in pod mqconsole (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 rocketmq-console.yaml:9-16
────────────────────────────────────────
   9 ┌   - name: mqconsole
  10 │     image: apacherocketmq/rocketmq-console:2.0.0
  11 │     imagePullPolicy: IfNotPresent
  12 │     env:
  13 │     - name: JAVA_OPTS
  14 │       value: "-Drocketmq.config.namesrvAddr=rmqnamesrv:9876 -Drocketmq.config.isVIPChannel=false"
  15 │     ports:
  16 └     - containerPort: 8080
────────────────────────────────────────



rocketmqbroker-pod.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rmqbroker' of Pod 'rmqbroker' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rmqbroker' of 'pod' 'rmqbroker' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rmqbroker' of Pod 'rmqbroker' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rmqbroker' of Pod 'rmqbroker' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rmqbroker' of Pod 'rmqbroker' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rmqbroker" of pod "rmqbroker" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod rmqbroker in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rocketmqbroker-pod.yaml:4-6
────────────────────────────────────────
   4 ┌   name: rmqbroker
   5 │   labels:
   6 └     app: rmqbroker
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rmqbroker in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rmqbroker in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocketmqbroker-pod.yaml:8-28
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 └     - name: MAX_POSSIBLE_HEAP
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rmqbroker in pod rmqbroker (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 rocketmqbroker-pod.yaml:9-24
────────────────────────────────────────
   9 ┌   - name: rmqbroker
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqbroker", "-c", "/opt/rocketmq/conf/broker.conf"]
  13 │     env:
  14 │     - name: NAMESRV_ADDR
  15 │       value: "namesrv:9876"
  16 │     - name: MAX_POSSIBLE_HEAP
  17 └       value: "200000000"
  ..   
────────────────────────────────────────



rocketmqnamesrv-pod.yaml (kubernetes)
=====================================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rmqnamesrv' of 'pod' 'rmqnamesrv' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rmqnamesrv' of Pod 'rmqnamesrv' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rmqnamesrv" of pod "rmqnamesrv" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod rmqnamesrv in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:4-6
────────────────────────────────────────
   4 ┌   name: rmqnamesrv
   5 │   labels:
   6 └     app: rmqnamesrv
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rmqnamesrv in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rmqnamesrv in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container rmqnamesrv in pod rmqnamesrv (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 rocketmqnamesrv-pod.yaml:9-14
────────────────────────────────────────
   9 ┌   - name: rmqnamesrv
  10 │     image: apache/rocketmq:4.9.1
  11 │     imagePullPolicy: IfNotPresent
  12 │     command: ["sh", "mqnamesrv"]
  13 │     ports:
  14 └     - containerPort: 9876
────────────────────────────────────────



rocky-nenya.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 101, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 6, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rocky' of Pod 'rocky-nenya' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rocky' of Pod 'rocky-nenya' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rocky' of 'pod' 'rocky-nenya' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rocky' of Pod 'rocky-nenya' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rocky' of Pod 'rocky-nenya' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'rocky' of Pod 'rocky-nenya' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rocky' of Pod 'rocky-nenya' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rocky' of Pod 'rocky-nenya' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): Pod 'rocky-nenya' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 rocky-nenya.yaml:7-20
────────────────────────────────────────
   7 ┌   nodeName: shadowfax-01
   8 │   containers:
   9 │     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 └         requests:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rocky" of pod "rocky-nenya" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocky-nenya.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rocky-nenya in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocky-nenya.yaml:7-20
────────────────────────────────────────
   7 ┌   nodeName: shadowfax-01
   8 │   containers:
   9 │     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "dnf install -y iputils dnsutils && while true; do sleep 10; done"]
  14 │       resources:
  15 └         requests:
  ..   
────────────────────────────────────────



rocky-nessa.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 101, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 7, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rocky' of Pod 'rocky-nessa' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rocky' of Pod 'rocky-nessa' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rocky' of 'pod' 'rocky-nessa' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rocky' of Pod 'rocky-nessa' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rocky' of Pod 'rocky-nessa' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'rocky' of Pod 'rocky-nessa' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rocky' of Pod 'rocky-nessa' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rocky' of Pod 'rocky-nessa' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rocky" of pod "rocky-nessa" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocky-nessa.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod rocky-nessa in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rocky-nessa.yaml:4-5
────────────────────────────────────────
   4 ┌   name: rocky-nessa
   5 └   namespace: default
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rocky-nessa in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocky-nessa.yaml:7-20
────────────────────────────────────────
   7 ┌   nodeName: nessa
   8 │   containers:
   9 │     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 └         requests:
  ..   
────────────────────────────────────────



rocky-nienna.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 101, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 7, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rocky' of Pod 'rocky-nienna' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rocky' of Pod 'rocky-nienna' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rocky' of 'pod' 'rocky-nienna' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rocky' of Pod 'rocky-nienna' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rocky' of Pod 'rocky-nienna' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'rocky' of Pod 'rocky-nienna' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rocky' of Pod 'rocky-nienna' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rocky' of Pod 'rocky-nienna' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rocky" of pod "rocky-nienna" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocky-nienna.yaml:9-20
────────────────────────────────────────
   9 ┌     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 │         requests:
  16 │           cpu: 100m
  17 └           memory: 512Mi
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod rocky-nienna in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rocky-nienna.yaml:4-5
────────────────────────────────────────
   4 ┌   name: rocky-nienna
   5 └   namespace: default
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rocky-nienna in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocky-nienna.yaml:7-20
────────────────────────────────────────
   7 ┌   nodeName: nienna
   8 │   containers:
   9 │     - name: rocky
  10 │       image: rockylinux:9
  11 │       securityContext:
  12 │         privileged: true
  13 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  14 │       resources:
  15 └         requests:
  ..   
────────────────────────────────────────



rocky.yaml (kubernetes)
=======================
Tests: 115 (SUCCESSES: 102, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 7, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'rocky' of Pod 'rocky-linux' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'rocky' of Pod 'rocky-linux' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'rocky' of 'pod' 'rocky-linux' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'rocky' of Pod 'rocky-linux' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'rocky' of Pod 'rocky-linux' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'rocky' of Pod 'rocky-linux' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'rocky' of Pod 'rocky-linux' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "rocky" of pod "rocky-linux" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod rocky-linux in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 rocky.yaml:4-5
────────────────────────────────────────
   4 ┌   name: rocky-linux
   5 └   namespace: default
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container rocky-linux in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocky.yaml:8-17
────────────────────────────────────────
   8 ┌     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 │         limits:
  16 │           cpu: 323m
  17 └           memory: 886M
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod rocky-linux in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 rocky.yaml:7-17
────────────────────────────────────────
   7 ┌   containers:
   8 │     - name: rocky
   9 │       image: rockylinux:9
  10 │       command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
  11 │       resources:
  12 │         requests:
  13 │           cpu: 50m
  14 │           memory: 443M
  15 └         limits:
  ..   
────────────────────────────────────────



role-03.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'capo-leader-election-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role-03.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - ''
  11 │   resources:
  12 │   - configmaps
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 │   - watch
  17 └   - create
  ..   
────────────────────────────────────────



role-04.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'orc-leader-election-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role-04.yaml:10-21
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - configmaps
  14 │   verbs:
  15 │   - get
  16 │   - list
  17 │   - watch
  18 └   - create
  ..   
────────────────────────────────────────



role-all-readers.yaml (kubernetes)
==================================
Tests: 116 (SUCCESSES: 113, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 3)

AVD-KSV-0046 (CRITICAL): ClusterRole 'readers-all' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role-all-readers.yaml:9-12
────────────────────────────────────────
   9 ┌   - apiGroups: [""]
  10 │     #    resources: ["pods","pods/log","nodes","services","jobs","cronjobs","deployments"]
  11 │     resources: ["*"]
  12 └     verbs: ["get","list","watch"] 
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'readers-all' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role-all-readers.yaml:14-17
────────────────────────────────────────
  14 ┌   - apiGroups: ["apps"]
  15 │     #    resources: ["pods","pods/log","nodes","services","jobs","cronjobs","deployments"]
  16 │     resources: ["*"]
  17 └     verbs: ["get","list","watch"] 
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'readers-all' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role-all-readers.yaml:23-26
────────────────────────────────────────
  23 ┌   - apiGroups: ["extensions"]
  24 │     #    resources: ["pods","pods/log","nodes","services","jobs","cronjobs","deployments"]
  25 │     resources: ["*"]
  26 └     verbs: ["get","list","watch"] 
────────────────────────────────────────



role-bad1.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad1.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr01' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad1.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad10.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad10.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr01' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad10.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad10_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad10_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad10_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad10_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad10_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'badcr03' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad10_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad11.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad11.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad11.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role-bad11_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad11_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad11_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad11_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad11_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad11_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr03' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad11_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────



role-bad13.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad13.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr01' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad13.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad13_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad13_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad13_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad13_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'badcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad13_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad14.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad14.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr01' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad14.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad14_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad14_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad14_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad14_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad14_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'badcr03' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad14_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad15.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad15.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad15.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role-bad15_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad15_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad15_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad15_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad15_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad15_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr03' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad15_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────



role-bad17.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad17.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr01' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad17.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad17_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad17_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad17_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad17_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'badcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad17_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad18.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad18.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr01' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad18.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad18_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad18_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad18_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad18_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad18_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'badcr03' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad18_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad19.yaml (kubernetes)
============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad19.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad19.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role-bad19_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad19_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad19_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad19_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad19_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad19_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr03' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad19_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────



role-bad1_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad1_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad1_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad1_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'badcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad1_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad2.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad2.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr01' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad2.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad2_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad2_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad2_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad2_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad2_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'badcr03' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad2_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad3.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad3.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad3.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role-bad3_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad3_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad3_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad3_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad3_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad3_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr03' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad3_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────



role-bad5.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad5.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr01' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad5.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad5_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad5_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad5_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad5_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'badcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad5_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad6.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad6.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr01' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad6.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - '*'
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad6_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad6_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad6_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad6_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad6_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'badcr03' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad6_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-bad7.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad7.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad7.yaml:6-12
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - pods
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role-bad7_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad7_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'badcr02' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-bad7_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - get
  12 │   - watch
  13 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad7_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad7_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-bad7_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'badcr03' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad7_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   verbs:
  11 │   - update
  12 │   - '*'
  13 └   - create
────────────────────────────────────────



role-bad9.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr01' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad9.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr01' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad9.yaml:6-14
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - namespaces
  10 │   - secrets
  11 │   - pods
  12 │   verbs:
  13 │   - get
  14 └   - create
────────────────────────────────────────



role-bad9_1.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'badcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-bad9_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'badcr02' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad9_1.yaml:14-23
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - namespaces
  18 │   - secrets
  19 │   - pods
  20 │   verbs:
  21 │   - create
  22 │   - watch
  23 └   - list
────────────────────────────────────────



role-bad9_2.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'badcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-bad9_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - update
  12 │   - list
  13 └   - create
────────────────────────────────────────



role-binding.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'exam-resource-access' shouldn't have access to manage secrets in namespace 'exam'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-binding.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - configmaps
  13 │   - deployments
  14 │   - statefulsets
  15 └   - secrets
  ..   
────────────────────────────────────────



role-binding11.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): RoleBinding 'admin-role-binding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-binding11.yaml:4-5
────────────────────────────────────────
   4 ┌   name: admin-role-binding
   5 └   namespace: default
────────────────────────────────────────



role-binding5.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): RoleBinding 'admin-role-binding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-binding5.yaml:4-5
────────────────────────────────────────
   4 ┌   name: admin-role-binding
   5 └   namespace: default
────────────────────────────────────────



role-binding54.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): RoleBinding 'admin-role-binding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-binding54.yaml:4-5
────────────────────────────────────────
   4 ┌   name: admin-role-binding
   5 └   namespace: default
────────────────────────────────────────



role-binding6.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'exam-resource-access' shouldn't have access to manage secrets in namespace 'exam'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-binding6.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - configmaps
  13 │   - deployments
  14 │   - statefulsets
  15 └   - secrets
  ..   
────────────────────────────────────────



role-binding61.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'fluid-cluster-rolebinding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-binding61.yaml:4-5
────────────────────────────────────────
   4 ┌   name: fluid-cluster-rolebinding
   5 └   namespace: fluid-system
────────────────────────────────────────



role-binding64.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'api-gateway-full-access' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role-binding64.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-bindings1_2.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-admin-rolebinding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-bindings1_2.yaml:4
────────────────────────────────────────
   4 [   name: cluster-admin-rolebinding
────────────────────────────────────────



role-bindings_2.yaml (kubernetes)
=================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-admin-rolebinding' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-bindings_2.yaml:4
────────────────────────────────────────
   4 [   name: cluster-admin-rolebinding
────────────────────────────────────────



role-cluster-admin.yaml (kubernetes)
====================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'kubernetes-ec2-cluster-admin' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 role-cluster-admin.yaml:5
────────────────────────────────────────
   5 [   name: kubernetes-ec2-cluster-admin
────────────────────────────────────────



role-config.yaml (kubernetes)
=============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config1.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config10.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config10.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config11.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config11.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config12.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config12.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config13.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config13.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config14.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config14.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config15.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config15.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config16.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config16.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config17.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config17.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config18.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config18.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config19.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config19.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config2.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config20.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config20.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config21.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config21.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config22.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config22.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config23.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config23.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config24.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config24.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config25.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config25.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config26.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config26.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config27.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config27.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config28.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config28.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config29.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config29.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config3.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config3.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config30.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config30.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config31.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config31.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config4.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config4.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config5.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config5.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config6.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config6.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config7.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config7.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config8.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config8.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-config9.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-config9.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role-create-jobs.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'create-jobs' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-create-jobs.yaml:7-15
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │     - batch
   9 │   resources: 
  10 │     - jobs
  11 │   verbs:
  12 │     - create
  13 │     - get
  14 │     - list
  15 └     - patch
────────────────────────────────────────



role-dev-namespace.yaml (kubernetes)
====================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-dev-namespace.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev-user-full-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev-namespace.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'dev-user-full-access-role' shouldn't manage all resources at the namespace 'dev'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-dev-namespace.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role-dev-namespace1.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-dev-namespace1.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev-user-full-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev-namespace1.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'dev-user-full-access-role' shouldn't manage all resources at the namespace 'dev'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-dev-namespace1.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role-dev-namespace2.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-dev-namespace2.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev-user-full-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev-namespace2.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'dev-user-full-access-role' shouldn't manage all resources at the namespace 'dev'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-dev-namespace2.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role-dev-namespace3.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-dev-namespace3.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev-user-full-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev-namespace3.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'dev-user-full-access-role' shouldn't manage all resources at the namespace 'dev'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-dev-namespace3.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role-dev-namespace4.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-dev-namespace4.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev-user-full-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev-namespace4.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'dev-user-full-access-role' shouldn't manage all resources at the namespace 'dev'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-dev-namespace4.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role-dev-namespace5.yaml (kubernetes)
=====================================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-dev-namespace5.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev-user-full-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev-namespace5.yaml:10-14
────────────────────────────────────────
  10 ┌ - apiGroups: ["batch"]
  11 │   resources:
  12 │   - jobs
  13 │   - cronjobs
  14 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'dev-user-full-access-role' shouldn't manage all resources at the namespace 'dev'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-dev-namespace5.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role-dev.yaml (kubernetes)
==========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"] # Specifies the API groups this Role applies to (core, extensions, and apps)
   8 │   resources: ["deployments", "replicasets", "pods"] # Specifies the resources this Role provides access to (deployments, replicasets, and pods)
   9 └   verbs: ["list", "get", "watch", "create", "update", "patch"] # Specifies the allowed actions (list, get, watch, create, update, and patch)
────────────────────────────────────────



role-dev1.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev1.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"] # Specifies the API groups this Role applies to (core, extensions, and apps)
   8 │   resources: ["deployments", "replicasets", "pods"] # Specifies the resources this Role provides access to (deployments, replicasets, and pods)
   9 └   verbs: ["list", "get", "watch", "create", "update", "patch"] # Specifies the allowed actions (list, get, watch, create, update, and patch)
────────────────────────────────────────



role-dev2.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0042 (MEDIUM): Role 'dev' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role-dev2.yaml:14-17
────────────────────────────────────────
  14 ┌   - apiGroups: ["*"]
  15 │     resources: ["pods","pods/log","pods/exec","deployments"]
  16 │     #   resources: ["*"]
  17 └     verbs: ["get","list","watch","create","update","patch","delete"] 
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'dev' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev2.yaml:14-17
────────────────────────────────────────
  14 ┌   - apiGroups: ["*"]
  15 │     resources: ["pods","pods/log","pods/exec","deployments"]
  16 │     #   resources: ["*"]
  17 └     verbs: ["get","list","watch","create","update","patch","delete"] 
────────────────────────────────────────


AVD-KSV-0053 (HIGH): Role 'dev' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role-dev2.yaml:14-17
────────────────────────────────────────
  14 ┌   - apiGroups: ["*"]
  15 │     resources: ["pods","pods/log","pods/exec","deployments"]
  16 │     #   resources: ["*"]
  17 └     verbs: ["get","list","watch","create","update","patch","delete"] 
────────────────────────────────────────



role-dev3.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev3.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["deployments", "replicasets", "pods"]
   9 └   verbs: ["list", "get", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────



role-dev4.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev4.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["deployments", "replicasets", "pods"]
   9 └   verbs: ["list", "get", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────



role-dev6.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'devops' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-dev6.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["deployments", "replicasets", "pods"]
   9 └   verbs: ["list", "get", "watch", "create", "update", "patch", "delete"]  
────────────────────────────────────────



role-garnet-operator.yaml (kubernetes)
======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'garnet-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-garnet-operator.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resourceNames:
   9 │   - garnet-operator-webhook-tls
  10 │   resources:
  11 │   - secrets
  12 │   verbs:
  13 └   - watch
────────────────────────────────────────



role-good10_1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good10_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good10_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good10_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good10_3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-good10_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'goodcr04' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good10_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-good10_4.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr05' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good10_4.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good11_1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good11_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good11_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good11_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good11_3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'goodcr04' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-good11_3.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good13_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good13_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good14_1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good14_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good14_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good14_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good14_3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-good14_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'goodcr04' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good14_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-good14_4.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr05' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good14_4.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good15_1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good15_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good15_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good15_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good15_3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'goodcr04' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-good15_3.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good17_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good17_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good18_1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good18_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good18_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good18_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good18_3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-good18_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'goodcr04' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good18_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-good18_4.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr05' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good18_4.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good19_1.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good19_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good19_2.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good19_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good19_3.yaml (kubernetes)
===============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'goodcr04' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-good19_3.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good1_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good1_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good2_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good2_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good2_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good2_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good2_3.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-good2_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'goodcr04' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good2_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-good2_4.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr05' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good2_4.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good3_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good3_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good3_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good3_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good3_3.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'goodcr04' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-good3_3.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good5_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good5_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good6_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good6_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good6_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good6_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good6_3.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role-good6_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'goodcr04' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good6_3.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-good6_4.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr05' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good6_4.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - '*'
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good7_1.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'goodcr02' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-good7_1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - deployments
  10 │   verbs:
  11 │   - get
  12 │   - create
  13 └   - update
────────────────────────────────────────



role-good7_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good7_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - batch
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good7_3.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'goodcr04' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-good7_3.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - apps
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-good9_2.yaml (kubernetes)
==============================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'goodcr03' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-good9_2.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - secrets
  10 │   verbs:
  11 │   - create
  12 │   - update
  13 └   - patch
────────────────────────────────────────



role-main.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'role-main' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-main.yaml:10-12
────────────────────────────────────────
  10 ┌ - apiGroups: ["apps"]
  11 │   resources: ["deployments"]
  12 └   verbs: ["get", "list", "watch", "create", "delete"]
────────────────────────────────────────



role-pod-manager.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'pod-manager' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-pod-manager.yaml:9-11
────────────────────────────────────────
   9 ┌ - apiGroups: [""]
  10 │   resources: ["pods"]
  11 └   verbs: ["get", "list", "delete"]
────────────────────────────────────────



role-qdrant-operator.yaml (kubernetes)
======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'qdrant-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-qdrant-operator.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resourceNames:
   9 │   - qdrant-operator-webhook-tls
  10 │   resources:
  11 │   - secrets
  12 │   verbs:
  13 └   - watch
────────────────────────────────────────



role-qdrant-operator1.yaml (kubernetes)
=======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'qdrant-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-qdrant-operator1.yaml:6-13
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ""
   8 │   resourceNames:
   9 │   - qdrant-operator-webhook-tls
  10 │   resources:
  11 │   - secrets
  12 │   verbs:
  13 └   - watch
────────────────────────────────────────



role-rolebinding-manifests.yaml (kubernetes)
============================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role-rolebinding-manifests.yaml:7-14
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   resources:
  10 │   - pods
  11 │   verbs:
  12 │   - list
  13 │   - create
  14 └   - delete
────────────────────────────────────────



role-rolebinding.yaml (kubernetes)
==================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'full-access' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-rolebinding.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - '*'
  10 │   verbs:
  11 └   - '*'
────────────────────────────────────────



role-rolebindings.yaml (kubernetes)
===================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'dashboard-admin' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role-rolebindings.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role-service-account.yaml (kubernetes)
======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'serviceaccount-role' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role-service-account.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["pods","secrets"]
   8 └   verbs: ["get", "watch", "list"]
────────────────────────────────────────



role-student-readers.yaml (kubernetes)
======================================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'readers-all-student' shouldn't manage all resources at the namespace 'student'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role-student-readers.yaml:9-12
────────────────────────────────────────
   9 ┌   - apiGroups: ["*"]
  10 │     #    resources: ["pods","pods/log","nodes","services","jobs","cronjobs","deployments"]
  11 │     resources: ["*"]
  12 └     verbs: ["get","list","watch"] 
────────────────────────────────────────



role-with-exec.yaml (kubernetes)
================================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role-with-exec.yaml:12-19
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │     - '*'
  14 │   resources:
  15 │     - '*'
  16 │   verbs:
  17 │     - delete
  18 │     - get
  19 └     - patch
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'argocd-server' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role-with-exec.yaml:6-11
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │     - ""
   8 │   resources:
   9 │     - pods/exec
  10 │   verbs:
  11 └     - create
────────────────────────────────────────



role.yaml (kubernetes)
======================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 role.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'controller-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role1.yaml (kubernetes)
=======================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 2, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role1.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - endpoints
  11 │   - namespaces
  12 │   - nodes
  13 │   - nodes/proxy
  14 │   - secrets
  15 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 role1.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - endpoints
  11 │   - namespaces
  12 │   - nodes
  13 │   - nodes/proxy
  14 │   - secrets
  15 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role1.yaml:19-33
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - persistentvolumeclaims
  23 │   - pods
  24 │   - serviceaccounts
  25 │   - services
  26 │   verbs:
  27 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role1.yaml:34-47
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - apps
  36 │   resources:
  37 │   - daemonsets
  38 │   - replicasets
  39 │   - statefulsets
  40 │   verbs:
  41 │   - create
  42 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'manager-role' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role1.yaml:60-74
────────────────────────────────────────
  60 ┌ - apiGroups:
  61 │   - rbac.authorization.k8s.io
  62 │   resources:
  63 │   - clusterrolebindings
  64 │   - clusterroles
  65 │   - rolebindings
  66 │   - roles
  67 │   verbs:
  68 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role1.yaml:19-33
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - persistentvolumeclaims
  23 │   - pods
  24 │   - serviceaccounts
  25 │   - services
  26 │   verbs:
  27 └   - create
  ..   
────────────────────────────────────────



role107.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secret-reader-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role107.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["secrets"]
   9 └   verbs: ["get", "list", "create", "update", "patch"]
────────────────────────────────────────



role108.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'spring-petclinic'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role108.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role109.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role109.yaml:35-46
────────────────────────────────────────
  35 ┌ - apiGroups:
  36 │   - networking.k8s.io
  37 │   resources:
  38 │   - ingresses
  39 │   verbs:
  40 │   - create
  41 │   - delete
  42 │   - get
  43 └   - list
  ..   
────────────────────────────────────────



role110.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role110.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["pods"]
   9 └   verbs: ["get", "watch", "list", "patch"]
────────────────────────────────────────



role115.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role115.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role148.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0042 (MEDIUM): Role 'developer-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role148.yaml:13-15
────────────────────────────────────────
  13 ┌   - apiGroups: [""]
  14 │     resources: ["pods","pods/log"]
  15 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role148.yaml:13-15
────────────────────────────────────────
  13 ┌   - apiGroups: [""]
  14 │     resources: ["pods","pods/log"]
  15 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'developer-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role148.yaml:13-15
────────────────────────────────────────
  13 ┌   - apiGroups: [""]
  14 │     resources: ["pods","pods/log"]
  15 └     verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'developer-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role148.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["services"]
   9 └     verbs: ["*"]
────────────────────────────────────────



role153.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'kmerge-controller-admin' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role153.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - "*"
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role159.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 2, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role159.yaml:43-52
────────────────────────────────────────
  43 ┌ - apiGroups:
  44 │   - ""
  45 │   resources:
  46 │   - secrets
  47 │   verbs:
  48 │   - create
  49 │   - get
  50 │   - list
  51 │   - update
  52 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role159.yaml:26-36
────────────────────────────────────────
  26 ┌ - apiGroups:
  27 │   - ""
  28 │   resources:
  29 │   - pods
  30 │   verbs:
  31 │   - create
  32 │   - delete
  33 │   - get
  34 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role159.yaml:64-74
────────────────────────────────────────
  64 ┌ - apiGroups:
  65 │   - apps
  66 │   resources:
  67 │   - statefulsets
  68 │   verbs:
  69 │   - create
  70 │   - delete
  71 │   - get
  72 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role159.yaml:7-17
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'manager-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role159.yaml:37-42
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ""
  39 │   resources:
  40 │   - pods/exec
  41 │   verbs:
  42 └   - create
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role159.yaml:53-63
────────────────────────────────────────
  53 ┌ - apiGroups:
  54 │   - ""
  55 │   resources:
  56 │   - services
  57 │   verbs:
  58 │   - create
  59 │   - delete
  60 │   - get
  61 └   - list
  ..   
────────────────────────────────────────



role16.yaml (kubernetes)
========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'manage-pods' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role16.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["pods", "pods/exec"]
   9 └   verbs: ["get", "watch", "list", "create", "delete"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'manage-pods' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role16.yaml:10-12
────────────────────────────────────────
  10 ┌ - apiGroups: ["apps"]
  11 │   resources: ["deployments"]
  12 └   verbs: ["get", "watch", "list", "delete", "create"]
────────────────────────────────────────


AVD-KSV-0053 (HIGH): Role 'manage-pods' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role16.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["pods", "pods/exec"]
   9 └   verbs: ["get", "watch", "list", "create", "delete"]
────────────────────────────────────────



role165.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role165.yaml:14-21
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ""
  16 │   resources:
  17 │   - secrets
  18 │   verbs:
  19 │   - get
  20 │   - list
  21 └   - watch
────────────────────────────────────────



role166_1.yaml (kubernetes)
===========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kubebpfbox' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role166_1.yaml:6-22
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - services
  11 │   - endpoints
  12 │   - events
  13 │   - configmaps
  14 └   - nodes
  ..   
────────────────────────────────────────



role168.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 111, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 1, CRITICAL: 0)

AVD-KSV-0042 (MEDIUM): Role 'test-sa-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role168.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]  # Core API group
   8 │     resources: ["services", "pods", "pods/log", "pods/portforward"]
   9 └     verbs: ["get", "list", "create", "delete", "update", "watch"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'test-sa-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role168.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]  # Core API group
   8 │     resources: ["services", "pods", "pods/log", "pods/portforward"]
   9 └     verbs: ["get", "list", "create", "delete", "update", "watch"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'test-sa-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role168.yaml:10-12
────────────────────────────────────────
  10 ┌   - apiGroups: ["apps"]  # "apps" API group
  11 │     resources: ["deployments"]
  12 └     verbs: ["get", "list", "create", "delete", "update", "watch"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'test-sa-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role168.yaml:13-15
────────────────────────────────────────
  13 ┌   - apiGroups: ["batch"]  # "batch" API group
  14 │     resources: ["jobs"]
  15 └     verbs: ["get", "list", "create", "delete", "update", "watch"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'test-sa-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role168.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]  # Core API group
   8 │     resources: ["services", "pods", "pods/log", "pods/portforward"]
   9 └     verbs: ["get", "list", "create", "delete", "update", "watch"]
────────────────────────────────────────



role17.yaml (kubernetes)
========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role17.yaml:13-21
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - extensions
  15 │   resourceNames:
  16 │   - kube-state-metrics
  17 │   resources:
  18 │   - deployments
  19 │   verbs:
  20 │   - get
  21 └   - update
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role17.yaml:22-30
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - apps
  24 │   resourceNames:
  25 │   - kube-state-metrics
  26 │   resources:
  27 │   - deployments
  28 │   verbs:
  29 │   - get
  30 └   - update
────────────────────────────────────────



role174.yaml (kubernetes)
=========================
Tests: 118 (SUCCESSES: 108, FAILURES: 10)
Failures: 10 (UNKNOWN: 0, LOW: 0, MEDIUM: 5, HIGH: 1, CRITICAL: 4)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role174.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - endpoints
  14 │   - persistentvolumeclaims
  15 │   - events
  16 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role174.yaml:21-27
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - batch
  23 │   - extensions
  24 │   resources:
  25 │   - jobs
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role174.yaml:28-37
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   - extensions
  31 │   resources:
  32 │   - deployments
  33 │   - daemonsets
  34 │   - replicasets
  35 │   - statefulsets
  36 │   verbs:
  37 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'spinnaker-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role174.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - endpoints
  14 │   - persistentvolumeclaims
  15 │   - events
  16 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'spinnaker-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role174.yaml:21-27
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - batch
  23 │   - extensions
  24 │   resources:
  25 │   - jobs
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'spinnaker-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role174.yaml:28-37
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - apps
  30 │   - extensions
  31 │   resources:
  32 │   - deployments
  33 │   - daemonsets
  34 │   - replicasets
  35 │   - statefulsets
  36 │   verbs:
  37 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'spinnaker-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role174.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - endpoints
  14 │   - persistentvolumeclaims
  15 │   - events
  16 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'spinnaker-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role174.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - endpoints
  14 │   - persistentvolumeclaims
  15 │   - events
  16 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'spinnaker-operator' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role174.yaml:53-59
────────────────────────────────────────
  53 ┌ - apiGroups:
  54 │   - spinnaker.io
  55 │   resources:
  56 │   - '*'
  57 │   - spinnakerservices
  58 │   verbs:
  59 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'spinnaker-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role174.yaml:8-20
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - endpoints
  14 │   - persistentvolumeclaims
  15 │   - events
  16 └   - configmaps
  ..   
────────────────────────────────────────



role175.yaml (kubernetes)
=========================
Tests: 118 (SUCCESSES: 108, FAILURES: 10)
Failures: 10 (UNKNOWN: 0, LOW: 0, MEDIUM: 5, HIGH: 1, CRITICAL: 4)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role175.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - endpoints
  13 │   - persistentvolumeclaims
  14 │   - events
  15 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role175.yaml:20-26
────────────────────────────────────────
  20 ┌ - apiGroups:
  21 │   - batch
  22 │   - extensions
  23 │   resources:
  24 │   - jobs
  25 │   verbs:
  26 └   - '*'
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role175.yaml:27-36
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - apps
  29 │   - extensions
  30 │   resources:
  31 │   - deployments
  32 │   - daemonsets
  33 │   - replicasets
  34 │   - statefulsets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'spinnaker-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role175.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - endpoints
  13 │   - persistentvolumeclaims
  14 │   - events
  15 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'spinnaker-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role175.yaml:20-26
────────────────────────────────────────
  20 ┌ - apiGroups:
  21 │   - batch
  22 │   - extensions
  23 │   resources:
  24 │   - jobs
  25 │   verbs:
  26 └   - '*'
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'spinnaker-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role175.yaml:27-36
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - apps
  29 │   - extensions
  30 │   resources:
  31 │   - deployments
  32 │   - daemonsets
  33 │   - replicasets
  34 │   - statefulsets
  35 │   verbs:
  36 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'spinnaker-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role175.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - endpoints
  13 │   - persistentvolumeclaims
  14 │   - events
  15 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'spinnaker-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role175.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - endpoints
  13 │   - persistentvolumeclaims
  14 │   - events
  15 └   - configmaps
  ..   
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'spinnaker-operator' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role175.yaml:52-58
────────────────────────────────────────
  52 ┌ - apiGroups:
  53 │   - spinnaker.io
  54 │   resources:
  55 │   - '*'
  56 │   - spinnakerservices
  57 │   verbs:
  58 └   - '*'
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'spinnaker-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role175.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - endpoints
  13 │   - persistentvolumeclaims
  14 │   - events
  15 └   - configmaps
  ..   
────────────────────────────────────────



role176.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 108, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'spinnaker-operator-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role176.yaml:16-31
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - ""
  18 │   resources:
  19 │   - services
  20 │   - events
  21 │   - configmaps
  22 │   - secrets
  23 │   - namespaces
  24 └   - ingresses
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'spinnaker-operator-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role176.yaml:54-65
────────────────────────────────────────
  54 ┌ - apiGroups:
  55 │   - spinnaker.io
  56 │   resources:
  57 │   - '*'
  58 │   - spinnakerservices
  59 │   verbs:
  60 │   - create
  61 │   - get
  62 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'spinnaker-operator-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role176.yaml:32-46
────────────────────────────────────────
  32 ┌ - apiGroups:
  33 │   - apps
  34 │   - extensions
  35 │   resources:
  36 │   - deployments
  37 │   - daemonsets
  38 │   - replicasets
  39 │   - statefulsets
  40 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'spinnaker-operator-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role176.yaml:16-31
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - ""
  18 │   resources:
  19 │   - services
  20 │   - events
  21 │   - configmaps
  22 │   - secrets
  23 │   - namespaces
  24 └   - ingresses
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'spinnaker-operator-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role176.yaml:16-31
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - ""
  18 │   resources:
  19 │   - services
  20 │   - events
  21 │   - configmaps
  22 │   - secrets
  23 │   - namespaces
  24 └   - ingresses
  ..   
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'spinnaker-operator-role' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 role176.yaml:66-71
────────────────────────────────────────
  66 ┌ - apiGroups:
  67 │   - admissionregistration.k8s.io
  68 │   resources:
  69 │   - validatingwebhookconfigurations
  70 │   verbs:
  71 └   - '*'
────────────────────────────────────────



role180.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role180.yaml:9-20
────────────────────────────────────────
   9 ┌ - apiGroups:
  10 │   - apps
  11 │   resources:
  12 │   - deployments
  13 │   verbs:
  14 │   - create
  15 │   - delete
  16 │   - get
  17 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role180.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - batch
  23 │   resources:
  24 │   - jobs
  25 │   verbs:
  26 │   - create
  27 │   - delete
  28 │   - get
  29 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role180.yaml:41-52
────────────────────────────────────────
  41 ┌ - apiGroups:
  42 │   - ""
  43 │   resources:
  44 │   - services
  45 │   verbs:
  46 │   - create
  47 │   - delete
  48 │   - get
  49 └   - list
  ..   
────────────────────────────────────────



role19.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'resource-access-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role19.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "services", "deployments", "configmaps"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'resource-access-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role19.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "services", "deployments", "configmaps"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'resource-access-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role19.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "services", "deployments", "configmaps"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────



role192.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 111, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 2, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role192.yaml:14-28
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ""
  16 │   resources:
  17 │   - persistentvolumeclaims
  18 │   - secrets
  19 │   - serviceaccounts
  20 │   - services
  21 │   verbs:
  22 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role192.yaml:45-56
────────────────────────────────────────
  45 ┌ - apiGroups:
  46 │   - apps
  47 │   resources:
  48 │   - deployments
  49 │   verbs:
  50 │   - create
  51 │   - delete
  52 │   - get
  53 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role192.yaml:77-88
────────────────────────────────────────
  77 ┌ - apiGroups:
  78 │   - batch
  79 │   resources:
  80 │   - cronjobs
  81 │   verbs:
  82 │   - create
  83 │   - delete
  84 │   - get
  85 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role192.yaml:14-28
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ""
  16 │   resources:
  17 │   - persistentvolumeclaims
  18 │   - secrets
  19 │   - serviceaccounts
  20 │   - services
  21 │   verbs:
  22 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role192.yaml:89-100
────────────────────────────────────────
  89 ┌ - apiGroups:
  90 │   - networking.k8s.io
  91 │   resources:
  92 │   - ingresses
  93 │   verbs:
  94 │   - create
  95 │   - delete
  96 │   - get
  97 └   - list
  ..   
────────────────────────────────────────



role193.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role193.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role193.yaml:59-70
────────────────────────────────────────
  59 ┌ - apiGroups:
  60 │   - apps
  61 │   resources:
  62 │   - deployments
  63 │   verbs:
  64 │   - create
  65 │   - delete
  66 │   - get
  67 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role193.yaml:33-44
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - ""
  35 │   resources:
  36 │   - services
  37 │   verbs:
  38 │   - create
  39 │   - delete
  40 │   - get
  41 └   - list
  ..   
────────────────────────────────────────



role215.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role215.yaml:13-21
────────────────────────────────────────
  13 ┌   - apiGroups:
  14 │       - extensions
  15 │     resourceNames:
  16 │       - kube-state-metrics
  17 │     resources:
  18 │       - deployments
  19 │     verbs:
  20 │       - get
  21 └       - update
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role215.yaml:22-30
────────────────────────────────────────
  22 ┌   - apiGroups:
  23 │       - apps
  24 │     resourceNames:
  25 │       - kube-state-metrics
  26 │     resources:
  27 │       - deployments
  28 │     verbs:
  29 │       - get
  30 └       - update
────────────────────────────────────────



role22.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'backsnap-manager' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role22.yaml:59-70
────────────────────────────────────────
  59 ┌ - apiGroups:
  60 │   - batch
  61 │   resources:
  62 │   - jobs
  63 │   verbs:
  64 │   - create
  65 │   - delete
  66 │   - get
  67 └   - list
  ..   
────────────────────────────────────────



role226.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role226.yaml:17-27
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - ""
  19 │   resources:
  20 │   - secrets
  21 │   verbs:
  22 │   - create
  23 │   - get
  24 │   - list
  25 └   - patch
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role226.yaml:7-16
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 │   - patch
  15 │   - update
  16 └   - watch
────────────────────────────────────────



role227.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 110, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 2, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role227.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role227.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role227.yaml:22-36
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - apps
  24 │   resources:
  25 │   - daemonsets
  26 │   - deployments
  27 │   - replicasets
  28 │   - statefulsets
  29 │   verbs:
  30 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role227.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role227.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - pods
  12 │   - secrets
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role227.yaml:66-77
────────────────────────────────────────
  66 ┌ - apiGroups:
  67 │   - networking.k8s.io
  68 │   resources:
  69 │   - ingresses
  70 │   verbs:
  71 │   - create
  72 │   - delete
  73 │   - get
  74 └   - list
  ..   
────────────────────────────────────────



role23.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'backsnap-manager' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role23.yaml:59-70
────────────────────────────────────────
  59 ┌ - apiGroups:
  60 │   - batch
  61 │   resources:
  62 │   - jobs
  63 │   verbs:
  64 │   - create
  65 │   - delete
  66 │   - get
  67 └   - list
  ..   
────────────────────────────────────────



role232.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role232.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role232.yaml:26-34
────────────────────────────────────────
  26 ┌ - apiGroups:
  27 │   - ""
  28 │   resources:
  29 │   - pods
  30 │   verbs:
  31 │   - create
  32 │   - get
  33 │   - list
  34 └   - watch
────────────────────────────────────────



role233.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role233.yaml:7-16
────────────────────────────────────────
   7 ┌ - resources:
   8 │   - secrets
   9 │   verbs:
  10 │   - create
  11 │   - delete
  12 │   - get
  13 │   - list
  14 │   - patch
  15 │   - update
  16 └   - watch
────────────────────────────────────────



role234.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role234.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"]
   8 │   resources: ["services","persistentvolumeclaims","pods"]
   9 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'developer-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role234.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"]
   8 │   resources: ["services","persistentvolumeclaims","pods"]
   9 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'developer-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role234.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"]
   8 │   resources: ["services","persistentvolumeclaims","pods"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role237.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role237.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role239.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role239.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role24.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kube-prometheus-stack-kube-state-metrics' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role24.yaml:132-135
────────────────────────────────────────
 132 ┌ - apiGroups: [""]
 133 │   resources:
 134 │   - secrets
 135 └   verbs: ["list", "watch"]
────────────────────────────────────────



role242.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 2, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kubelb-ccm' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role242.yaml:15-26
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ""
  17 │   resources:
  18 │   - secrets
  19 │   verbs:
  20 │   - create
  21 │   - delete
  22 │   - get
  23 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kubelb-ccm' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role242.yaml:27-37
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - ""
  29 │   resources:
  30 │   - services
  31 │   verbs:
  32 │   - create
  33 │   - get
  34 │   - list
  35 └   - patch
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kubelb-ccm' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role242.yaml:132-141
────────────────────────────────────────
 132 ┌ - apiGroups:
 133 │   - networking.k8s.io
 134 │   resources:
 135 │   - ingresses
 136 │   verbs:
 137 │   - get
 138 │   - list
 139 │   - patch
 140 │   - update
 141 └   - watch
────────────────────────────────────────



role243.yaml (kubernetes)
=========================
Tests: 118 (SUCCESSES: 110, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 3, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'kubelb' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role243.yaml:27-38
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - ""
  29 │   resources:
  30 │   - secrets
  31 │   verbs:
  32 │   - create
  33 │   - delete
  34 │   - get
  35 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kubelb' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role243.yaml:63-74
────────────────────────────────────────
  63 ┌ - apiGroups:
  64 │   - apps
  65 │   resources:
  66 │   - daemonsets
  67 │   verbs:
  68 │   - create
  69 │   - delete
  70 │   - get
  71 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'kubelb' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role243.yaml:75-86
────────────────────────────────────────
  75 ┌ - apiGroups:
  76 │   - apps
  77 │   resources:
  78 │   - deployments
  79 │   verbs:
  80 │   - create
  81 │   - delete
  82 │   - get
  83 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'kubelb' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role243.yaml:285-298
────────────────────────────────────────
 285 ┌ - apiGroups:
 286 │   - rbac.authorization.k8s.io
 287 │   resources:
 288 │   - rolebindings
 289 │   verbs:
 290 │   - bind
 291 │   - create
 292 │   - delete
 293 └   - escalate
 ...   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'kubelb' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role243.yaml:299-312
────────────────────────────────────────
 299 ┌ - apiGroups:
 300 │   - rbac.authorization.k8s.io
 301 │   resources:
 302 │   - roles
 303 │   verbs:
 304 │   - bind
 305 │   - create
 306 │   - delete
 307 └   - escalate
 ...   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kubelb' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role243.yaml:51-62
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - ""
  53 │   resources:
  54 │   - services
  55 │   verbs:
  56 │   - create
  57 │   - delete
  58 │   - get
  59 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kubelb' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role243.yaml:87-98
────────────────────────────────────────
  87 ┌ - apiGroups:
  88 │   - discovery.k8s.io
  89 │   resources:
  90 │   - endpointslices
  91 │   verbs:
  92 │   - create
  93 │   - delete
  94 │   - get
  95 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'kubelb' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role243.yaml:265-276
────────────────────────────────────────
 265 ┌ - apiGroups:
 266 │   - networking.k8s.io
 267 │   resources:
 268 │   - ingresses
 269 │   verbs:
 270 │   - create
 271 │   - delete
 272 │   - get
 273 └   - list
 ...   
────────────────────────────────────────



role247.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role247.yaml:16-28
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - ""
  18 │   resources:
  19 │   - events
  20 │   - nodes
  21 │   - pods
  22 │   verbs:
  23 │   - create
  24 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role247.yaml:29-41
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - ""
  31 │   resources:
  32 │   - persistentvolumes
  33 │   - services
  34 │   verbs:
  35 │   - create
  36 │   - delete
  37 └   - get
  ..   
────────────────────────────────────────



role256.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role256.yaml:13-21
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - extensions
  15 │   resourceNames:
  16 │   - kube-state-metrics
  17 │   resources:
  18 │   - deployments
  19 │   verbs:
  20 │   - get
  21 └   - update
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role256.yaml:22-30
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - apps
  24 │   resourceNames:
  25 │   - kube-state-metrics
  26 │   resources:
  27 │   - deployments
  28 │   verbs:
  29 │   - get
  30 └   - update
────────────────────────────────────────



role257.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role257.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["pods"]
   8 └   verbs: ["list", "get", "create", "update", "delete"]
────────────────────────────────────────



role258.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'manage-pods' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role258.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["pods", "pods/exec"]
   9 └   verbs: ["get", "watch", "list", "create", "delete"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'manage-pods' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role258.yaml:10-12
────────────────────────────────────────
  10 ┌ - apiGroups: ["apps"]
  11 │   resources: ["deployments"]
  12 └   verbs: ["get", "watch", "list", "delete", "create"]
────────────────────────────────────────


AVD-KSV-0053 (HIGH): Role 'manage-pods' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role258.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["pods", "pods/exec"]
   9 └   verbs: ["get", "watch", "list", "create", "delete"]
────────────────────────────────────────



role259.yaml (kubernetes)
=========================
Tests: 117 (SUCCESSES: 110, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 5, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role259.yaml:43-54
────────────────────────────────────────
  43 ┌ - apiGroups:
  44 │   - ""
  45 │   resources:
  46 │   - secrets
  47 │   verbs:
  48 │   - create
  49 │   - delete
  50 │   - get
  51 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role259.yaml:31-42
────────────────────────────────────────
  31 ┌ - apiGroups:
  32 │   - ""
  33 │   resources:
  34 │   - pods
  35 │   verbs:
  36 │   - create
  37 │   - delete
  38 │   - get
  39 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role259.yaml:67-78
────────────────────────────────────────
  67 ┌ - apiGroups:
  68 │   - apps
  69 │   resources:
  70 │   - deployments
  71 │   verbs:
  72 │   - create
  73 │   - delete
  74 │   - get
  75 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role259.yaml:79-90
────────────────────────────────────────
  79 ┌ - apiGroups:
  80 │   - apps
  81 │   resources:
  82 │   - statefulsets
  83 │   verbs:
  84 │   - create
  85 │   - delete
  86 │   - get
  87 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role259.yaml:91-102
────────────────────────────────────────
  91 ┌ - apiGroups:
  92 │   - batch
  93 │   resources:
  94 │   - jobs
  95 │   verbs:
  96 │   - create
  97 │   - delete
  98 │   - get
  99 └   - list
 ...   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role259.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role259.yaml:55-66
────────────────────────────────────────
  55 ┌ - apiGroups:
  56 │   - ""
  57 │   resources:
  58 │   - services
  59 │   verbs:
  60 │   - create
  61 │   - delete
  62 │   - get
  63 └   - list
  ..   
────────────────────────────────────────



role26.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'kube-prometheus-stack-admission' shouldn't have access to manage secrets in namespace 'monitoring'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role26.yaml:25-31
────────────────────────────────────────
  25 ┌   - apiGroups:
  26 │       - ""
  27 │     resources:
  28 │       - secrets
  29 │     verbs:
  30 │       - get
  31 └       - create
────────────────────────────────────────



role261.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role261.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role261.yaml:43-54
────────────────────────────────────────
  43 ┌ - apiGroups:
  44 │   - apps
  45 │   resources:
  46 │   - deployments
  47 │   verbs:
  48 │   - create
  49 │   - delete
  50 │   - get
  51 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role261.yaml:113-124
────────────────────────────────────────
 113 ┌ - apiGroups:
 114 │   - ""
 115 │   resources:
 116 │   - services
 117 │   verbs:
 118 │   - create
 119 │   - delete
 120 │   - get
 121 └   - list
 ...   
────────────────────────────────────────



role266.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'jenkins-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role266.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""] # "" indicates the core API group
   8 │   resources: ["pods"]
   9 └   verbs: ["get", "watch", "list", "create", "delete", "update", "patch"]
────────────────────────────────────────



role27.yaml (kubernetes)
========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role27.yaml:7-16
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - nodes
  12 │   - secrets
  13 │   verbs:
  14 │   - get
  15 │   - list
  16 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role27.yaml:17-26
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - ""
  19 │   resources:
  20 │   - pods
  21 │   verbs:
  22 │   - get
  23 │   - list
  24 │   - patch
  25 │   - update
  26 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role27.yaml:33-41
────────────────────────────────────────
  33 ┌ - apiGroups:
  34 │   - apps
  35 │   resources:
  36 │   - statefulsets
  37 │   verbs:
  38 │   - get
  39 │   - list
  40 │   - patch
  41 └   - watch
────────────────────────────────────────



role28.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role28.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - batch
   9 │   resources:
  10 │   - jobs
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role283.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role283.yaml:14-26
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ""
  16 │   resources:
  17 │   - secrets
  18 │   - services
  19 │   verbs:
  20 │   - create
  21 │   - delete
  22 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role283.yaml:27-38
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - apps
  29 │   resources:
  30 │   - deployments
  31 │   verbs:
  32 │   - create
  33 │   - delete
  34 │   - get
  35 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role283.yaml:14-26
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ""
  16 │   resources:
  17 │   - secrets
  18 │   - services
  19 │   verbs:
  20 │   - create
  21 │   - delete
  22 └   - get
  ..   
────────────────────────────────────────



role284.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role284.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role285.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0112 (CRITICAL): Role 'auto-complete-me' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role285.yaml:7-12
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │       - "k8qu.io"
   9 │     resources:
  10 │       - "*"
  11 │     verbs:
  12 └       - "*"
────────────────────────────────────────



role310.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role310.yaml:7-14
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role310.yaml:15-26
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - apps
  17 │   resources:
  18 │   - deployments
  19 │   verbs:
  20 │   - create
  21 │   - delete
  22 │   - get
  23 └   - list
  ..   
────────────────────────────────────────



role321.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'podcreator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role321.yaml:6-8
────────────────────────────────────────
   6 ┌ - apiGroups: [""]
   7 │   resources: ["pods", "deployments"]
   8 └   verbs: ["get", "update", "list", "create"]
────────────────────────────────────────



role322.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role322.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - cache.example.com
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role323.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'spring-kubernetes-role' shouldn't have access to manage secrets in namespace 'study'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role323.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["configmaps", "pods", "services", "endpoints", "secrets"]
   9 └   verbs: ["get", "watch", "list"]
────────────────────────────────────────



role340.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'pod-reader' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role340.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "services", "persistentvolumeclaims"]
   9 └     verbs: ["get", "watch", "list", "create", "delete", "deletecollection", "patch"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'pod-reader' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role340.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "services", "persistentvolumeclaims"]
   9 └     verbs: ["get", "watch", "list", "create", "delete", "deletecollection", "patch"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'pod-reader' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role340.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "services", "persistentvolumeclaims"]
   9 └     verbs: ["get", "watch", "list", "create", "delete", "deletecollection", "patch"]
────────────────────────────────────────



role343.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role343.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role343.yaml:19-30
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - pods
  23 │   verbs:
  24 │   - create
  25 │   - delete
  26 │   - get
  27 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role343.yaml:45-56
────────────────────────────────────────
  45 ┌ - apiGroups:
  46 │   - ""
  47 │   resources:
  48 │   - services
  49 │   verbs:
  50 │   - create
  51 │   - delete
  52 │   - get
  53 └   - list
  ..   
────────────────────────────────────────



role344.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role344.yaml:55-66
────────────────────────────────────────
  55 ┌ - apiGroups:
  56 │   - networking.k8s.io
  57 │   resources:
  58 │   - networkpolicies
  59 │   verbs:
  60 │   - create
  61 │   - delete
  62 │   - get
  63 └   - list
  ..   
────────────────────────────────────────



role345.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 2, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role345.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role345.yaml:98-109
────────────────────────────────────────
  98 ┌ - apiGroups:
  99 │   - ""
 100 │   resources:
 101 │   - services
 102 │   verbs:
 103 │   - create
 104 │   - delete
 105 │   - get
 106 └   - list
 ...   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role345.yaml:110-121
────────────────────────────────────────
 110 ┌ - apiGroups:
 111 │   - networking.k8s.io
 112 │   resources:
 113 │   - ingresses
 114 │   verbs:
 115 │   - create
 116 │   - delete
 117 │   - get
 118 └   - list
 ...   
────────────────────────────────────────



role348.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role348.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - batch
   9 │   resources:
  10 │   - jobs
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role349.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role349.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role35.yaml (kubernetes)
========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role35.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - batch
   9 │   resources:
  10 │   - jobs
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role35.yaml:25-36
────────────────────────────────────────
  25 ┌ - apiGroups:
  26 │   - batch.tutorial.kubebuilder.io
  27 │   resources:
  28 │   - cronjobs
  29 │   verbs:
  30 │   - create
  31 │   - delete
  32 │   - get
  33 └   - list
  ..   
────────────────────────────────────────



role356.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 110, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 1, CRITICAL: 0)

AVD-KSV-0042 (MEDIUM): Role 'heimdal-deploy-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role356.yaml:6-19
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - pods
  10 │       - pods/log
  11 │       - services
  12 │     verbs:
  13 │       - get
  14 └       - watch
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'heimdal-deploy-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role356.yaml:6-19
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - pods
  10 │       - pods/log
  11 │       - services
  12 │     verbs:
  13 │       - get
  14 └       - watch
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'heimdal-deploy-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role356.yaml:20-34
────────────────────────────────────────
  20 ┌   - apiGroups:
  21 │       - apps
  22 │     resources:
  23 │       - deployments
  24 │       - replicasets
  25 │       - statefulsets
  26 │       - daemonsets
  27 │     verbs:
  28 └       - get
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'heimdal-deploy-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role356.yaml:6-19
────────────────────────────────────────
   6 ┌   - apiGroups:
   7 │       - ""
   8 │     resources:
   9 │       - pods
  10 │       - pods/log
  11 │       - services
  12 │     verbs:
  13 │       - get
  14 └       - watch
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'heimdal-deploy-role' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role356.yaml:35-46
────────────────────────────────────────
  35 ┌   - apiGroups:
  36 │       - ""
  37 │     resources:
  38 │       - secrets
  39 │     verbs:
  40 │       - get
  41 │       - watch
  42 │       - list
  43 └       - create
  ..   
────────────────────────────────────────



role357.yaml (kubernetes)
=========================
Tests: 118 (SUCCESSES: 109, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 5)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role357.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - ""
  19 │   resources:
  20 │   - secrets
  21 │   verbs:
  22 └   - "*"
────────────────────────────────────────


AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role357.yaml:48-55
────────────────────────────────────────
  48 ┌ - verbs:
  49 │   - "*"
  50 │   apiGroups:
  51 │   - ""
  52 │   resources:
  53 │   - "configmaps"
  54 │   - "secrets"
  55 └   - "services"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role357.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - ""
  19 │   resources:
  20 │   - secrets
  21 │   verbs:
  22 └   - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role357.yaml:48-55
────────────────────────────────────────
  48 ┌ - verbs:
  49 │   - "*"
  50 │   apiGroups:
  51 │   - ""
  52 │   resources:
  53 │   - "configmaps"
  54 │   - "secrets"
  55 └   - "services"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role357.yaml:56-61
────────────────────────────────────────
  56 ┌ - verbs:
  57 │   - "*"
  58 │   apiGroups:
  59 │   - "apps"
  60 │   resources:
  61 └   - "statefulsets"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role357.yaml:56-61
────────────────────────────────────────
  56 ┌ - verbs:
  57 │   - "*"
  58 │   apiGroups:
  59 │   - "apps"
  60 │   resources:
  61 └   - "statefulsets"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role357.yaml:62-73
────────────────────────────────────────
  62 ┌ - apiGroups:
  63 │   - apps
  64 │   resources:
  65 │   - deployments
  66 │   verbs:
  67 │   - get
  68 │   - list
  69 │   - create
  70 └   - update
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role357.yaml:48-55
────────────────────────────────────────
  48 ┌ - verbs:
  49 │   - "*"
  50 │   apiGroups:
  51 │   - ""
  52 │   resources:
  53 │   - "configmaps"
  54 │   - "secrets"
  55 └   - "services"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role357.yaml:48-55
────────────────────────────────────────
  48 ┌ - verbs:
  49 │   - "*"
  50 │   apiGroups:
  51 │   - ""
  52 │   resources:
  53 │   - "configmaps"
  54 │   - "secrets"
  55 └   - "services"
────────────────────────────────────────



role361.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 1)

AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role361.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""] # "" indicates the core API group
   8 │   resources: ["pods"]
   9 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'developer-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role361.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""] # "" indicates the core API group
   8 │   resources: ["pods"]
   9 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'developer-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role361.yaml:13-15
────────────────────────────────────────
  13 ┌ - apiGroups: [""] # "" indicates the core API group
  14 │   resources: ["services"]
  15 └   verbs: ["*"]
────────────────────────────────────────



role364.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role364.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role368.yaml (kubernetes)
=========================
Tests: 120 (SUCCESSES: 113, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 7)

AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:13-18
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - apps
  15 │   resources:
  16 │   - '*'
  17 │   verbs:
  18 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:19-24
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - batch
  21 │   resources:
  22 │   - '*'
  23 │   verbs:
  24 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:25-30
────────────────────────────────────────
  25 ┌ - apiGroups:
  26 │   - certificates.k8s.io
  27 │   resources:
  28 │   - '*'
  29 │   verbs:
  30 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:39-44
────────────────────────────────────────
  39 ┌ - apiGroups:
  40 │   - extensions
  41 │   resources:
  42 │   - '*'
  43 │   verbs:
  44 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:45-50
────────────────────────────────────────
  45 ┌ - apiGroups:
  46 │   - github.com
  47 │   resources:
  48 │   - '*'
  49 │   verbs:
  50 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'manager-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role368.yaml:51-56
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - rbac.authorization.k8s.io
  53 │   resources:
  54 │   - '*'
  55 │   verbs:
  56 └   - '*'
────────────────────────────────────────



role370.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role370.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ""
  23 │   resources:
  24 │   - secrets
  25 │   verbs:
  26 │   - get
  27 │   - list
  28 └   - watch
────────────────────────────────────────



role374.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role374.yaml:25-32
────────────────────────────────────────
  25 ┌ - apiGroups:
  26 │   - ""
  27 │   resources:
  28 │   - secrets
  29 │   verbs:
  30 │   - get
  31 │   - list
  32 └   - watch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role374.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role380.yaml (kubernetes)
=========================
Tests: 120 (SUCCESSES: 107, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 3, CRITICAL: 6)

AVD-KSV-0048 (MEDIUM): Role 'provisioner-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role380.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "secrets", "services", "serviceaccounts", "namespaces", "persistentvolumeclaims"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'provisioner-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role380.yaml:10-12
────────────────────────────────────────
  10 ┌   - apiGroups: ["apps"]
  11 │     resources: ["deployments","statefulsets"]
  12 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'provisioner-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role380.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "secrets", "services", "serviceaccounts", "namespaces", "persistentvolumeclaims"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): Role 'provisioner-role' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role380.yaml:34-36
────────────────────────────────────────
  34 ┌   - apiGroups: ["rbac.authorization.k8s.io"]
  35 │     resources: ["clusterrolebindings", "clusterroles", "rolebindings", "roles"]
  36 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'provisioner-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role380.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "secrets", "services", "serviceaccounts", "namespaces", "persistentvolumeclaims"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'provisioner-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role380.yaml:16-18
────────────────────────────────────────
  16 ┌   - apiGroups: ["networking.k8s.io"]
  17 │     resources: ["ingresses"]
  18 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'provisioner-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role380.yaml:25-27
────────────────────────────────────────
  25 ┌   - apiGroups: ["serving.knative.dev"]
  26 │     resources: ["services","revisions"]
  27 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'provisioner-role' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role380.yaml:46-48
────────────────────────────────────────
  46 ┌   - apiGroups: ["mysql.oracle.com"]
  47 │     resources: ["*"]
  48 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'provisioner-role' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role380.yaml:49-51
────────────────────────────────────────
  49 ┌   - apiGroups: ["cert-manager.io"]
  50 │     resources: ["*"]
  51 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'provisioner-role' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role380.yaml:43-45
────────────────────────────────────────
  43 ┌   - apiGroups: ["acid.zalan.do"]
  44 │     resources: ["*"]
  45 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'provisioner-role' shouldn't manage all resources at the namespace 'default'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role380.yaml:40-42
────────────────────────────────────────
  40 ┌   - apiGroups: ["mariadb.mmontes.io"]
  41 │     resources: ["*"]
  42 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'provisioner-role' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role380.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["pods", "configmaps", "secrets", "services", "serviceaccounts", "namespaces", "persistentvolumeclaims"]
   9 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): Role 'provisioner-role' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 role380.yaml:31-33
────────────────────────────────────────
  31 ┌   - apiGroups: ["admissionregistration.k8s.io"]
  32 │     resources: ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"]
  33 └     verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────



role381.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 1, CRITICAL: 3)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role381.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - ""
  19 │   resources:
  20 │   - secrets
  21 │   verbs:
  22 └   - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role381.yaml:17-22
────────────────────────────────────────
  17 ┌ - apiGroups:
  18 │   - ""
  19 │   resources:
  20 │   - secrets
  21 │   verbs:
  22 └   - "*"
────────────────────────────────────────


AVD-KSV-0045 (CRITICAL): Role permits wildcard verb on specific resources
════════════════════════════════════════
Check whether role permits wildcard verb on specific resources

See https://avd.aquasec.com/misconfig/ksv045
────────────────────────────────────────
 role381.yaml:56-62
────────────────────────────────────────
  56 ┌ - verbs:
  57 │   - "*"
  58 │   apiGroups:
  59 │   - "apps"
  60 │   resources:
  61 │   - "deployments"
  62 └   - "statefulsets"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role381.yaml:56-62
────────────────────────────────────────
  56 ┌ - verbs:
  57 │   - "*"
  58 │   apiGroups:
  59 │   - "apps"
  60 │   resources:
  61 │   - "deployments"
  62 └   - "statefulsets"
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role381.yaml:75-86
────────────────────────────────────────
  75 ┌ - apiGroups:
  76 │   - batch
  77 │   resources:
  78 │   - jobs
  79 │   verbs:
  80 │   - create
  81 │   - delete
  82 │   - get
  83 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role381.yaml:48-55
────────────────────────────────────────
  48 ┌ - verbs:
  49 │   - "*"
  50 │   apiGroups:
  51 │   - ""
  52 │   resources:
  53 │   - "configmaps"
  54 │   - "serviceaccounts"
  55 └   - "services"
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role381.yaml:48-55
────────────────────────────────────────
  48 ┌ - verbs:
  49 │   - "*"
  50 │   apiGroups:
  51 │   - ""
  52 │   resources:
  53 │   - "configmaps"
  54 │   - "serviceaccounts"
  55 └   - "services"
────────────────────────────────────────



role382.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 role382.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"] # "" indicates the core API group
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'testadmin' shouldn't manage all resources at the namespace 'test'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role382.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["*"] # "" indicates the core API group
   8 │   resources: ["*"]
   9 └   verbs: ["*"]
────────────────────────────────────────



role383.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role383.yaml:25-36
────────────────────────────────────────
  25 ┌ - apiGroups:
  26 │   - ""
  27 │   resources:
  28 │   - pods
  29 │   verbs:
  30 │   - create
  31 │   - delete
  32 │   - get
  33 └   - list
  ..   
────────────────────────────────────────



role423.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role423.yaml:27-38
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - apps
  29 │   resources:
  30 │   - deployments
  31 │   verbs:
  32 │   - create
  33 │   - delete
  34 │   - get
  35 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role423.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role424.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'non-admin-controller-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role424.yaml:15-26
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ""
  17 │   resources:
  18 │   - secrets
  19 │   verbs:
  20 │   - create
  21 │   - delete
  22 │   - get
  23 └   - list
  ..   
────────────────────────────────────────



role425.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role425.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role426.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role426.yaml:29-40
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - apps
  31 │   resources:
  32 │   - statefulsets
  33 │   verbs:
  34 │   - create
  35 │   - delete
  36 │   - get
  37 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role426.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - serviceaccounts
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'manager-role' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role426.yaml:79-91
────────────────────────────────────────
  79 ┌ - apiGroups:
  80 │   - rbac.authorization.k8s.io
  81 │   resources:
  82 │   - rolebindings
  83 │   - roles
  84 │   verbs:
  85 │   - create
  86 │   - delete
  87 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role426.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - serviceaccounts
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────



role427.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 109, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role427.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - serviceaccounts
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role427.yaml:31-42
────────────────────────────────────────
  31 ┌ - apiGroups:
  32 │   - apps
  33 │   resources:
  34 │   - statefulsets
  35 │   verbs:
  36 │   - create
  37 │   - delete
  38 │   - get
  39 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role427.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - serviceaccounts
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'manager-role' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role427.yaml:55-67
────────────────────────────────────────
  55 ┌ - apiGroups:
  56 │   - rbac.authorization.k8s.io
  57 │   resources:
  58 │   - clusterroles
  59 │   - rolebindings
  60 │   verbs:
  61 │   - create
  62 │   - delete
  63 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role427.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - serviceaccounts
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────



role441.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role441.yaml:13-21
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - extensions
  15 │   resourceNames:
  16 │   - kube-state-metrics
  17 │   resources:
  18 │   - deployments
  19 │   verbs:
  20 │   - get
  21 └   - update
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'kube-state-metrics' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role441.yaml:22-30
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - apps
  24 │   resourceNames:
  25 │   - kube-state-metrics
  26 │   resources:
  27 │   - deployments
  28 │   verbs:
  29 │   - get
  30 └   - update
────────────────────────────────────────



role449.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 110, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'mongodb-kubernetes-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role449.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - configmaps
  13 │   - secrets
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'mongodb-kubernetes-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role449.yaml:22-33
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - apps
  24 │   resources:
  25 │   - statefulsets
  26 │   verbs:
  27 │   - create
  28 │   - delete
  29 │   - get
  30 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'mongodb-kubernetes-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role449.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - configmaps
  13 │   - secrets
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'mongodb-kubernetes-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role449.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - configmaps
  13 │   - secrets
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'mongodb-kubernetes-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role449.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - pods
  11 │   - services
  12 │   - configmaps
  13 │   - secrets
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────



role453.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 2, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role453.yaml:10-25
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - services
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └     verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0042 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role453.yaml:10-25
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - services
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └     verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role453.yaml:10-25
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - services
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └     verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role453.yaml:26-40
────────────────────────────────────────
  26 ┌   - apiGroups:
  27 │       - apps
  28 │     resources:
  29 │       - deployments
  30 │       - daemonsets
  31 │       - replicasets
  32 │       - statefulsets
  33 │     verbs:
  34 └       - create
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'manager-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role453.yaml:10-25
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - services
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └     verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role453.yaml:10-25
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - services
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └     verbs:
  ..   
────────────────────────────────────────



role456.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role456.yaml:36-43
────────────────────────────────────────
  36 ┌ - apiGroups:
  37 │   - ""
  38 │   resources:
  39 │   - secrets
  40 │   verbs:
  41 │   - get
  42 │   - list
  43 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role456.yaml:56-67
────────────────────────────────────────
  56 ┌ - apiGroups:
  57 │   - apps
  58 │   resources:
  59 │   - statefulsets
  60 │   verbs:
  61 │   - create
  62 │   - delete
  63 │   - get
  64 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role456.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role456.yaml:44-55
────────────────────────────────────────
  44 ┌ - apiGroups:
  45 │   - ""
  46 │   resources:
  47 │   - services
  48 │   verbs:
  49 │   - create
  50 │   - delete
  51 │   - get
  52 └   - list
  ..   
────────────────────────────────────────



role459.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role459.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role460.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role460.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - serviceaccounts
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role460.yaml:30-41
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - apps
  32 │   resources:
  33 │   - statefulsets
  34 │   verbs:
  35 │   - create
  36 │   - delete
  37 │   - get
  38 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role460.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - serviceaccounts
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role460.yaml:7-21
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - serviceaccounts
  13 │   - services
  14 │   verbs:
  15 └   - create
  ..   
────────────────────────────────────────



role461.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'role-full-access-to-secrets' shouldn't have access to manage secrets in namespace 'k8s-ecr-token-updater'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role461.yaml:7-14
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   resources:
  10 │   - secrets
  11 │   resourceNames:
  12 │   - regcred
  13 │   verbs:
  14 └   - delete
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'role-full-access-to-secrets' shouldn't have access to manage secrets in namespace 'k8s-ecr-token-updater'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role461.yaml:15-20
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ''
  17 │   resources:
  18 │   - secrets
  19 │   verbs:
  20 └   - create
────────────────────────────────────────



role462.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role462.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role462.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - apps
  23 │   resources:
  24 │   - statefulsets
  25 │   verbs:
  26 │   - create
  27 │   - delete
  28 │   - get
  29 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role462.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role462.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────



role474.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'kubernetes-secrets-provider' shouldn't have access to manage secrets in namespace 'jenkins'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role474.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["secrets"]
   9 └     verbs: ["get", "list"]
────────────────────────────────────────



role476.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role476.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["deployments", "replicasets", "pods"]
   9 └   verbs: ["get", "list", "watch", "create", "update", "patch", "delete"] # You can also use ["*"]
────────────────────────────────────────



role477.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 role477.yaml:7-9
────────────────────────────────────────
   7 ┌   - verbs: ["*"]
   8 │     apiGroups: ["*"]
   9 └     resources: ["*"]
────────────────────────────────────────


AVD-KSV-0112 (CRITICAL): Role 'testadmin' shouldn't manage all resources at the namespace 'rbac-test'
════════════════════════════════════════
Full control of the resources within a namespace.  In some cluster configurations, this is excessive. In others, this is normal (a gitops deployment operator like flux)

See https://avd.aquasec.com/misconfig/ksv112
────────────────────────────────────────
 role477.yaml:7-9
────────────────────────────────────────
   7 ┌   - verbs: ["*"]
   8 │     apiGroups: ["*"]
   9 └     resources: ["*"]
────────────────────────────────────────



role478.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'deployment-manager' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role478.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups: ["","extensions","apps"]
   8 │   #
   9 │   # at the HTTP level, the name of the resource for accessing ConfigMap
  10 │   # objects is "configmaps"
  11 │   resources: ["deployments","replicasets","pods"]
  12 └   verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
────────────────────────────────────────



role479.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 109, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 2, CRITICAL: 1)

AVD-KSV-0048 (MEDIUM): Role 'redis-enterprise-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role479.yaml:26-28
────────────────────────────────────────
  26 ┌   - apiGroups: ["apps"]
  27 │     resources: ["deployments", "statefulsets", "replicasets"]
  28 └     verbs: ["create", "delete", "deletecollection", "get", "list", "patch", "update", "watch"]
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'redis-enterprise-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role479.yaml:38-40
────────────────────────────────────────
  38 ┌   - apiGroups: [""]
  39 │     resources: ["pods"]
  40 └     verbs: ["get", "watch", "list", "update", "patch", "delete"]
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'redis-enterprise-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role479.yaml:32-34
────────────────────────────────────────
  32 ┌   - apiGroups: [""]
  33 │     resources: ["configmaps"]
  34 └     verbs: ["create", "delete", "get" , "update", "list", "watch"]
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): Role 'redis-enterprise-operator' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role479.yaml:6-9
────────────────────────────────────────
   6 ┌   - apiGroups: ["rbac.authorization.k8s.io", ""]
   7 │     resources: ["roles", "serviceaccounts", "rolebindings"]
   8 │     verbs: ["bind", "escalate", "impersonate", "userextras", "create", "get",
   9 └             "list", "watch", "update", "patch", "delete", "deletecollection"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'redis-enterprise-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role479.yaml:41-43
────────────────────────────────────────
  41 ┌   - apiGroups: [""]
  42 │     resources: ["services"]
  43 └     verbs: ["get", "watch", "list", "update", "patch", "create", "delete"]
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'redis-enterprise-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role479.yaml:48-51
────────────────────────────────────────
  48 ┌   - apiGroups: ["networking.k8s.io"]
  49 │     resources: ["ingresses"]
  50 │     verbs: ["create", "patch", "replace", "delete", "deletecollection", "read", "list", "listallnamespaces",
  51 └             "watch", "watchlist", "watchlistallnamespaces", "patchstatus", "readstatus", "replacestatus", "update"]
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'redis-enterprise-operator' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role479.yaml:16-19
────────────────────────────────────────
  16 ┌   - apiGroups: [""]
  17 │     resources: ["secrets"]
  18 │     verbs: ["update", "get", "read", "list", "listallnamespaces", "watch", "watchlist",
  19 └             "watchlistallnamespaces", "create", "patch", "replace", "delete", "deletecollection"]
────────────────────────────────────────



role480.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role480.yaml:14-25
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - apps
  16 │   resources:
  17 │   - deployments
  18 │   verbs:
  19 │   - create
  20 │   - delete
  21 │   - get
  22 └   - list
  ..   
────────────────────────────────────────



role494.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'developer' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role494.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: ["", "extensions", "apps"]
   8 │   resources: ["deployments", "replicasets", "pods"]
   9 └   verbs: ["get", "list", "watch", "create", "update", "patch", "delete"] # You can also use ["*"]
────────────────────────────────────────



role495.yaml (kubernetes)
=========================
Tests: 117 (SUCCESSES: 107, FAILURES: 10)
Failures: 10 (UNKNOWN: 0, LOW: 0, MEDIUM: 5, HIGH: 3, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role495.yaml:10-28
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - pods
  15 │       - pods/exec
  16 │       - pods/log
  17 │       - persistentvolumeclaims
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0042 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role495.yaml:10-28
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - pods
  15 │       - pods/exec
  16 │       - pods/log
  17 │       - persistentvolumeclaims
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role495.yaml:10-28
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - pods
  15 │       - pods/exec
  16 │       - pods/log
  17 │       - persistentvolumeclaims
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role495.yaml:29-43
────────────────────────────────────────
  29 ┌   - apiGroups:
  30 │       - apps
  31 │     resources:
  32 │       - deployments
  33 │       - daemonsets
  34 │       - replicasets
  35 │       - statefulsets
  36 │     verbs:
  37 └       - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role495.yaml:44-55
────────────────────────────────────────
  44 ┌   - apiGroups:
  45 │       - batch
  46 │     resources:
  47 │       - jobs
  48 │     verbs:
  49 │       - create
  50 │       - delete
  51 │       - get
  52 └       - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role495.yaml:10-28
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - pods
  15 │       - pods/exec
  16 │       - pods/log
  17 │       - persistentvolumeclaims
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'manager-role' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role495.yaml:56-68
────────────────────────────────────────
  56 ┌   - apiGroups:
  57 │       - rbac.authorization.k8s.io
  58 │     resources:
  59 │       - roles
  60 │       - rolebindings
  61 │     verbs:
  62 │       - create
  63 │       - delete
  64 └       - get
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'manager-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role495.yaml:10-28
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - pods
  15 │       - pods/exec
  16 │       - pods/log
  17 │       - persistentvolumeclaims
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role495.yaml:10-28
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - pods
  15 │       - pods/exec
  16 │       - pods/log
  17 │       - persistentvolumeclaims
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role495.yaml:69-80
────────────────────────────────────────
  69 ┌   - apiGroups:
  70 │       - networking.k8s.io
  71 │     resources:
  72 │       - ingresses
  73 │     verbs:
  74 │       - create
  75 │       - delete
  76 │       - get
  77 └       - list
  ..   
────────────────────────────────────────



role499.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 108, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 2, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role499.yaml:10-26
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - configmaps
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0042 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 role499.yaml:10-26
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - configmaps
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role499.yaml:10-26
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - configmaps
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role499.yaml:27-41
────────────────────────────────────────
  27 ┌   - apiGroups:
  28 │       - apps
  29 │     resources:
  30 │       - deployments
  31 │       - daemonsets
  32 │       - replicasets
  33 │       - statefulsets
  34 │     verbs:
  35 └       - create
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role499.yaml:10-26
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - configmaps
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'manager-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role499.yaml:10-26
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - configmaps
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └       - services
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role499.yaml:10-26
────────────────────────────────────────
  10 ┌   - apiGroups:
  11 │       - ""
  12 │     resources:
  13 │       - secrets
  14 │       - configmaps
  15 │       - pods
  16 │       - pods/exec
  17 │       - pods/log
  18 └       - services
  ..   
────────────────────────────────────────



role52.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'secret-reader-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role52.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["secrets"]
   9 └   verbs: ["get", "list", "create", "update", "patch"]
────────────────────────────────────────



role521.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'secret-reader' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role521.yaml:7-17
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────



role523.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role523.yaml:39-50
────────────────────────────────────────
  39 ┌ - apiGroups:
  40 │   - ""
  41 │   resources:
  42 │   - pods
  43 │   verbs:
  44 │   - create
  45 │   - delete
  46 │   - get
  47 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role523.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role524.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role524.yaml:15-24
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ""
  17 │   resources:
  18 │   - pods
  19 │   verbs:
  20 │   - delete
  21 │   - get
  22 │   - list
  23 │   - patch
  24 └   - update
────────────────────────────────────────



role525.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 112, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role525.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role525.yaml:19-27
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - pods
  23 │   verbs:
  24 │   - create
  25 │   - get
  26 │   - list
  27 └   - watch
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role525.yaml:28-39
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - ""
  30 │   resources:
  31 │   - services
  32 │   verbs:
  33 │   - create
  34 │   - delete
  35 │   - get
  36 └   - list
  ..   
────────────────────────────────────────



role526.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role526.yaml:14-25
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ""
  16 │   resources:
  17 │   - secrets
  18 │   verbs:
  19 │   - create
  20 │   - delete
  21 │   - get
  22 └   - list
  ..   
────────────────────────────────────────



role527.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role527.yaml:36-42
────────────────────────────────────────
  36 ┌   - apiGroups:
  37 │       - ""
  38 │     resources:
  39 │       - secrets
  40 │     verbs:
  41 │       - get
  42 └       - list
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role527.yaml:19-27
────────────────────────────────────────
  19 ┌   - apiGroups:
  20 │       - batch
  21 │     resources:
  22 │       - jobs
  23 │     verbs:
  24 │       - create
  25 │       - get
  26 │       - list
  27 └       - watch
────────────────────────────────────────


AVD-KSV-0114 (CRITICAL): ClusterRole 'manager-role' should not have access to resources ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Webhooks can silently intercept or actively mutate/block resources as they are being created or updated. This includes secrets and pod specs.

See https://avd.aquasec.com/misconfig/ksv114
────────────────────────────────────────
 role527.yaml:7-18
────────────────────────────────────────
   7 ┌   - apiGroups:
   8 │       - admissionregistration.k8s.io
   9 │     resources:
  10 │       - mutatingwebhookconfigurations
  11 │     verbs:
  12 │       - create
  13 │       - delete
  14 │       - get
  15 └       - list
  ..   
────────────────────────────────────────



role529.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role529.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role53.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'namespace-reader' shouldn't have access to manage secrets in namespace 'spring-petclinic'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role53.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ''
   9 │   - extensions
  10 │   - apps
  11 │   resources:
  12 │   - configmaps
  13 │   - pods
  14 │   - services
  15 └   - endpoints
  ..   
────────────────────────────────────────



role533.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'my-ing-ingress-nginx-admission' shouldn't have access to manage secrets in namespace 'ingress'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role533.yaml:19-25
────────────────────────────────────────
  19 ┌   - apiGroups:
  20 │       - ""
  21 │     resources:
  22 │       - secrets
  23 │     verbs:
  24 │       - get
  25 └       - create
────────────────────────────────────────



role534.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 110, FAILURES: 5)
Failures: 5 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'mongodb-kubernetes-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role534.yaml:8-22
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - configmaps
  14 │   - secrets
  15 │   verbs:
  16 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): Role 'mongodb-kubernetes-operator' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role534.yaml:23-34
────────────────────────────────────────
  23 ┌ - apiGroups:
  24 │   - apps
  25 │   resources:
  26 │   - statefulsets
  27 │   verbs:
  28 │   - create
  29 │   - delete
  30 │   - get
  31 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): Role 'mongodb-kubernetes-operator' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role534.yaml:8-22
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - configmaps
  14 │   - secrets
  15 │   verbs:
  16 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): Role 'mongodb-kubernetes-operator' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role534.yaml:8-22
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - configmaps
  14 │   - secrets
  15 │   verbs:
  16 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'mongodb-kubernetes-operator' shouldn't have access to manage secrets in namespace 'mongodb'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role534.yaml:8-22
────────────────────────────────────────
   8 ┌ - apiGroups:
   9 │   - ""
  10 │   resources:
  11 │   - pods
  12 │   - services
  13 │   - configmaps
  14 │   - secrets
  15 │   verbs:
  16 └   - create
  ..   
────────────────────────────────────────



role535.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'istiod' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role535.yaml:25-27
────────────────────────────────────────
  25 ┌ - apiGroups: [""]
  26 │   resources: ["configmaps"]
  27 └   verbs: ["delete"]
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'istiod' shouldn't have access to manage secrets in namespace 'istio-system'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role535.yaml:19-22
────────────────────────────────────────
  19 ┌ - apiGroups: [""]
  20 │   resources: ["secrets"]
  21 │   # TODO lock this down to istio-ca-cert if not using the DNS cert mesh config
  22 └   verbs: ["create", "get", "watch", "list", "update", "delete"]
────────────────────────────────────────



role536.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'istiod' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role536.yaml:25-27
────────────────────────────────────────
  25 ┌ - apiGroups: [""]
  26 │   resources: ["configmaps"]
  27 └   verbs: ["delete"]
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'istiod' shouldn't have access to manage secrets in namespace 'istio-system'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role536.yaml:19-22
────────────────────────────────────────
  19 ┌ - apiGroups: [""]
  20 │   resources: ["secrets"]
  21 │   # TODO lock this down to istio-ca-cert if not using the DNS cert mesh config
  22 └   verbs: ["create", "get", "watch", "list", "update", "delete"]
────────────────────────────────────────



role537.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'istiod' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role537.yaml:25-27
────────────────────────────────────────
  25 ┌ - apiGroups: [""]
  26 │   resources: ["configmaps"]
  27 └   verbs: ["delete"]
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'istiod' shouldn't have access to manage secrets in namespace 'istio-system'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role537.yaml:19-22
────────────────────────────────────────
  19 ┌ - apiGroups: [""]
  20 │   resources: ["secrets"]
  21 │   # TODO lock this down to istio-ca-cert if not using the DNS cert mesh config
  22 └   verbs: ["create", "get", "watch", "list", "update", "delete"]
────────────────────────────────────────



role539.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role539.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - cronjob.tutorial.kubebuilder.io
   9 │   resources:
  10 │   - cronjobs
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role54.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 1, CRITICAL: 0)

AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role54.yaml:35-46
────────────────────────────────────────
  35 ┌ - apiGroups:
  36 │   - networking.k8s.io
  37 │   resources:
  38 │   - ingresses
  39 │   verbs:
  40 │   - create
  41 │   - delete
  42 │   - get
  43 └   - list
  ..   
────────────────────────────────────────



role541.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): Role 'pod-manager' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role541.yaml:7-9
────────────────────────────────────────
   7 ┌ - apiGroups: [""]
   8 │   resources: ["pods"]
   9 └   verbs: ["get", "list", "create", "delete"]
────────────────────────────────────────



role544.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'spring-cloud-kubernetes-role' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 role544.yaml:7-9
────────────────────────────────────────
   7 ┌   - apiGroups: [""]
   8 │     resources: ["configmaps", "secrets", "endpoints", "pods", "services"]
   9 └     verbs: ["get", "list", "watch"]
────────────────────────────────────────



role55.yaml (kubernetes)
========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 role55.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'controller-role' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 role55.yaml:7-12
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - '*'
   9 │   resources:
  10 │   - '*'
  11 │   verbs:
  12 └   - '*'
────────────────────────────────────────



role557.yaml (kubernetes)
=========================
Tests: 117 (SUCCESSES: 113, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 4, HIGH: 0, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role557.yaml:16-25
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - apps
  18 │   resources:
  19 │   - deployments
  20 │   verbs:
  21 │   - get
  22 │   - list
  23 │   - patch
  24 │   - update
  25 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role557.yaml:76-85
────────────────────────────────────────
  76 ┌ - apiGroups:
  77 │   - apps
  78 │   resources:
  79 │   - statefulsets
  80 │   verbs:
  81 │   - get
  82 │   - list
  83 │   - patch
  84 │   - update
  85 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role557.yaml:96-104
────────────────────────────────────────
  96 ┌ - apiGroups:
  97 │   - batch
  98 │   resources:
  99 │   - cronjobs
 100 │   verbs:
 101 │   - create
 102 │   - get
 103 │   - list
 104 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role557.yaml:105-113
────────────────────────────────────────
 105 ┌ - apiGroups:
 106 │   - batch
 107 │   resources:
 108 │   - jobs
 109 │   verbs:
 110 │   - create
 111 │   - get
 112 │   - list
 113 └   - watch
────────────────────────────────────────



role559.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role559.yaml:36-43
────────────────────────────────────────
  36 ┌ - apiGroups:
  37 │   - ""
  38 │   resources:
  39 │   - secrets
  40 │   verbs:
  41 │   - get
  42 │   - list
  43 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role559.yaml:18-29
────────────────────────────────────────
  18 ┌ - apiGroups:
  19 │   - ""
  20 │   resources:
  21 │   - pods
  22 │   verbs:
  23 │   - create
  24 │   - delete
  25 │   - get
  26 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'manager-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 role559.yaml:30-35
────────────────────────────────────────
  30 ┌ - apiGroups:
  31 │   - ""
  32 │   resources:
  33 │   - pods/exec
  34 │   verbs:
  35 └   - create
────────────────────────────────────────



role56.yaml (kubernetes)
========================
Tests: 115 (SUCCESSES: 109, FAILURES: 6)
Failures: 6 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 2, CRITICAL: 2)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role56.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - endpoints
  11 │   - namespaces
  12 │   - nodes
  13 │   - nodes/proxy
  14 │   - secrets
  15 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0047 (HIGH): Role permits privilege escalation from node proxy
════════════════════════════════════════
Check whether role permits privilege escalation from node proxy

See https://avd.aquasec.com/misconfig/ksv047
────────────────────────────────────────
 role56.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - endpoints
  11 │   - namespaces
  12 │   - nodes
  13 │   - nodes/proxy
  14 │   - secrets
  15 └   verbs:
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role56.yaml:19-33
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - persistentvolumeclaims
  23 │   - pods
  24 │   - serviceaccounts
  25 │   - services
  26 │   verbs:
  27 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role56.yaml:34-47
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - apps
  36 │   resources:
  37 │   - daemonsets
  38 │   - replicasets
  39 │   - statefulsets
  40 │   verbs:
  41 │   - create
  42 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0050 (CRITICAL): ClusterRole 'manager-role' should not have access to resources ["roles", "rolebindings"] for verbs ["create", "update", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
An effective level of access equivalent to cluster-admin should not be provided.

See https://avd.aquasec.com/misconfig/ksv050
────────────────────────────────────────
 role56.yaml:60-74
────────────────────────────────────────
  60 ┌ - apiGroups:
  61 │   - rbac.authorization.k8s.io
  62 │   resources:
  63 │   - clusterrolebindings
  64 │   - clusterroles
  65 │   - rolebindings
  66 │   - roles
  67 │   verbs:
  68 └   - create
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role56.yaml:19-33
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - persistentvolumeclaims
  23 │   - pods
  24 │   - serviceaccounts
  25 │   - services
  26 │   verbs:
  27 └   - create
  ..   
────────────────────────────────────────



role565.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 111, FAILURES: 3)
Failures: 3 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role565.yaml:7-17
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - apps
   9 │   resources:
  10 │   - deployments
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role565.yaml:29-40
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - ""
  31 │   resources:
  32 │   - configmaps
  33 │   - services
  34 │   verbs:
  35 │   - create
  36 │   - delete
  37 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role565.yaml:29-40
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - ""
  31 │   resources:
  32 │   - configmaps
  33 │   - services
  34 │   verbs:
  35 │   - create
  36 │   - delete
  37 └   - get
  ..   
────────────────────────────────────────



role566.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role566.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────



role572.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role572.yaml:19-30
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - ""
  21 │   resources:
  22 │   - secrets
  23 │   verbs:
  24 │   - create
  25 │   - delete
  26 │   - get
  27 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role572.yaml:43-54
────────────────────────────────────────
  43 ┌ - apiGroups:
  44 │   - apps
  45 │   resources:
  46 │   - deployments
  47 │   verbs:
  48 │   - create
  49 │   - delete
  50 │   - get
  51 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role572.yaml:63-74
────────────────────────────────────────
  63 ┌ - apiGroups:
  64 │   - batch
  65 │   resources:
  66 │   - jobs
  67 │   verbs:
  68 │   - create
  69 │   - delete
  70 │   - get
  71 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role572.yaml:31-42
────────────────────────────────────────
  31 ┌ - apiGroups:
  32 │   - ""
  33 │   resources:
  34 │   - services
  35 │   verbs:
  36 │   - create
  37 │   - delete
  38 │   - get
  39 └   - list
  ..   
────────────────────────────────────────



role574.yaml (kubernetes)
=========================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 2, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role574.yaml:39-50
────────────────────────────────────────
  39 ┌ - apiGroups:
  40 │   - apps
  41 │   resources:
  42 │   - deployments
  43 │   verbs:
  44 │   - create
  45 │   - delete
  46 │   - get
  47 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role574.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role574.yaml:29-38
────────────────────────────────────────
  29 ┌ - apiGroups:
  30 │   - ""
  31 │   resources:
  32 │   - services
  33 │   verbs:
  34 │   - create
  35 │   - get
  36 │   - list
  37 │   - update
  38 └   - watch
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role574.yaml:51-62
────────────────────────────────────────
  51 ┌ - apiGroups:
  52 │   - networking.k8s.io
  53 │   resources:
  54 │   - ingresses
  55 │   verbs:
  56 │   - create
  57 │   - delete
  58 │   - get
  59 └   - list
  ..   
────────────────────────────────────────



role575.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role575.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   verbs:
  13 │   - create
  14 │   - delete
  15 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role575.yaml:7-19
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   verbs:
  13 │   - create
  14 │   - delete
  15 └   - get
  ..   
────────────────────────────────────────



role576.yaml (kubernetes)
=========================
Tests: 116 (SUCCESSES: 112, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 3, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role576.yaml:27-34
────────────────────────────────────────
  27 ┌ - apiGroups:
  28 │   - ""
  29 │   resources:
  30 │   - secrets
  31 │   verbs:
  32 │   - get
  33 │   - list
  34 └   - watch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role576.yaml:15-26
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ""
  17 │   resources:
  18 │   - pods
  19 │   verbs:
  20 │   - create
  21 │   - delete
  22 │   - get
  23 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role576.yaml:61-72
────────────────────────────────────────
  61 ┌ - apiGroups:
  62 │   - batch
  63 │   resources:
  64 │   - cronjobs
  65 │   verbs:
  66 │   - create
  67 │   - delete
  68 │   - get
  69 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role576.yaml:73-84
────────────────────────────────────────
  73 ┌ - apiGroups:
  74 │   - batch
  75 │   resources:
  76 │   - jobs
  77 │   verbs:
  78 │   - create
  79 │   - delete
  80 │   - get
  81 └   - list
  ..   
────────────────────────────────────────



role583.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 113, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role583.yaml:7-14
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - get
  13 │   - list
  14 └   - watch
────────────────────────────────────────



role584.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 112, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role584.yaml:7-18
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - secrets
  11 │   verbs:
  12 │   - create
  13 │   - delete
  14 │   - get
  15 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role584.yaml:19-28
────────────────────────────────────────
  19 ┌ - apiGroups:
  20 │   - apps
  21 │   resources:
  22 │   - deployments
  23 │   verbs:
  24 │   - get
  25 │   - list
  26 │   - patch
  27 │   - update
  28 └   - watch
────────────────────────────────────────



role585.yaml (kubernetes)
=========================
Tests: 114 (SUCCESSES: 110, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 role585.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'manager-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 role585.yaml:21-32
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - apps
  23 │   resources:
  24 │   - statefulsets
  25 │   verbs:
  26 │   - create
  27 │   - delete
  28 │   - get
  29 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'manager-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 role585.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────


AVD-KSV-0056 (HIGH): ClusterRole 'manager-role' should not have access to resources ["services", "endpoints", "endpointslices", "networkpolicies", "ingresses"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to control which pods get service traffic directed to them allows for interception attacks. Controlling network policy allows for bypassing lateral movement restrictions.

See https://avd.aquasec.com/misconfig/ksv056
────────────────────────────────────────
 role585.yaml:7-20
────────────────────────────────────────
   7 ┌ - apiGroups:
   8 │   - ""
   9 │   resources:
  10 │   - configmaps
  11 │   - secrets
  12 │   - services
  13 │   verbs:
  14 │   - create
  15 └   - delete
  ..   
────────────────────────────────────────


