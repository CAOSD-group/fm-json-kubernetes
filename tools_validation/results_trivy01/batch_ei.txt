
Report Summary

┌──────────────────────────────────────────────────────────┬────────────┬───────────────────┐
│                          Target                          │    Type    │ Misconfigurations │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ IntrusionDetection.yaml                                  │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ IntrusionDetection_1.yaml                                │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_19.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_20.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_21.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_22.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_23.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_24.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_25.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_26.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_27.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_28.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_29.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_3.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_30.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_31.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_32.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_34.yaml                                         │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_35.yaml                                         │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_39.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_4.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_40.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_41.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_42.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_43.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_44.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_5.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_6.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_7.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_8.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install1_9.yaml                                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_42.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_43.yaml                                        │ kubernetes │        10         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install29_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_10.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_11.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_12.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_13.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_14.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_15.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_16.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_17.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_18.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_19.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_2.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_20.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_21.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_22.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_23.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_24.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_25.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_26.yaml                                         │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_27.yaml                                         │ kubernetes │        35         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_28.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_29.yaml                                         │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_3.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_30.yaml                                         │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_4.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_5.yaml                                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_6.yaml                                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_7.yaml                                          │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_8.yaml                                          │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install2_9.yaml                                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3.yaml                                            │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install30_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32.yaml                                           │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_1.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_13.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_14.yaml                                        │ kubernetes │         7         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_2.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install32_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install33_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install34_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install36_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install37_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install39_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_10.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_11.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_12.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_13.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_14.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_15.yaml                                         │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_16.yaml                                         │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_17.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_18.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_19.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_20.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_21.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_22.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_23.yaml                                         │ kubernetes │        10         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_24.yaml                                         │ kubernetes │        10         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install3_9.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_17.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_18.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_33.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_34.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_35.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_36.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_42.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_43.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_44.yaml                                        │ kubernetes │         8         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_48.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_49.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_50.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_51.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install51_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_10.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_12.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_13.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_14.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_15.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_16.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_17.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_18.yaml                                        │ kubernetes │         2         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_19.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_20.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_21.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_22.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_23.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_24.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_25.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_26.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_27.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_28.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_29.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_30.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_31.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_32.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_33.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_34.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_35.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_36.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_37.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_38.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_39.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_4.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_40.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_41.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_42.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_43.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_44.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_46.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_47.yaml                                        │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_48.yaml                                        │ kubernetes │        15         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_5.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_52.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_53.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_54.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_55.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_56.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_57.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_58.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install53_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install56.yaml                                           │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install56_1.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install56_2.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install56_3.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install57.yaml                                           │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install57_1.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install57_2.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install57_3.yaml                                         │ kubernetes │        14         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_1.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_10.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_11.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_12.yaml                                        │ kubernetes │        13         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_3.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_4.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_5.yaml                                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_6.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_7.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_8.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install58_9.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ install_package_path.golden.yaml                         │ kubernetes │         9         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2.yaml                                       │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_1.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_15.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_16.yaml                                    │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_17.yaml                                    │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_19.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_2.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_20.yaml                                    │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_22.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_23.yaml                                    │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_27.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_28.yaml                                    │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_29.yaml                                    │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_3.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_30.yaml                                    │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_33.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_34.yaml                                    │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_36.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_37.yaml                                    │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_4.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_5.yaml                                     │ kubernetes │         7         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_6.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_7.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_8.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ installation2_9.yaml                                     │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instaslice_editor_role.yaml                              │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instaslice_viewer_role.yaml                              │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instructor-service-deployment.yaml                       │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instructor-service-service.yaml                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instrumentation-replace-backend2.yaml                    │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instrumentation_editor_role.yaml                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instrumentation_viewer_role.yaml                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instrumented-app-deploy.yaml                             │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ instrumented-app-svc.yaml                                │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ integration-prometheus-clusterrole.yaml                  │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ integration-prometheus-clusterrole_1.yaml                │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ integration-vault-kubegres.yaml                          │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ integration_admin_role.yaml                              │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ integration_editor_role.yaml                             │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ integration_viewer_role.yaml                             │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ intelgpu-job.yaml                                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inter-pod-affinity.yaml                                  │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inter-pod-affinity_1.yaml                                │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ interceptors.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ interceptors_1.yaml                                      │ kubernetes │         7         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ interceptors_2.yaml                                      │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal-deploy.yaml                                     │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal-load-balanced-service.yaml                      │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal-netpol.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal-network-policy.yaml                             │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal-service.yaml                                    │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal-svc.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion.yaml   │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion1.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion10.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion11.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion12.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion13.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion14.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion15.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion16.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion17.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion18.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion19.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion2.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion20.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion21.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion22.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion23.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion24.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion25.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion26.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion27.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion28.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion29.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion3.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion33.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion34.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion35.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion36.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion37.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion38.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion39.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion4.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion40.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion41.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion42.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion43.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion44.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion45.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion46.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion47.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion48.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion49.yaml │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion5.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion6.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion7.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion8.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal.apiserver.k8s.io.v1alpha1.StorageVersion9.yaml  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal_network.yaml                                    │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal_service_serverToDB.yaml                         │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ internal_service_serverToDB1.yaml                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-cm.yaml                                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-cm1.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-metadata.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-metadata_1.yaml                                  │ kubernetes │         4         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-metadata_2.yaml                                  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-metadata_3.yaml                                  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod.yaml                                         │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod1.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod10.yaml                                       │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod11.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod12.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod13.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod14.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod15.yaml                                       │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod16.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod17.yaml                                       │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod18.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod19.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod2.yaml                                        │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod20.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod21.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod24.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod25.yaml                                       │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod26.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod27.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod28.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod29.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod3.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod30.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod31.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod32.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod33.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod34.yaml                                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod35.yaml                                       │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod4.yaml                                        │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod5.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod6.yaml                                        │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod7.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod8.yaml                                        │ kubernetes │        17         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-pod9.yaml                                        │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args.yaml                          │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args1.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args10.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args11.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args13.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args14.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args15.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args16.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args17.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args18.yaml                        │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args2.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args3.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args4.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args5.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args6.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args7.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args8.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-rc-with-empty-args9.yaml                         │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-resource.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-target-service.yaml                              │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-tls-secret.yaml                                  │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-tls-secret1.yaml                                 │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-tls-secret2.yaml                                 │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-utf8.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid-wildcard-tls-secret.yaml                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalid9.yaml                                            │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod.yaml                                          │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod1.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod2.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod3.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod4.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod41.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod42.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod43.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod44.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod45.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod47.yaml                                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod5.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod6.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidPod8.yaml                                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidsvc.yaml                                          │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invalidsvc_1.yaml                                        │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory&booking-k8s.yaml                               │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory&booking-k8s_1.yaml                             │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-db-deployment.yaml                             │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-db-service.yaml                                │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-deploy.yaml                                    │ kubernetes │        21         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-deploy1.yaml                                   │ kubernetes │        21         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-secret.yaml                                    │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-db-deploy.yaml                         │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-db-deploy1.yaml                        │ kubernetes │        18         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-db-np.yaml                             │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-db-np1.yaml                            │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-db-svc.yaml                            │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-db-svc1.yaml                           │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-deploy.yaml                            │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-deploy1.yaml                           │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-deployment.yaml                        │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-deployment1.yaml                       │ kubernetes │        19         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-deployment2.yaml                       │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-deployment3.yaml                       │ kubernetes │        20         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-pv.yaml                                │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-pv1.yaml                               │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-pvc.yaml                               │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-pvc1.yaml                              │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-service.yaml                           │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-service1.yaml                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-service2.yaml                          │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-svc.yaml                               │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service-svc1.yaml                              │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service.yaml                                   │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service1.yaml                                  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-service2.yaml                                  │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-svc.yaml                                       │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory-svc_1.yaml                                     │ kubernetes │        50         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory110.yaml                                        │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory110_1.yaml                                      │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory21.yaml                                         │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory21_1.yaml                                       │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ inventory21_2.yaml                                       │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_deployment.yaml                                  │ kubernetes │        31         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_deployment_v2.yaml                               │ kubernetes │        30         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_networkpolicy.yaml                               │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_postgresql.yaml                                  │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_postgresql_1.yaml                                │ kubernetes │        13         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_postgresql_2.yaml                                │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ invoice_service.yaml                                     │ kubernetes │         1         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-config.yaml                                           │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding.yaml                           │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding1.yaml                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding2.yaml                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding3.yaml                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding4.yaml                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding5.yaml                          │ kubernetes │         0         │
├──────────────────────────────────────────────────────────┼────────────┼───────────────────┤
│ ip-masq-agent-psp-binding6.yaml                          │ kubernetes │         0         │
└──────────────────────────────────────────────────────────┴────────────┴───────────────────┘
Legend:
- '-': Not scanned
- '0': Clean (no security findings detected)


IntrusionDetection.yaml (kubernetes)
====================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'fastapi-server' of 'deployment' 'intrusion-detection-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'fastapi-server' of Deployment 'intrusion-detection-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 IntrusionDetection.yaml:8-22
────────────────────────────────────────
   8 ┌   replicas: 2
   9 │   selector:
  10 │     matchLabels:
  11 │       app: fastapi-server
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: fastapi-server
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "fastapi-server" of deployment "intrusion-detection-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment intrusion-detection-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 IntrusionDetection.yaml:4-6
────────────────────────────────────────
   4 ┌   name: intrusion-detection-deployment
   5 │   labels:
   6 └     app: fastapi-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container intrusion-detection-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 IntrusionDetection.yaml:18-22
────────────────────────────────────────
  18 ┌       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment intrusion-detection-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 IntrusionDetection.yaml:17-22
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: fastapi-server
  19 │         image: detect_server:v0.3
  20 │         imagePullPolicy: IfNotPresent
  21 │         ports:
  22 └         - containerPort: 8891
────────────────────────────────────────



IntrusionDetection_1.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 IntrusionDetection_1.yaml:6-13
────────────────────────────────────────
   6 ┌   type: LoadBalancer
   7 │   selector:
   8 │     app: fastapi-server
   9 │   ports:
  10 │   - protocol: TCP
  11 │     port: 8891
  12 │     targetPort: 8891
  13 └     nodePort: 30000
────────────────────────────────────────



install1_26.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_26.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install1_27.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_27.yaml:13-19
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: metrics
  15 │     port: 8082
  16 │     protocol: TCP
  17 │     targetPort: 8082
  18 │   selector:
  19 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install1_28.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_28.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install1_29.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_29.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install1_30.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_30.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install1_31.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_31.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install1_32.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_32.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install1_34.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_34.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install1_34.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install1_34.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install1_35.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install1_35.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.4.2-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install1_35.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.4.2-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install1_35.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.4.2-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install1_35.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.4.2-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install1_35.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.4.2-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install1_35.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.4.2-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_35.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install1_35.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install1_39.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_39.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install1_40.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_40.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install1_41.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_41.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install1_42.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_42.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install1_43.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_43.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install1_44.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install1_44.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install1_9.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install1_9.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install29_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install29_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install29_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install29_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install29_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install29_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install29_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install29_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install29_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install29_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install29_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install29_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install29_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install29_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install29_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install29_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install29_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install29_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install29_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install29_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install29_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install29_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install29_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install29_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install29_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install29_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install29_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 104, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 14, MEDIUM: 3, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'copyutil' of Deployment 'argocd-dex-server' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install29_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install29_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install29_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:latest
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install29_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install29_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 105, FAILURES: 10)
Failures: 10 (UNKNOWN: 0, LOW: 8, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_43.yaml:10-85
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install29_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install29_43.yaml:21-65
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install29_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install29_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.14-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install29_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.14-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install29_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.14-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install29_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.14-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install29_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.14-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install29_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.14-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install29_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install29_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install29_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install29_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install29_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install29_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install29_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install29_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install29_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install2_17.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'argocd-ssh-known-hosts-cm' in 'default' namespace stores sensitive contents in key(s) or value(s) '{"github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



install2_20.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_20.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 5556
  13 │     protocol: TCP
  14 │     targetPort: 5556
  15 │   - name: grpc
  16 │     port: 5557
  17 │     protocol: TCP
  18 └     targetPort: 5557
  ..   
────────────────────────────────────────



install2_21.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_21.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install2_22.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_22.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install2_23.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_23.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install2_24.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_24.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install2_25.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_25.yaml:10-21
────────────────────────────────────────
  10 ┌   type: LoadBalancer
  11 │   ports:
  12 │   - name: http
  13 │     port: 80
  14 │     protocol: TCP
  15 │     targetPort: 8080
  16 │   - name: https
  17 │     port: 443
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install2_26.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'argocd-application-controller' of 'deployment' 'argocd-application-controller' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-application-controller' of Deployment 'argocd-application-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_26.yaml:10-44
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-application-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-application-controller
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "argocd-application-controller" of deployment "argocd-application-controller" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-application-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install2_26.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: application-controller
   6 │     app.kubernetes.io/name: argocd-application-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-application-controller
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container argocd-application-controller in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-application-controller in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_26.yaml:20-44
────────────────────────────────────────
  20 ┌       containers:
  21 │       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 └         imagePullPolicy: Always
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-application-controller in deployment argocd-application-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install2_26.yaml:21-43
────────────────────────────────────────
  21 ┌       - command:
  22 │         - argocd-application-controller
  23 │         - --status-processors
  24 │         - '20'
  25 │         - --operation-processors
  26 │         - '10'
  27 │         image: argoproj/argocd:v1.2.4
  28 │         imagePullPolicy: Always
  29 └         livenessProbe:
  ..   
────────────────────────────────────────



install2_27.yaml (kubernetes)
=============================
Tests: 132 (SUCCESSES: 97, FAILURES: 35)
Failures: 35 (UNKNOWN: 0, LOW: 22, MEDIUM: 8, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'copyutil' of 'deployment' 'argocd-dex-server' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'dex' of 'deployment' 'argocd-dex-server' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_27.yaml:10-45
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "copyutil" of deployment "argocd-dex-server" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "dex" of deployment "argocd-dex-server" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install2_27.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container argocd-dex-server in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container argocd-dex-server in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_27.yaml:18-45
────────────────────────────────────────
  18 ┌       containers:
  19 │       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 └         - containerPort: 5556
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install2_27.yaml:32-41
────────────────────────────────────────
  32 ┌       - command:
  33 │         - cp
  34 │         - /usr/local/bin/argocd-util
  35 │         - /shared
  36 │         image: argoproj/argocd:v1.2.4
  37 │         imagePullPolicy: Always
  38 │         name: copyutil
  39 │         volumeMounts:
  40 │         - mountPath: /shared
  41 └           name: static-files
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install2_27.yaml:19-30
────────────────────────────────────────
  19 ┌       - command:
  20 │         - /shared/argocd-util
  21 │         - rundex
  22 │         image: quay.io/dexidp/dex:v2.14.0
  23 │         imagePullPolicy: Always
  24 │         name: dex
  25 │         ports:
  26 │         - containerPort: 5556
  27 └         - containerPort: 5557
  ..   
────────────────────────────────────────



install2_28.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'redis' of Deployment 'argocd-redis' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'redis' of 'deployment' 'argocd-redis' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_28.yaml:10-28
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "redis" of deployment "argocd-redis" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install2_28.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container argocd-redis in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_28.yaml:19-28
────────────────────────────────────────
  19 ┌       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 │         name: redis
  27 │         ports:
  28 └         - containerPort: 6379
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-redis in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_28.yaml:18-28
────────────────────────────────────────
  18 ┌       containers:
  19 │       - args:
  20 │         - --save
  21 │         - ''
  22 │         - --appendonly
  23 │         - 'no'
  24 │         image: redis:5.0.3
  25 │         imagePullPolicy: Always
  26 └         name: redis
  ..   
────────────────────────────────────────



install2_29.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'argocd-repo-server' of 'deployment' 'argocd-repo-server' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-repo-server' of Deployment 'argocd-repo-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_29.yaml:10-52
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-repo-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-repo-server
  17 │     spec:
  18 └       automountServiceAccountToken: false
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "argocd-repo-server" of deployment "argocd-repo-server" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-repo-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install2_29.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: repo-server
   6 │     app.kubernetes.io/name: argocd-repo-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-repo-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container argocd-repo-server in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-repo-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_29.yaml:18-52
────────────────────────────────────────
  18 ┌       automountServiceAccountToken: false
  19 │       containers:
  20 │       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 └         imagePullPolicy: Always
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-repo-server in deployment argocd-repo-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install2_29.yaml:20-45
────────────────────────────────────────
  20 ┌       - command:
  21 │         - uid_entrypoint.sh
  22 │         - argocd-repo-server
  23 │         - --redis
  24 │         - argocd-redis:6379
  25 │         image: argoproj/argocd:v1.2.4
  26 │         imagePullPolicy: Always
  27 │         livenessProbe:
  28 └           initialDelaySeconds: 5
  ..   
────────────────────────────────────────



install2_30.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'argocd-server' of Deployment 'argocd-server' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'argocd-server' of 'deployment' 'argocd-server' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'argocd-server' of Deployment 'argocd-server' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'argocd-server' of Deployment 'argocd-server' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-server' of Deployment 'argocd-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install2_30.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-server
  17 │     spec:
  18 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "argocd-server" of deployment "argocd-server" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install2_30.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: server
   6 │     app.kubernetes.io/name: argocd-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container argocd-server in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install2_30.yaml:18-55
────────────────────────────────────────
  18 ┌       containers:
  19 │       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 └           httpGet:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-server in deployment argocd-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install2_30.yaml:19-45
────────────────────────────────────────
  19 ┌       - command:
  20 │         - argocd-server
  21 │         - --staticassets
  22 │         - /shared/app
  23 │         image: argoproj/argocd:v1.2.4
  24 │         imagePullPolicy: Always
  25 │         livenessProbe:
  26 │           httpGet:
  27 └             path: /healthz
  ..   
────────────────────────────────────────



install2_5.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install2_5.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install2_6.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install2_6.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install2_7.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install2_7.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install2_7.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install2_8.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install2_8.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install2_8.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install2_9.yaml (kubernetes)
============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install2_9.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────



install30_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install30_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install30_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install30_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install30_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install30_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install30_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install30_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install30_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install30_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install30_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install30_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install30_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install30_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install30_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install30_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install30_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install30_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install30_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install30_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install30_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install30_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install30_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install30_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install30_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install30_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install30_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install30_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install30_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install30_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install30_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install30_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install30_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install30_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install30_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install30_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install30_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install30_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install30_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install30_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install30_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install30_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install30_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install30_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install30_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install30_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install30_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install30_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install30_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install30_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install32_1.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install32_1.yaml:13-16
────────────────────────────────────────
  13 ┌   selector:
  14 │     matchLabels:
  15 │       app.kubernetes.io/name: reports-server
  16 └   maxUnavailable: 50%
────────────────────────────────────────



install32_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install32_10.yaml:16-26
────────────────────────────────────────
  16 ┌   type: ClusterIP
  17 │   clusterIP: None
  18 │   publishNotReadyAddresses: true
  19 │   ports:
  20 │   - name: tcp-postgresql
  21 │     port: 5432
  22 │     targetPort: tcp-postgresql
  23 │   selector:
  24 └     app.kubernetes.io/instance: reports-server
  ..   
────────────────────────────────────────



install32_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install32_11.yaml:14-24
────────────────────────────────────────
  14 ┌   type: ClusterIP
  15 │   sessionAffinity: None
  16 │   ports:
  17 │   - name: tcp-postgresql
  18 │     port: 5432
  19 │     targetPort: tcp-postgresql
  20 │     nodePort: null
  21 │   selector:
  22 └     app.kubernetes.io/instance: reports-server
  ..   
────────────────────────────────────────



install32_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install32_12.yaml:13-21
────────────────────────────────────────
  13 ┌   type: ClusterIP
  14 │   ports:
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 │     targetPort: https
  19 │   selector:
  20 │     app.kubernetes.io/name: reports-server
  21 └     app.kubernetes.io/instance: reports-server
────────────────────────────────────────



install32_13.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 7, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'reports-server' of Deployment 'reports-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'reports-server' of Deployment 'reports-server' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'reports-server' of Deployment 'reports-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'reports-server' of Deployment 'reports-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'reports-server' of Deployment 'reports-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'reports-server' of Deployment 'reports-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'reports-server' of Deployment 'reports-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install32_13.yaml:13-106
────────────────────────────────────────
  13 ┌   strategy:
  14 │     rollingUpdate:
  15 │       maxUnavailable: 0
  16 │   replicas: 1
  17 │   selector:
  18 │     matchLabels:
  19 │       app.kubernetes.io/name: reports-server
  20 │       app.kubernetes.io/instance: reports-server
  21 └   template:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container reports-server in deployment reports-server (namespace: reports-server) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install32_13.yaml:35-102
────────────────────────────────────────
  35 ┌       - name: reports-server
  36 │         args:
  37 │         - --dbsslmode=disable
  38 │         - --dbsslrootcert=
  39 │         - --dbsslkey=
  40 │         - --dbsslcert=
  41 │         - --servicename=reports-server
  42 │         - --servicens=reports-server
  43 └         - --storereports=true
  ..   
────────────────────────────────────────



install32_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 108, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 5, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'postgresql' of StatefulSet 'reports-server-postgresql' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install32_14.yaml:58-147
────────────────────────────────────────
  58 ┌       - name: postgresql
  59 │         image: docker.io/bitnami/postgresql:16.1.0-debian-11-r22
  60 │         imagePullPolicy: IfNotPresent
  61 │         securityContext:
  62 │           allowPrivilegeEscalation: false
  63 │           capabilities:
  64 │             drop:
  65 │             - ALL
  66 └           privileged: false
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'postgresql' of StatefulSet 'reports-server-postgresql' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install32_14.yaml:58-147
────────────────────────────────────────
  58 ┌       - name: postgresql
  59 │         image: docker.io/bitnami/postgresql:16.1.0-debian-11-r22
  60 │         imagePullPolicy: IfNotPresent
  61 │         securityContext:
  62 │           allowPrivilegeEscalation: false
  63 │           capabilities:
  64 │             drop:
  65 │             - ALL
  66 └           privileged: false
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'postgresql' of StatefulSet 'reports-server-postgresql' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install32_14.yaml:58-147
────────────────────────────────────────
  58 ┌       - name: postgresql
  59 │         image: docker.io/bitnami/postgresql:16.1.0-debian-11-r22
  60 │         imagePullPolicy: IfNotPresent
  61 │         securityContext:
  62 │           allowPrivilegeEscalation: false
  63 │           capabilities:
  64 │             drop:
  65 │             - ALL
  66 └           privileged: false
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'postgresql' of StatefulSet 'reports-server-postgresql' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install32_14.yaml:58-147
────────────────────────────────────────
  58 ┌       - name: postgresql
  59 │         image: docker.io/bitnami/postgresql:16.1.0-debian-11-r22
  60 │         imagePullPolicy: IfNotPresent
  61 │         securityContext:
  62 │           allowPrivilegeEscalation: false
  63 │           capabilities:
  64 │             drop:
  65 │             - ALL
  66 └           privileged: false
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'postgresql' of StatefulSet 'reports-server-postgresql' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install32_14.yaml:58-147
────────────────────────────────────────
  58 ┌       - name: postgresql
  59 │         image: docker.io/bitnami/postgresql:16.1.0-debian-11-r22
  60 │         imagePullPolicy: IfNotPresent
  61 │         securityContext:
  62 │           allowPrivilegeEscalation: false
  63 │           capabilities:
  64 │             drop:
  65 │             - ALL
  66 └           privileged: false
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install32_14.yaml:14-162
────────────────────────────────────────
  14 ┌   replicas: 1
  15 │   serviceName: reports-server-postgresql-hl
  16 │   updateStrategy:
  17 │     rollingUpdate: {}
  18 │     type: RollingUpdate
  19 │   selector:
  20 │     matchLabels:
  21 │       app.kubernetes.io/instance: reports-server
  22 └       app.kubernetes.io/name: postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container postgresql in statefulset reports-server-postgresql (namespace: reports-server) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install32_14.yaml:58-147
────────────────────────────────────────
  58 ┌       - name: postgresql
  59 │         image: docker.io/bitnami/postgresql:16.1.0-debian-11-r22
  60 │         imagePullPolicy: IfNotPresent
  61 │         securityContext:
  62 │           allowPrivilegeEscalation: false
  63 │           capabilities:
  64 │             drop:
  65 │             - ALL
  66 └           privileged: false
  ..   
────────────────────────────────────────



install33_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install33_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install33_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install33_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install33_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install33_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install33_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install33_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install33_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install33_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install33_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install33_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install33_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install33_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install33_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install33_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install33_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install33_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install33_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install33_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install33_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install33_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install33_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install33_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install33_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install33_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install33_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install33_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install33_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install33_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install33_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install33_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install33_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install33_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install33_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install33_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install33_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install33_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install33_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install33_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install33_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install33_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install33_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install33_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install33_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install33_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install33_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install33_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install33_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install33_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install34_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install34_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install34_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install34_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install34_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install34_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install34_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install34_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install34_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install34_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install34_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install34_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install34_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install34_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install34_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install34_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install34_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install34_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install34_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install34_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install34_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install34_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install34_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install34_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install34_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install34_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install34_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install34_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install34_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install34_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install34_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install34_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install34_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install34_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install34_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install34_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install34_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install34_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install34_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install34_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install34_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install34_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install34_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install34_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install34_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install34_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install34_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install34_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install34_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install34_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install36_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install36_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install36_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install36_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install36_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install36_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install36_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install36_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install36_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install36_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install36_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install36_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install36_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install36_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install36_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install36_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install36_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install36_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install36_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install36_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install36_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install36_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install36_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install36_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install36_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install36_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install36_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install36_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install36_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install36_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install36_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install36_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install36_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install36_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install36_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install36_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install36_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install36_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install36_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install36_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install36_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install36_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install36_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install36_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install36_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install36_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install36_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install36_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install36_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install36_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install37_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install37_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install37_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install37_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install37_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install37_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install37_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install37_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install37_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install37_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install37_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install37_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install37_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install37_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install37_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install37_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install37_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install37_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install37_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install37_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install37_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install37_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install37_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install37_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install37_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install37_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install37_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install37_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install37_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install37_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install37_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install37_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install37_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install37_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install37_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install37_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install37_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install37_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install37_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install37_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install37_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install37_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install37_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install37_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install37_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install37_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install37_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install37_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install37_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install37_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install39_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install39_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install39_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install39_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install39_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install39_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install39_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install39_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install39_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install39_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install39_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install39_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install39_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install39_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install39_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install39_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install39_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install39_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install39_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install39_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install39_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install39_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install39_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install39_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install39_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install39_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install39_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install39_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install39_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install39_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.3
  68 │         imagePullPolicy: IfNotPresent
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install39_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install39_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install39_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install39_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install39_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install39_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install39_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install39_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install39_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install39_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install39_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: IfNotPresent
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install39_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install39_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install39_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install39_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install39_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install39_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install39_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install39_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install39_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install3_11.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argo-role' shouldn't have access to manage secrets in namespace 'argo'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install3_11.yaml:15-20
────────────────────────────────────────
  15 ┌ - apiGroups:
  16 │   - ''
  17 │   resources:
  18 │   - secrets
  19 │   verbs:
  20 └   - get
────────────────────────────────────────



install3_15.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 1, CRITICAL: 0)

AVD-KSV-0048 (MEDIUM): ClusterRole 'argo-cluster-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install3_15.yaml:6-18
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - pods/exec
  11 │   verbs:
  12 │   - create
  13 │   - get
  14 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'argo-cluster-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 install3_15.yaml:6-18
────────────────────────────────────────
   6 ┌ - apiGroups:
   7 │   - ''
   8 │   resources:
   9 │   - pods
  10 │   - pods/exec
  11 │   verbs:
  12 │   - create
  13 │   - get
  14 └   - list
  ..   
────────────────────────────────────────



install3_16.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 1, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'argo-server-cluster-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 install3_16.yaml:14-20
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - secrets
  18 │   verbs:
  19 │   - get
  20 └   - create
────────────────────────────────────────


AVD-KSV-0042 (MEDIUM): ClusterRole 'argo-server-cluster-role' should not have access to resource 'pods/log' for verbs ["delete", "deletecollection", "*"]
════════════════════════════════════════
Used to cover attacker’s tracks, but most clusters ship logs quickly off-cluster.

See https://avd.aquasec.com/misconfig/ksv042
────────────────────────────────────────
 install3_16.yaml:21-31
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - pods
  25 │   - pods/exec
  26 │   - pods/log
  27 │   verbs:
  28 │   - get
  29 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argo-server-cluster-role' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install3_16.yaml:21-31
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - pods
  25 │   - pods/exec
  26 │   - pods/log
  27 │   verbs:
  28 │   - get
  29 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0053 (HIGH): ClusterRole 'argo-server-cluster-role' should not have access to resource '["pods/exec"]' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
The ability to exec into a container with privileged access to the host or with an attached SA with higher RBAC permissions is a common escalation path to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv053
────────────────────────────────────────
 install3_16.yaml:21-31
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - pods
  25 │   - pods/exec
  26 │   - pods/log
  27 │   verbs:
  28 │   - get
  29 └   - list
  ..   
────────────────────────────────────────



install3_21.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install3_21.yaml:7-12
────────────────────────────────────────
   7 ┌   ports:
   8 │   - name: web
   9 │     port: 2746
  10 │     targetPort: 2746
  11 │   selector:
  12 └     app: argo-server
────────────────────────────────────────



install3_23.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 105, FAILURES: 10)
Failures: 10 (UNKNOWN: 0, LOW: 8, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argo-server' of Deployment 'argo-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argo-server' of Deployment 'argo-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argo-server' of Deployment 'argo-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argo-server' of Deployment 'argo-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argo-server' of Deployment 'argo-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argo-server' of Deployment 'argo-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install3_23.yaml:7-49
────────────────────────────────────────
   7 ┌   selector:
   8 │     matchLabels:
   9 │       app: argo-server
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: argo-server
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "argo-server" of deployment "argo-server" in "argo" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argo-server in deployment argo-server (namespace: argo) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install3_23.yaml:16-41
────────────────────────────────────────
  16 ┌       - args:
  17 │         - server
  18 │         - --auth-mode=server
  19 │         env: []
  20 │         image: quay.io/argoproj/argocli:v3.5.0
  21 │         name: argo-server
  22 │         ports:
  23 │         - containerPort: 2746
  24 └           name: web
  ..   
────────────────────────────────────────



install3_24.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 105, FAILURES: 10)
Failures: 10 (UNKNOWN: 0, LOW: 8, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'workflow-controller' of Deployment 'workflow-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'workflow-controller' of Deployment 'workflow-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'workflow-controller' of Deployment 'workflow-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'workflow-controller' of Deployment 'workflow-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'workflow-controller' of Deployment 'workflow-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'workflow-controller' of Deployment 'workflow-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install3_24.yaml:7-53
────────────────────────────────────────
   7 ┌   selector:
   8 │     matchLabels:
   9 │       app: workflow-controller
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: workflow-controller
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "workflow-controller" of deployment "workflow-controller" in "argo" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container workflow-controller in deployment workflow-controller (namespace: argo) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install3_24.yaml:16-47
────────────────────────────────────────
  16 ┌       - args: []
  17 │         command:
  18 │         - workflow-controller
  19 │         env:
  20 │         - name: LEADER_ELECTION_IDENTITY
  21 │           valueFrom:
  22 │             fieldRef:
  23 │               apiVersion: v1
  24 └               fieldPath: metadata.name
  ..   
────────────────────────────────────────



install51_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install51_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install51_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install51_11.yaml:48-56
────────────────────────────────────────
  48 ┌ - apiGroups:
  49 │   - ''
  50 │   resources:
  51 │   - secrets
  52 │   - configmaps
  53 │   verbs:
  54 │   - get
  55 │   - list
  56 └   - watch
────────────────────────────────────────



install51_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install51_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install51_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install51_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install51_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install51_14.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install51_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install51_14.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install51_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install51_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install51_15.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install51_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install51_16.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install51_16.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install51_33.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_33.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install51_34.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_34.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install51_35.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_35.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install51_36.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_36.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install51_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_37.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install51_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_38.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install51_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_39.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install51_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install51_42.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_42.yaml:10-100
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install51_42.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install51_42.yaml:18-100
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install51_42.yaml:62-83
────────────────────────────────────────
  62 ┌       - command:
  63 │         - /bin/cp
  64 │         - -n
  65 │         - /usr/local/bin/argocd
  66 │         - /shared/argocd-dex
  67 │         image: quay.io/argoproj/argocd:v2.9.0
  68 │         imagePullPolicy: Always
  69 │         name: copyutil
  70 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install51_42.yaml:28-60
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_DISABLE_TLS
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.disable.tls
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install51_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_43.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install51_43.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install51_43.yaml:21-59
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install51_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 107, FAILURES: 8)
Failures: 8 (UNKNOWN: 0, LOW: 8, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install51_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install51_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install51_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install51_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install51_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install51_44.yaml:34-49
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         image: redis:7.0.11-alpine
  40 │         imagePullPolicy: Always
  41 │         name: redis
  42 └         ports:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_44.yaml:10-55
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install51_44.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────



install51_48.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_48.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install51_49.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_49.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install51_50.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_50.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install51_51.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_51.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install51_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_52.yaml:6-31
────────────────────────────────────────
   6 ┌   egress:
   7 │   - ports:
   8 │     - port: 53
   9 │       protocol: UDP
  10 │     - port: 53
  11 │       protocol: TCP
  12 │   ingress:
  13 │   - from:
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install51_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_53.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install51_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install51_54.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install53_10.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-application-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_10.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install53_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-applicationset-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_11.yaml:50-58
────────────────────────────────────────
  50 ┌ - apiGroups:
  51 │   - ''
  52 │   resources:
  53 │   - secrets
  54 │   - configmaps
  55 │   verbs:
  56 │   - get
  57 │   - list
  58 └   - watch
────────────────────────────────────────



install53_12.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-dex-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_12.yaml:10-18
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - get
  17 │   - list
  18 └   - watch
────────────────────────────────────────



install53_13.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_13.yaml:21-28
────────────────────────────────────────
  21 ┌ - apiGroups:
  22 │   - ''
  23 │   resources:
  24 │   - configmaps
  25 │   - secrets
  26 │   verbs:
  27 │   - list
  28 └   - watch
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-notifications-controller' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_13.yaml:37-44
────────────────────────────────────────
  37 ┌ - apiGroups:
  38 │   - ''
  39 │   resourceNames:
  40 │   - argocd-notifications-secret
  41 │   resources:
  42 │   - secrets
  43 │   verbs:
  44 └   - get
────────────────────────────────────────



install53_14.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 114, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0113 (MEDIUM): Role 'argocd-redis' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_14.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resourceNames:
  13 │   - argocd-redis
  14 │   resources:
  15 │   - secrets
  16 │   verbs:
  17 └   - get
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-redis' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_14.yaml:18-23
────────────────────────────────────────
  18 ┌ - apiGroups:
  19 │   - ''
  20 │   resources:
  21 │   - secrets
  22 │   verbs:
  23 └   - create
────────────────────────────────────────



install53_15.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 2, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'argocd-server' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install53_15.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────


AVD-KSV-0113 (MEDIUM): Role 'argocd-server' shouldn't have access to manage secrets in namespace 'default'
════════════════════════════════════════
Viewing secrets at the namespace scope can lead to escalation if another service account in that namespace has a higher privileged rolebinding or clusterrolebinding bound.

See https://avd.aquasec.com/misconfig/ksv113
────────────────────────────────────────
 install53_15.yaml:10-22
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - ''
  12 │   resources:
  13 │   - secrets
  14 │   - configmaps
  15 │   verbs:
  16 │   - create
  17 │   - get
  18 └   - list
  ..   
────────────────────────────────────────



install53_16.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 2)

AVD-KSV-0044 (CRITICAL): Role permits wildcard verb on wildcard resource
════════════════════════════════════════
Check whether role permits wildcard verb on wildcard resource

See https://avd.aquasec.com/misconfig/ksv044
────────────────────────────────────────
 install53_16.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-application-controller' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install53_16.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────



install53_17.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'argocd-applicationset-controller' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 install53_17.yaml:62-69
────────────────────────────────────────
  62 ┌ - apiGroups:
  63 │   - ''
  64 │   resources:
  65 │   - secrets
  66 │   verbs:
  67 │   - get
  68 │   - list
  69 └   - watch
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'argocd-applicationset-controller' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install53_17.yaml:50-61
────────────────────────────────────────
  50 ┌ - apiGroups:
  51 │   - ''
  52 │   resources:
  53 │   - configmaps
  54 │   verbs:
  55 │   - create
  56 │   - update
  57 │   - delete
  58 └   - get
  ..   
────────────────────────────────────────



install53_18.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 113, FAILURES: 2)
Failures: 2 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'argocd-server' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 install53_18.yaml:10-17
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - '*'
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 │   - delete
  16 │   - get
  17 └   - patch
────────────────────────────────────────


AVD-KSV-0048 (MEDIUM): ClusterRole 'argocd-server' should not have access to resources ["pods", "deployments", "jobs", "cronjobs", "statefulsets", "daemonsets", "replicasets", "replicationcontrollers"] for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Depending on the policies enforced by the admission controller, this permission ranges from the ability to steal compute (crypto) by running workloads or allowing for creating workloads that escape to the node as root and escalation to cluster-admin.

See https://avd.aquasec.com/misconfig/ksv048
────────────────────────────────────────
 install53_18.yaml:40-45
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - batch
  42 │   resources:
  43 │   - jobs
  44 │   verbs:
  45 └   - create
────────────────────────────────────────



install53_37.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_37.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: webhook
  12 │     port: 7000
  13 │     protocol: TCP
  14 │     targetPort: webhook
  15 │   - name: metrics
  16 │     port: 8080
  17 │     protocol: TCP
  18 └     targetPort: metrics
  ..   
────────────────────────────────────────



install53_38.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_38.yaml:10-25
────────────────────────────────────────
  10 ┌   ports:
  11 │   - appProtocol: TCP
  12 │     name: http
  13 │     port: 5556
  14 │     protocol: TCP
  15 │     targetPort: 5556
  16 │   - name: grpc
  17 │     port: 5557
  18 └     protocol: TCP
  ..   
────────────────────────────────────────



install53_39.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_39.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8082
  13 │     protocol: TCP
  14 │     targetPort: 8082
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-application-controller
────────────────────────────────────────



install53_40.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_40.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 9001
  13 │     protocol: TCP
  14 │     targetPort: 9001
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-notifications-controller
────────────────────────────────────────



install53_41.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_41.yaml:10-15
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: tcp-redis
  12 │     port: 6379
  13 │     targetPort: 6379
  14 │   selector:
  15 └     app.kubernetes.io/name: argocd-redis
────────────────────────────────────────



install53_42.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_42.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: server
  12 │     port: 8081
  13 │     protocol: TCP
  14 │     targetPort: 8081
  15 │   - name: metrics
  16 │     port: 8084
  17 │     protocol: TCP
  18 └     targetPort: 8084
  ..   
────────────────────────────────────────



install53_43.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_43.yaml:10-20
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: http
  12 │     port: 80
  13 │     protocol: TCP
  14 │     targetPort: 8080
  15 │   - name: https
  16 │     port: 443
  17 │     protocol: TCP
  18 └     targetPort: 8080
  ..   
────────────────────────────────────────



install53_44.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_44.yaml:10-16
────────────────────────────────────────
  10 ┌   ports:
  11 │   - name: metrics
  12 │     port: 8083
  13 │     protocol: TCP
  14 │     targetPort: 8083
  15 │   selector:
  16 └     app.kubernetes.io/name: argocd-server
────────────────────────────────────────



install53_46.yaml (kubernetes)
==============================
Tests: 122 (SUCCESSES: 105, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 14, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'copyutil' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'dex' of Deployment 'argocd-dex-server' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_46.yaml:10-112
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-dex-server
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-dex-server
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-dex-server in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install53_46.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: dex-server
   6 │     app.kubernetes.io/name: argocd-dex-server
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-dex-server
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment argocd-dex-server in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install53_46.yaml:18-112
────────────────────────────────────────
  18 ┌       affinity:
  19 │         podAntiAffinity:
  20 │           preferredDuringSchedulingIgnoredDuringExecution:
  21 │           - podAffinityTerm:
  22 │               labelSelector:
  23 │                 matchLabels:
  24 │                   app.kubernetes.io/part-of: argocd
  25 │               topologyKey: kubernetes.io/hostname
  26 └             weight: 5
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container copyutil in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install53_46.yaml:74-95
────────────────────────────────────────
  74 ┌       - command:
  75 │         - /bin/cp
  76 │         - -n
  77 │         - /usr/local/bin/argocd
  78 │         - /shared/argocd-dex
  79 │         image: quay.io/argoproj/argocd:v2.13.3
  80 │         imagePullPolicy: Always
  81 │         name: copyutil
  82 └         securityContext:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container dex in deployment argocd-dex-server (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install53_46.yaml:28-72
────────────────────────────────────────
  28 ┌       - command:
  29 │         - /shared/argocd-dex
  30 │         - rundex
  31 │         env:
  32 │         - name: ARGOCD_DEX_SERVER_LOGFORMAT
  33 │           valueFrom:
  34 │             configMapKeyRef:
  35 │               key: dexserver.log.format
  36 └               name: argocd-cmd-params-cm
  ..   
────────────────────────────────────────



install53_47.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 8, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'argocd-notifications-controller' of Deployment 'argocd-notifications-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_47.yaml:10-91
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-notifications-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 │       labels:
  18 └         app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-notifications-controller in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install53_47.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: notifications-controller
   6 │     app.kubernetes.io/name: argocd-notifications-controller
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-notifications-controller
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container argocd-notifications-controller in deployment argocd-notifications-controller (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install53_47.yaml:21-71
────────────────────────────────────────
  21 ┌       - args:
  22 │         - /usr/local/bin/argocd-notifications
  23 │         env:
  24 │         - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
  25 │           valueFrom:
  26 │             configMapKeyRef:
  27 │               key: notificationscontroller.log.format
  28 │               name: argocd-cmd-params-cm
  29 └               optional: true
  ..   
────────────────────────────────────────



install53_48.yaml (kubernetes)
==============================
Tests: 121 (SUCCESSES: 106, FAILURES: 15)
Failures: 15 (UNKNOWN: 0, LOW: 14, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install53_48.yaml:34-56
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         - --requirepass $(REDIS_PASSWORD)
  40 │         env:
  41 │         - name: REDIS_PASSWORD
  42 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'secret-init' of Deployment 'argocd-redis' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install53_48.yaml:34-56
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         - --requirepass $(REDIS_PASSWORD)
  40 │         env:
  41 │         - name: REDIS_PASSWORD
  42 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'secret-init' of Deployment 'argocd-redis' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install53_48.yaml:34-56
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         - --requirepass $(REDIS_PASSWORD)
  40 │         env:
  41 │         - name: REDIS_PASSWORD
  42 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'secret-init' of Deployment 'argocd-redis' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install53_48.yaml:34-56
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         - --requirepass $(REDIS_PASSWORD)
  40 │         env:
  41 │         - name: REDIS_PASSWORD
  42 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'secret-init' of Deployment 'argocd-redis' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install53_48.yaml:34-56
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         - --requirepass $(REDIS_PASSWORD)
  40 │         env:
  41 │         - name: REDIS_PASSWORD
  42 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'secret-init' of Deployment 'argocd-redis' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'redis' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install53_48.yaml:34-56
────────────────────────────────────────
  34 ┌       - args:
  35 │         - --save
  36 │         - ''
  37 │         - --appendonly
  38 │         - 'no'
  39 │         - --requirepass $(REDIS_PASSWORD)
  40 │         env:
  41 │         - name: REDIS_PASSWORD
  42 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'secret-init' of Deployment 'argocd-redis' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_48.yaml:10-79
────────────────────────────────────────
  10 ┌   selector:
  11 │     matchLabels:
  12 │       app.kubernetes.io/name: argocd-redis
  13 │   template:
  14 │     metadata:
  15 │       labels:
  16 │         app.kubernetes.io/name: argocd-redis
  17 │     spec:
  18 └       affinity:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment argocd-redis in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install53_48.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/component: redis
   6 │     app.kubernetes.io/name: argocd-redis
   7 │     app.kubernetes.io/part-of: argocd
   8 └   name: argocd-redis
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container secret-init in deployment argocd-redis (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install53_48.yaml:58-73
────────────────────────────────────────
  58 ┌       - command:
  59 │         - argocd
  60 │         - admin
  61 │         - redis-initial-password
  62 │         image: quay.io/argoproj/argocd:v2.13.3
  63 │         imagePullPolicy: IfNotPresent
  64 │         name: secret-init
  65 │         securityContext:
  66 └           allowPrivilegeEscalation: false
  ..   
────────────────────────────────────────



install53_52.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_52.yaml:6-15
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 8082
  11 │   podSelector:
  12 │     matchLabels:
  13 │       app.kubernetes.io/name: argocd-application-controller
  14 │   policyTypes:
  15 └   - Ingress
────────────────────────────────────────



install53_53.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_53.yaml:6-18
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - namespaceSelector: {}
   9 │     ports:
  10 │     - port: 7000
  11 │       protocol: TCP
  12 │     - port: 8080
  13 │       protocol: TCP
  14 └   podSelector:
  ..   
────────────────────────────────────────



install53_54.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_54.yaml:6-25
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     ports:
  12 │     - port: 5556
  13 │       protocol: TCP
  14 └     - port: 5557
  ..   
────────────────────────────────────────



install53_55.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_55.yaml:10-20
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │     ports:
  14 │     - port: 9001
  15 │       protocol: TCP
  16 │   podSelector:
  17 │     matchLabels:
  18 └       app.kubernetes.io/name: argocd-notifications-controller
  ..   
────────────────────────────────────────



install53_56.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_56.yaml:6-24
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-repo-server
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install53_57.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_57.yaml:6-31
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - from:
   8 │     - podSelector:
   9 │         matchLabels:
  10 │           app.kubernetes.io/name: argocd-server
  11 │     - podSelector:
  12 │         matchLabels:
  13 │           app.kubernetes.io/name: argocd-application-controller
  14 └     - podSelector:
  ..   
────────────────────────────────────────



install53_58.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install53_58.yaml:6-12
────────────────────────────────────────
   6 ┌   ingress:
   7 │   - {}
   8 │   podSelector:
   9 │     matchLabels:
  10 │       app.kubernetes.io/name: argocd-server
  11 │   policyTypes:
  12 └   - Ingress
────────────────────────────────────────



install56_3.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 97, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 7, MEDIUM: 7, HIGH: 4, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nat64' of DaemonSet 'nat64' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nat64' of DaemonSet 'nat64' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nat64' of 'daemonset' 'nat64' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0009 (HIGH): DaemonSet 'nat64' should not set 'spec.template.spec.hostNetwork' to true
════════════════════════════════════════
Sharing the host’s network namespace permits processes in the pod to communicate with processes bound to the host’s loopback adapter.

See https://avd.aquasec.com/misconfig/ksv009
────────────────────────────────────────
 install56_3.yaml:11-55
────────────────────────────────────────
  11 ┌   selector:
  12 │     matchLabels:
  13 │       app: nat64
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 │         tier: node
  18 │         app: nat64
  19 └         k8s-app: nat64
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nat64' of DaemonSet 'nat64' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nat64' of DaemonSet 'nat64' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0017 (HIGH): Container 'nat64' of DaemonSet 'nat64' should set 'securityContext.privileged' to false
════════════════════════════════════════
Privileged containers share namespaces with the host system and do not offer any security. They should be used exclusively for system containers that require high privileges.

See https://avd.aquasec.com/misconfig/ksv017
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nat64' of DaemonSet 'nat64' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nat64' of DaemonSet 'nat64' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0022 (MEDIUM): Container 'nat64' of DaemonSet 'nat64' should not set 'securityContext.capabilities.add'
════════════════════════════════════════
According to pod security standard 'Capabilities', capabilities beyond the default set must not be added.

See https://avd.aquasec.com/misconfig/ksv022
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0023 (MEDIUM): DaemonSet 'nat64' should not set 'spec.template.volumes.hostPath'
════════════════════════════════════════
According to pod security standard 'HostPath Volumes', HostPath volumes must be forbidden.

See https://avd.aquasec.com/misconfig/ksv023
────────────────────────────────────────
 install56_3.yaml:11-55
────────────────────────────────────────
  11 ┌   selector:
  12 │     matchLabels:
  13 │       app: nat64
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 │         tier: node
  18 │         app: nat64
  19 └         k8s-app: nat64
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): DaemonSet 'nat64' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 install56_3.yaml:11-55
────────────────────────────────────────
  11 ┌   selector:
  12 │     matchLabels:
  13 │       app: nat64
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 │         tier: node
  18 │         app: nat64
  19 └         k8s-app: nat64
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install56_3.yaml:11-55
────────────────────────────────────────
  11 ┌   selector:
  12 │     matchLabels:
  13 │       app: nat64
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 │         tier: node
  18 │         app: nat64
  19 └         k8s-app: nat64
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nat64" of daemonset "nat64" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): daemonset nat64 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install56_3.yaml:21-55
────────────────────────────────────────
  21 ┌       hostNetwork: true
  22 │       tolerations:
  23 │       - operator: Exists
  24 │         effect: NoSchedule
  25 │       serviceAccountName: nat64
  26 │       containers:
  27 │       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 └         volumeMounts:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container nat64 in daemonset nat64 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install56_3.yaml:27-47
────────────────────────────────────────
  27 ┌       - name: nat64
  28 │         image: aojea/nat64:v0.1.0
  29 │         volumeMounts:
  30 │         - name: xtables-lock
  31 │           mountPath: /run/xtables.lock
  32 │           readOnly: false
  33 │         - name: lib-modules
  34 │           mountPath: /lib/modules
  35 └           readOnly: true
  ..   
────────────────────────────────────────



install57_3.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 101, FAILURES: 14)
Failures: 14 (UNKNOWN: 0, LOW: 8, MEDIUM: 4, HIGH: 2, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'external-dns' of Deployment 'external-dns' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'external-dns' of Deployment 'external-dns' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'external-dns' of 'deployment' 'external-dns' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'external-dns' of Deployment 'external-dns' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'external-dns' of Deployment 'external-dns' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'external-dns' of Deployment 'external-dns' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'external-dns' of Deployment 'external-dns' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install57_3.yaml:6-38
────────────────────────────────────────
   6 ┌   strategy:
   7 │     type: Recreate
   8 │   selector:
   9 │     matchLabels:
  10 │       app: external-dns
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 └         app: external-dns
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "external-dns" of deployment "external-dns" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment external-dns in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 install57_3.yaml:4
────────────────────────────────────────
   4 [   name: external-dns
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container external-dns in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container external-dns in deployment external-dns (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install57_3.yaml:18-36
────────────────────────────────────────
  18 ┌       - name: external-dns
  19 │         image: registry.k8s.io/external-dns/external-dns:v0.14.0
  20 │         envFrom:
  21 │         - secretRef:
  22 │             name: pihole-password
  23 │         args:
  24 │         - --source=service
  25 │         - --source=ingress
  26 └         - --registry=noop
  ..   
────────────────────────────────────────



install58_11.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install58_11.yaml:15-21
────────────────────────────────────────
  15 ┌   ports:
  16 │   - name: https
  17 │     port: 8443
  18 │     protocol: TCP
  19 │     targetPort: https
  20 │   selector:
  21 └     control-plane: controller-manager
────────────────────────────────────────



install58_12.yaml (kubernetes)
==============================
Tests: 121 (SUCCESSES: 108, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 7, MEDIUM: 4, HIGH: 2, CRITICAL: 0)

AVD-KSV-0014 (HIGH): Container 'kube-rbac-proxy' of Deployment 'oci-lb-controller-controller-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install58_12.yaml:27-49
────────────────────────────────────────
  27 ┌       - args:
  28 │         - --secure-listen-address=0.0.0.0:8443
  29 │         - --upstream=http://127.0.0.1:8080/
  30 │         - --logtostderr=true
  31 │         - --v=0
  32 │         image: registry.k8s.io/kubebuilder/kube-rbac-proxy:v0.15.0
  33 │         name: kube-rbac-proxy
  34 │         ports:
  35 └         - containerPort: 8443
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'manager' of Deployment 'oci-lb-controller-controller-manager' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 install58_12.yaml:50-81
────────────────────────────────────────
  50 ┌       - args:
  51 │         - --health-probe-bind-address=:8081
  52 │         - --metrics-bind-address=127.0.0.1:8080
  53 │         - --leader-elect
  54 │         command:
  55 │         - /manager
  56 │         image: norseto/oci-lb-registrar:v0.3.0-alpha.1
  57 │         livenessProbe:
  58 └           httpGet:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kube-rbac-proxy' of Deployment 'oci-lb-controller-controller-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install58_12.yaml:27-49
────────────────────────────────────────
  27 ┌       - args:
  28 │         - --secure-listen-address=0.0.0.0:8443
  29 │         - --upstream=http://127.0.0.1:8080/
  30 │         - --logtostderr=true
  31 │         - --v=0
  32 │         image: registry.k8s.io/kubebuilder/kube-rbac-proxy:v0.15.0
  33 │         name: kube-rbac-proxy
  34 │         ports:
  35 └         - containerPort: 8443
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'oci-lb-controller-controller-manager' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install58_12.yaml:50-81
────────────────────────────────────────
  50 ┌       - args:
  51 │         - --health-probe-bind-address=:8081
  52 │         - --metrics-bind-address=127.0.0.1:8080
  53 │         - --leader-elect
  54 │         command:
  55 │         - /manager
  56 │         image: norseto/oci-lb-registrar:v0.3.0-alpha.1
  57 │         livenessProbe:
  58 └           httpGet:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kube-rbac-proxy' of Deployment 'oci-lb-controller-controller-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install58_12.yaml:27-49
────────────────────────────────────────
  27 ┌       - args:
  28 │         - --secure-listen-address=0.0.0.0:8443
  29 │         - --upstream=http://127.0.0.1:8080/
  30 │         - --logtostderr=true
  31 │         - --v=0
  32 │         image: registry.k8s.io/kubebuilder/kube-rbac-proxy:v0.15.0
  33 │         name: kube-rbac-proxy
  34 │         ports:
  35 └         - containerPort: 8443
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'oci-lb-controller-controller-manager' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install58_12.yaml:50-81
────────────────────────────────────────
  50 ┌       - args:
  51 │         - --health-probe-bind-address=:8081
  52 │         - --metrics-bind-address=127.0.0.1:8080
  53 │         - --leader-elect
  54 │         command:
  55 │         - /manager
  56 │         image: norseto/oci-lb-registrar:v0.3.0-alpha.1
  57 │         livenessProbe:
  58 └           httpGet:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install58_12.yaml:27-49
────────────────────────────────────────
  27 ┌       - args:
  28 │         - --secure-listen-address=0.0.0.0:8443
  29 │         - --upstream=http://127.0.0.1:8080/
  30 │         - --logtostderr=true
  31 │         - --v=0
  32 │         image: registry.k8s.io/kubebuilder/kube-rbac-proxy:v0.15.0
  33 │         name: kube-rbac-proxy
  34 │         ports:
  35 └         - containerPort: 8443
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install58_12.yaml:50-81
────────────────────────────────────────
  50 ┌       - args:
  51 │         - --health-probe-bind-address=:8081
  52 │         - --metrics-bind-address=127.0.0.1:8080
  53 │         - --leader-elect
  54 │         command:
  55 │         - /manager
  56 │         image: norseto/oci-lb-registrar:v0.3.0-alpha.1
  57 │         livenessProbe:
  58 └           httpGet:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install58_12.yaml:15-85
────────────────────────────────────────
  15 ┌   replicas: 1
  16 │   selector:
  17 │     matchLabels:
  18 │       control-plane: controller-manager
  19 │   template:
  20 │     metadata:
  21 │       annotations:
  22 │         kubectl.kubernetes.io/default-container: manager
  23 └       labels:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kube-rbac-proxy" of deployment "oci-lb-controller-controller-manager" in "oci-lb-controller-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install58_12.yaml:27-49
────────────────────────────────────────
  27 ┌       - args:
  28 │         - --secure-listen-address=0.0.0.0:8443
  29 │         - --upstream=http://127.0.0.1:8080/
  30 │         - --logtostderr=true
  31 │         - --v=0
  32 │         image: registry.k8s.io/kubebuilder/kube-rbac-proxy:v0.15.0
  33 │         name: kube-rbac-proxy
  34 │         ports:
  35 └         - containerPort: 8443
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "manager" of deployment "oci-lb-controller-controller-manager" in "oci-lb-controller-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install58_12.yaml:50-81
────────────────────────────────────────
  50 ┌       - args:
  51 │         - --health-probe-bind-address=:8081
  52 │         - --metrics-bind-address=127.0.0.1:8080
  53 │         - --leader-elect
  54 │         command:
  55 │         - /manager
  56 │         image: norseto/oci-lb-registrar:v0.3.0-alpha.1
  57 │         livenessProbe:
  58 └           httpGet:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kube-rbac-proxy in deployment oci-lb-controller-controller-manager (namespace: oci-lb-controller-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install58_12.yaml:27-49
────────────────────────────────────────
  27 ┌       - args:
  28 │         - --secure-listen-address=0.0.0.0:8443
  29 │         - --upstream=http://127.0.0.1:8080/
  30 │         - --logtostderr=true
  31 │         - --v=0
  32 │         image: registry.k8s.io/kubebuilder/kube-rbac-proxy:v0.15.0
  33 │         name: kube-rbac-proxy
  34 │         ports:
  35 └         - containerPort: 8443
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment oci-lb-controller-controller-manager (namespace: oci-lb-controller-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install58_12.yaml:50-81
────────────────────────────────────────
  50 ┌       - args:
  51 │         - --health-probe-bind-address=:8081
  52 │         - --metrics-bind-address=127.0.0.1:8080
  53 │         - --leader-elect
  54 │         command:
  55 │         - /manager
  56 │         image: norseto/oci-lb-registrar:v0.3.0-alpha.1
  57 │         livenessProbe:
  58 └           httpGet:
  ..   
────────────────────────────────────────



install58_4.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0049 (MEDIUM): Role 'oci-lb-controller-leader-election-role' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 install58_4.yaml:14-25
────────────────────────────────────────
  14 ┌ - apiGroups:
  15 │   - ''
  16 │   resources:
  17 │   - configmaps
  18 │   verbs:
  19 │   - get
  20 │   - list
  21 │   - watch
  22 └   - create
  ..   
────────────────────────────────────────



install58_5.yaml (kubernetes)
=============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0041 (CRITICAL): ClusterRole 'oci-lb-controller-manager-role' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 install58_5.yaml:20-27
────────────────────────────────────────
  20 ┌ - apiGroups:
  21 │   - ''
  22 │   resources:
  23 │   - secrets
  24 │   verbs:
  25 │   - get
  26 │   - list
  27 └   - watch
────────────────────────────────────────



install_package_path.golden.yaml (kubernetes)
=============================================
Tests: 115 (SUCCESSES: 106, FAILURES: 9)
Failures: 9 (UNKNOWN: 0, LOW: 6, MEDIUM: 2, HIGH: 1, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'discovery' of Deployment 'istiod' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'discovery' of Deployment 'istiod' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'discovery' of Deployment 'istiod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'discovery' of Deployment 'istiod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 install_package_path.golden.yaml:14-158
────────────────────────────────────────
  14 ┌   selector:
  15 │     matchLabels:
  16 │       istio: pilot
  17 │   strategy:
  18 │     rollingUpdate:
  19 │       maxSurge: 100%
  20 │       maxUnavailable: 25%
  21 │   template:
  22 └     metadata:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "discovery" of deployment "istiod" in "istio-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment istiod in istio-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 install_package_path.golden.yaml:36-158
────────────────────────────────────────
  36 ┌       containers:
  37 │       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 └         - 30m
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container discovery in deployment istiod (namespace: istio-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 install_package_path.golden.yaml:37-129
────────────────────────────────────────
  37 ┌       - args:
  38 │         - discovery
  39 │         - --monitoringAddr=:15014
  40 │         - --log_output_level=default:info
  41 │         - --domain
  42 │         - cluster.local
  43 │         - --keepaliveMaxServerConnectionAge
  44 │         - 30m
  45 └         env:
  ..   
────────────────────────────────────────



installation2_1.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_1.yaml:11-19
────────────────────────────────────────
  11 ┌   egress:
  12 │   - {}
  13 │   ingress:
  14 │   - from:
  15 │     - podSelector: {}
  16 │   podSelector: {}
  17 │   policyTypes:
  18 │   - Ingress
  19 └   - Egress
────────────────────────────────────────



installation2_16.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_16.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: source-controller
  20 └   type: ClusterIP
────────────────────────────────────────



installation2_17.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 installation2_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 installation2_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_17.yaml:13-106
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: source-controller
  17 │   strategy:
  18 │     type: Recreate
  19 │   template:
  20 │     metadata:
  21 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 installation2_17.yaml:28-94
────────────────────────────────────────
  28 ┌       - args:
  29 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  30 │         - --watch-all-namespaces=true
  31 │         - --log-level=info
  32 │         - --log-encoding=json
  33 │         - --enable-leader-election
  34 │         - --storage-path=/data
  35 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  36 └         env:
  ..   
────────────────────────────────────────



installation2_2.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_2.yaml:11-19
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │     ports:
  15 │     - port: 8080
  16 │       protocol: TCP
  17 │   podSelector: {}
  18 │   policyTypes:
  19 └   - Ingress
────────────────────────────────────────



installation2_20.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 installation2_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'kustomize-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 installation2_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_20.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: kustomize-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment kustomize-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 installation2_20.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



installation2_23.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 installation2_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'helm-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 installation2_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_23.yaml:13-93
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: helm-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment helm-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 installation2_23.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



installation2_28.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_28.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



installation2_29.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_29.yaml:13-20
────────────────────────────────────────
  13 ┌   ports:
  14 │   - name: http
  15 │     port: 80
  16 │     protocol: TCP
  17 │     targetPort: http-webhook
  18 │   selector:
  19 │     app: notification-controller
  20 └   type: ClusterIP
────────────────────────────────────────



installation2_3.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_3.yaml:11-18
────────────────────────────────────────
  11 ┌   ingress:
  12 │   - from:
  13 │     - namespaceSelector: {}
  14 │   podSelector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   policyTypes:
  18 └   - Ingress
────────────────────────────────────────



installation2_30.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 installation2_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'notification-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 installation2_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_30.yaml:13-97
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: notification-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment notification-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 installation2_30.yaml:26-88
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --watch-all-namespaces=true
  28 │         - --log-level=info
  29 │         - --log-encoding=json
  30 │         - --enable-leader-election
  31 │         env:
  32 │         - name: RUNTIME_NAMESPACE
  33 │           valueFrom:
  34 └             fieldRef:
  ..   
────────────────────────────────────────



installation2_34.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 installation2_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-reflector-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 installation2_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_34.yaml:13-96
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-reflector-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-reflector-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 installation2_34.yaml:26-85
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



installation2_37.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 installation2_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'image-automation-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 installation2_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_37.yaml:13-92
────────────────────────────────────────
  13 ┌   replicas: 1
  14 │   selector:
  15 │     matchLabels:
  16 │       app: image-automation-controller
  17 │   template:
  18 │     metadata:
  19 │       annotations:
  20 │         prometheus.io/port: '8080'
  21 └         prometheus.io/scrape: 'true'
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment image-automation-controller (namespace: flux-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 installation2_37.yaml:26-83
────────────────────────────────────────
  26 ┌       - args:
  27 │         - --events-addr=http://notification-controller.flux-system.svc.cluster.local./
  28 │         - --watch-all-namespaces=true
  29 │         - --log-level=info
  30 │         - --log-encoding=json
  31 │         - --enable-leader-election
  32 │         env:
  33 │         - name: RUNTIME_NAMESPACE
  34 └           valueFrom:
  ..   
────────────────────────────────────────



installation2_4.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 installation2_4.yaml:12
────────────────────────────────────────
  12 [     pods: '1000'
────────────────────────────────────────



installation2_5.yaml (kubernetes)
=================================
Tests: 119 (SUCCESSES: 112, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 6)

AVD-KSV-0041 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't have access to manage resource 'secrets'
════════════════════════════════════════
Viewing secrets at the cluster-scope is akin to cluster-admin in most clusters as there are typically at least one service accounts (their token stored in a secret) bound to cluster-admin directly or a role/clusterrole that gives similar permissions.

See https://avd.aquasec.com/misconfig/ksv041
────────────────────────────────────────
 installation2_5.yaml:40-50
────────────────────────────────────────
  40 ┌ - apiGroups:
  41 │   - ''
  42 │   resources:
  43 │   - namespaces
  44 │   - secrets
  45 │   - configmaps
  46 │   - serviceaccounts
  47 │   verbs:
  48 └   - get
  ..   
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_5.yaml:10-15
────────────────────────────────────────
  10 ┌ - apiGroups:
  11 │   - source.toolkit.fluxcd.io
  12 │   resources:
  13 │   - '*'
  14 │   verbs:
  15 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_5.yaml:16-21
────────────────────────────────────────
  16 ┌ - apiGroups:
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 │   verbs:
  21 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_5.yaml:22-27
────────────────────────────────────────
  22 ┌ - apiGroups:
  23 │   - helm.toolkit.fluxcd.io
  24 │   resources:
  25 │   - '*'
  26 │   verbs:
  27 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_5.yaml:28-33
────────────────────────────────────────
  28 ┌ - apiGroups:
  29 │   - notification.toolkit.fluxcd.io
  30 │   resources:
  31 │   - '*'
  32 │   verbs:
  33 └   - '*'
────────────────────────────────────────


AVD-KSV-0046 (CRITICAL): ClusterRole 'crd-controller-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_5.yaml:34-39
────────────────────────────────────────
  34 ┌ - apiGroups:
  35 │   - image.toolkit.fluxcd.io
  36 │   resources:
  37 │   - '*'
  38 │   verbs:
  39 └   - '*'
────────────────────────────────────────


AVD-KSV-0049 (MEDIUM): ClusterRole 'crd-controller-flux-system' should not have access to resource 'configmaps' for verbs ["create", "update", "patch", "delete", "deletecollection", "impersonate", "*"]
════════════════════════════════════════
Some workloads leverage configmaps to store sensitive data or configuration parameters that affect runtime behavior that can be modified by an attacker or combined with another issue to potentially lead to compromise.

See https://avd.aquasec.com/misconfig/ksv049
────────────────────────────────────────
 installation2_5.yaml:58-69
────────────────────────────────────────
  58 ┌ - apiGroups:
  59 │   - ''
  60 │   resources:
  61 │   - configmaps
  62 │   verbs:
  63 │   - get
  64 │   - list
  65 │   - watch
  66 └   - create
  ..   
────────────────────────────────────────



installation2_6.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-edit-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_6.yaml:12-25
────────────────────────────────────────
  12 ┌ - apiGroups:
  13 │   - notification.toolkit.fluxcd.io
  14 │   - source.toolkit.fluxcd.io
  15 │   - helm.toolkit.fluxcd.io
  16 │   - image.toolkit.fluxcd.io
  17 │   - kustomize.toolkit.fluxcd.io
  18 │   resources:
  19 │   - '*'
  20 └   verbs:
  ..   
────────────────────────────────────────



installation2_7.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1)

AVD-KSV-0046 (CRITICAL): ClusterRole 'flux-view-flux-system' shouldn't manage all resources
════════════════════════════════════════
Full control of the cluster resources, and therefore also root on all nodes where workloads can run and has access to all pods, secrets, and data.

See https://avd.aquasec.com/misconfig/ksv046
────────────────────────────────────────
 installation2_7.yaml:13-24
────────────────────────────────────────
  13 ┌ - apiGroups:
  14 │   - notification.toolkit.fluxcd.io
  15 │   - source.toolkit.fluxcd.io
  16 │   - helm.toolkit.fluxcd.io
  17 │   - image.toolkit.fluxcd.io
  18 │   - kustomize.toolkit.fluxcd.io
  19 │   resources:
  20 │   - '*'
  21 └   verbs:
  ..   
────────────────────────────────────────



installation2_8.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0111 (MEDIUM): ClusterRoleBinding 'cluster-reconciler-flux-system' should not bind to roles ["cluster-admin", "admin", "edit"]
════════════════════════════════════════
Either cluster-admin or those granted powerful permissions.

See https://avd.aquasec.com/misconfig/ksv111
────────────────────────────────────────
 installation2_8.yaml:4-8
────────────────────────────────────────
   4 ┌   labels:
   5 │     app.kubernetes.io/instance: flux-system
   6 │     app.kubernetes.io/part-of: flux
   7 │     app.kubernetes.io/version: v2.3.0
   8 └   name: cluster-reconciler-flux-system
────────────────────────────────────────



instructor-service-deployment.yaml (kubernetes)
===============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'instructor-service' of Deployment 'instructor-service' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'instructor-service' of 'deployment' 'instructor-service' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'instructor-service' of Deployment 'instructor-service' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'instructor-service' of Deployment 'instructor-service' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'instructor-service' of Deployment 'instructor-service' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'instructor-service' of Deployment 'instructor-service' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 instructor-service-deployment.yaml:6-19
────────────────────────────────────────
   6 ┌   replicas: 3
   7 │   selector:
   8 │     matchLabels:
   9 │       app: instructor-service
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: instructor-service
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "instructor-service" of deployment "instructor-service" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment instructor-service in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 instructor-service-deployment.yaml:4
────────────────────────────────────────
   4 [   name: instructor-service
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container instructor-service in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment instructor-service in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 instructor-service-deployment.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container instructor-service in deployment instructor-service (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 instructor-service-deployment.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: instructor-service
  17 │         image: sanjananilanka/instructor-service:latest
  18 │         ports:
  19 └         - containerPort: 8000
────────────────────────────────────────



instructor-service-service.yaml (kubernetes)
============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 instructor-service-service.yaml:6-11
────────────────────────────────────────
   6 ┌   selector:
   7 │     app: instructor-service
   8 │   ports:
   9 │     - protocol: TCP
  10 │       port: 83
  11 └       targetPort: 8000
────────────────────────────────────────



instrumentation-replace-backend2.yaml (kubernetes)
==================================================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 11, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'backend2' of Deployment 'backend2-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'backend2' of 'deployment' 'backend2-deployment' in 'tutorial-application' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'backend2' of Deployment 'backend2-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'backend2' of Deployment 'backend2-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'backend2' of Deployment 'backend2-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'backend2' of Deployment 'backend2-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:10-36
────────────────────────────────────────
  10 ┌   replicas: 1
  11 │   selector:
  12 │     matchLabels:
  13 │       app: backend2
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 │         app: backend2
  18 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "backend2" of deployment "backend2-deployment" in "tutorial-application" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container backend2-deployment in tutorial-application namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment backend2-deployment in tutorial-application namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:22-36
────────────────────────────────────────
  22 ┌       containers:
  23 │       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 └         - name: RATE_HIGH_DELAY
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container backend2 in deployment backend2-deployment (namespace: tutorial-application) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 instrumentation-replace-backend2.yaml:23-36
────────────────────────────────────────
  23 ┌       - name: backend2
  24 │         image: ghcr.io/pavolloffay/kubecon-eu-2024-opentelemetry-kubernetes-tracing-tutorial-backend4:latest
  25 │         ports:
  26 │         - containerPort: 5165
  27 │         env:
  28 │         - name: RATE_ERROR
  29 │           value: "20"
  30 │         - name: RATE_HIGH_DELAY
  31 └           value: "20"
  ..   
────────────────────────────────────────



instrumented-app-deploy.yaml (kubernetes)
=========================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'example-app' of Deployment 'example-app' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'example-app' of Deployment 'example-app' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'example-app' of 'deployment' 'example-app' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'example-app' of Deployment 'example-app' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'example-app' of Deployment 'example-app' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'example-app' of Deployment 'example-app' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'example-app' of Deployment 'example-app' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'example-app' of Deployment 'example-app' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'example-app' of Deployment 'example-app' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'example-app' of Deployment 'example-app' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'example-app' of Deployment 'example-app' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'example-app' of Deployment 'example-app' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 instrumented-app-deploy.yaml:6-20
────────────────────────────────────────
   6 ┌   replicas: 3
   7 │   selector:
   8 │     matchLabels:
   9 │       app: example-app
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: example-app
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "example-app" of deployment "example-app" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment example-app in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 instrumented-app-deploy.yaml:4
────────────────────────────────────────
   4 [   name: example-app
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container example-app in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment example-app in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 instrumented-app-deploy.yaml:15-20
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container example-app in deployment example-app (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 instrumented-app-deploy.yaml:16-20
────────────────────────────────────────
  16 ┌       - name: example-app
  17 │         image: fabxc/instrumented_app
  18 │         ports:
  19 │         - name: web
  20 └           containerPort: 8080
────────────────────────────────────────



instrumented-app-svc.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 instrumented-app-svc.yaml:8-12
────────────────────────────────────────
   8 ┌   selector:
   9 │     app: example-app
  10 │   ports:
  11 │   - name: web
  12 └     port: 8080
────────────────────────────────────────



integration-vault-kubegres.yaml (kubernetes)
============================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 11, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'vault-client' of 'job' 'generate-kubegres-credentials' in 'vault' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'vault-client' of Job 'generate-kubegres-credentials' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 integration-vault-kubegres.yaml:20-44
────────────────────────────────────────
  20 ┌   template:
  21 │     spec:
  22 │       containers:
  23 │         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "vault-client" of job "generate-kubegres-credentials" in "vault" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container generate-kubegres-credentials in vault namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────


AVD-KSV-0118 (HIGH): job generate-kubegres-credentials in vault namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 integration-vault-kubegres.yaml:22-41
────────────────────────────────────────
  22 ┌       containers:
  23 │         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 │             - 'echo "$VAULT_ROOT_TOKEN" \
  29 │                    vault login \
  30 └                        -ca-cert /opt/vault/tls/vault-0/ca.crt \
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container vault-client in job generate-kubegres-credentials (namespace: vault) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 integration-vault-kubegres.yaml:23-28
────────────────────────────────────────
  23 ┌         - name: vault-client
  24 │           image: "hashicorp/vault:1.14.0"
  25 │           command:
  26 │             - "sh"
  27 │             - "-c"
  28 └             - 'echo "$VAULT_ROOT_TOKEN" \
────────────────────────────────────────



intelgpu-job.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'intelgpu-demo-job-1' of 'job' 'intelgpu-demo-job' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'intelgpu-demo-job-1' of Job 'intelgpu-demo-job' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 intelgpu-job.yaml:9-23
────────────────────────────────────────
   9 ┌   template:
  10 │     metadata:
  11 │       labels:
  12 │         jobgroup: intelgpu-demo
  13 │     spec:
  14 │       restartPolicy: Never
  15 │       containers:
  16 │         -
  17 └           name: intelgpu-demo-job-1
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "intelgpu-demo-job-1" of job "intelgpu-demo-job" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0110 (LOW): job intelgpu-demo-job in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 intelgpu-job.yaml:5-7
────────────────────────────────────────
   5 ┌   name: intelgpu-demo-job
   6 │   labels:
   7 └     jobgroup: intelgpu-demo
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container intelgpu-demo-job in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0118 (HIGH): job intelgpu-demo-job in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 intelgpu-job.yaml:14-23
────────────────────────────────────────
  14 ┌       restartPolicy: Never
  15 │       containers:
  16 │         -
  17 │           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container intelgpu-demo-job-1 in job intelgpu-demo-job (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 intelgpu-job.yaml:17-23
────────────────────────────────────────
  17 ┌           name: intelgpu-demo-job-1
  18 │           image: lanyitin/intel-opencl-icd:latest
  19 │           imagePullPolicy: IfNotPresent
  20 │           command: [ "clinfo" ]
  21 │           resources:
  22 │             limits:
  23 └               gpu.intel.com/i915: 1
────────────────────────────────────────



inter-pod-affinity.yaml (kubernetes)
====================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx-affinity' of 'deployment' 'nginx-affinity' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx-affinity' of Deployment 'nginx-affinity' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx-affinity' of Deployment 'nginx-affinity' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inter-pod-affinity.yaml:6-30
────────────────────────────────────────
   6 ┌   replicas: 10
   7 │   selector:
   8 │     matchLabels:
   9 │       app: nginx-affinity
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: nginx-affinity
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx-affinity" of deployment "nginx-affinity" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment nginx-affinity in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inter-pod-affinity.yaml:4
────────────────────────────────────────
   4 [   name: nginx-affinity
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment nginx-affinity in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nginx-affinity in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inter-pod-affinity.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment nginx-affinity in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inter-pod-affinity.yaml:15-30
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: nginx-affinity
  17 │         image: nginx
  18 │         ports:
  19 │         - containerPort: 80
  20 │       affinity:
  21 │         podAffinity:
  22 │           requiredDuringSchedulingIgnoredDuringExecution:
  23 └           - labelSelector:
  ..   
────────────────────────────────────────



inter-pod-affinity_1.yaml (kubernetes)
======================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx-anti-affinity' of 'deployment' 'nginx-anti-affinity' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx-anti-affinity' of Deployment 'nginx-anti-affinity' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inter-pod-affinity_1.yaml:6-29
────────────────────────────────────────
   6 ┌   replicas: 5
   7 │   selector:
   8 │     matchLabels:
   9 │       app: nginx
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: nginx
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx-anti-affinity" of deployment "nginx-anti-affinity" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment nginx-anti-affinity in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inter-pod-affinity_1.yaml:4
────────────────────────────────────────
   4 [   name: nginx-anti-affinity
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment nginx-anti-affinity in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container nginx-anti-affinity in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inter-pod-affinity_1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment nginx-anti-affinity in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inter-pod-affinity_1.yaml:15-29
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: nginx-anti-affinity
  17 │         image: nginx
  18 │         ports:
  19 │         - containerPort: 80
  20 │       affinity:
  21 │         podAntiAffinity:
  22 │           requiredDuringSchedulingIgnoredDuringExecution:
  23 └           - labelSelector:
  ..   
────────────────────────────────────────



interceptors_1.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 108, FAILURES: 7)
Failures: 7 (UNKNOWN: 0, LOW: 5, MEDIUM: 0, HIGH: 2, CRITICAL: 0)

AVD-KSV-0011 (LOW): Container 'tekton-triggers-core-interceptors' of Deployment 'tekton-triggers-core-interceptors' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 interceptors_1.yaml:35-75
────────────────────────────────────────
  35 ┌       - name: tekton-triggers-core-interceptors
  36 │         image: gcr.io/tekton-releases/github.com/tektoncd/triggers/cmd/interceptors:v0.26.2@sha256:80508a5a9c014cda7ab34bed2c32cbabfcadab58f24dc098d469a1f4d1ee531e
  37 │         ports:
  38 │         - containerPort: 8443
  39 │         args:
  40 │         - -logtostderr
  41 │         - -stderrthreshold
  42 │         - INFO
  43 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'tekton-triggers-core-interceptors' of Deployment 'tekton-triggers-core-interceptors' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 interceptors_1.yaml:35-75
────────────────────────────────────────
  35 ┌       - name: tekton-triggers-core-interceptors
  36 │         image: gcr.io/tekton-releases/github.com/tektoncd/triggers/cmd/interceptors:v0.26.2@sha256:80508a5a9c014cda7ab34bed2c32cbabfcadab58f24dc098d469a1f4d1ee531e
  37 │         ports:
  38 │         - containerPort: 8443
  39 │         args:
  40 │         - -logtostderr
  41 │         - -stderrthreshold
  42 │         - INFO
  43 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'tekton-triggers-core-interceptors' of Deployment 'tekton-triggers-core-interceptors' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 interceptors_1.yaml:35-75
────────────────────────────────────────
  35 ┌       - name: tekton-triggers-core-interceptors
  36 │         image: gcr.io/tekton-releases/github.com/tektoncd/triggers/cmd/interceptors:v0.26.2@sha256:80508a5a9c014cda7ab34bed2c32cbabfcadab58f24dc098d469a1f4d1ee531e
  37 │         ports:
  38 │         - containerPort: 8443
  39 │         args:
  40 │         - -logtostderr
  41 │         - -stderrthreshold
  42 │         - INFO
  43 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'tekton-triggers-core-interceptors' of Deployment 'tekton-triggers-core-interceptors' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 interceptors_1.yaml:35-75
────────────────────────────────────────
  35 ┌       - name: tekton-triggers-core-interceptors
  36 │         image: gcr.io/tekton-releases/github.com/tektoncd/triggers/cmd/interceptors:v0.26.2@sha256:80508a5a9c014cda7ab34bed2c32cbabfcadab58f24dc098d469a1f4d1ee531e
  37 │         ports:
  38 │         - containerPort: 8443
  39 │         args:
  40 │         - -logtostderr
  41 │         - -stderrthreshold
  42 │         - INFO
  43 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'tekton-triggers-core-interceptors' of Deployment 'tekton-triggers-core-interceptors' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 interceptors_1.yaml:35-75
────────────────────────────────────────
  35 ┌       - name: tekton-triggers-core-interceptors
  36 │         image: gcr.io/tekton-releases/github.com/tektoncd/triggers/cmd/interceptors:v0.26.2@sha256:80508a5a9c014cda7ab34bed2c32cbabfcadab58f24dc098d469a1f4d1ee531e
  37 │         ports:
  38 │         - containerPort: 8443
  39 │         args:
  40 │         - -logtostderr
  41 │         - -stderrthreshold
  42 │         - INFO
  43 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 interceptors_1.yaml:14-75
────────────────────────────────────────
  14 ┌   replicas: 1
  15 │   selector:
  16 │     matchLabels:
  17 │       app.kubernetes.io/name: core-interceptors
  18 │       app.kubernetes.io/component: interceptors
  19 │       app.kubernetes.io/instance: default
  20 │       app.kubernetes.io/part-of: tekton-triggers
  21 │   template:
  22 └     metadata:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment tekton-triggers-core-interceptors in tekton-pipelines namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 interceptors_1.yaml:33-75
────────────────────────────────────────
  33 ┌       serviceAccountName: tekton-triggers-core-interceptors
  34 │       containers:
  35 │       - name: tekton-triggers-core-interceptors
  36 │         image: gcr.io/tekton-releases/github.com/tektoncd/triggers/cmd/interceptors:v0.26.2@sha256:80508a5a9c014cda7ab34bed2c32cbabfcadab58f24dc098d469a1f4d1ee531e
  37 │         ports:
  38 │         - containerPort: 8443
  39 │         args:
  40 │         - -logtostderr
  41 └         - -stderrthreshold
  ..   
────────────────────────────────────────



interceptors_2.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 interceptors_2.yaml:16-23
────────────────────────────────────────
  16 ┌   ports:
  17 │   - name: https
  18 │     port: 8443
  19 │   selector:
  20 │     app.kubernetes.io/name: core-interceptors
  21 │     app.kubernetes.io/component: interceptors
  22 │     app.kubernetes.io/instance: default
  23 └     app.kubernetes.io/part-of: tekton-triggers
────────────────────────────────────────



internal-deploy.yaml (kubernetes)
=================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'internal-service-container' of 'deployment' 'internal-service-deploy' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'internal-service-container' of Deployment 'internal-service-deploy' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal-deploy.yaml:9-62
────────────────────────────────────────
   9 ┌   selector:
  10 │     matchLabels:
  11 │       name: internal-service-po
  12 │       app: kubernetes-poc
  13 │   template:
  14 │     metadata:
  15 │       name: internal-service-po
  16 │       labels:
  17 └         name: internal-service-po
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "internal-service-container" of deployment "internal-service-deploy" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment internal-service-deploy in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 internal-deploy.yaml:4-7
────────────────────────────────────────
   4 ┌   name: internal-service-deploy
   5 │   labels:
   6 │     name: internal-service-deploy
   7 └     app: kubernetes-poc
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container internal-service-deploy in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 internal-deploy.yaml:21-62
────────────────────────────────────────
  21 ┌         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 │                 configMapKeyRef:
  29 └                   name: app-config
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment internal-service-deploy in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 internal-deploy.yaml:20-62
────────────────────────────────────────
  20 ┌       containers:
  21 │         - name: internal-service-container
  22 │           image: internal-service:1.0.0
  23 │           ports:
  24 │             - containerPort: 8081
  25 │           env:
  26 │             - name: MYSQL_HOST
  27 │               valueFrom:
  28 └                 configMapKeyRef:
  ..   
────────────────────────────────────────



internal-load-balanced-service.yaml (kubernetes)
================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal-load-balanced-service.yaml:8-12
────────────────────────────────────────
   8 ┌   type: LoadBalancer
   9 │   ports:
  10 │   - port: 80
  11 │   selector:
  12 └     app: aks-helloworld
────────────────────────────────────────



internal-netpol.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal-netpol.yaml:9-33
────────────────────────────────────────
   9 ┌   podSelector:
  10 │     matchLabels:
  11 │       name: internal-service-po
  12 │       app: kubernetes-poc
  13 │   policyTypes:
  14 │     - Ingress
  15 │     - Egress
  16 │   ingress:
  17 └     - from:
  ..   
────────────────────────────────────────



internal-network-policy.yaml (kubernetes)
=========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal-network-policy.yaml:6-23
────────────────────────────────────────
   6 ┌   podSelector:
   7 │     matchLabels:
   8 │       name: internal
   9 │   policyTypes:
  10 │     - Egress
  11 │   egress:
  12 │     - to:
  13 │         - podSelector:
  14 └             matchLabels:
  ..   
────────────────────────────────────────



internal-service.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal-service.yaml:11-17
────────────────────────────────────────
  11 ┌   selector:     # Define os Pods que este Service vai direcionar. Neste caso, ele seleciona todos os Pods com o rótulo app: internal-app.
  12 │     app: internal-app
  13 │ 
  14 │   ports:        # Especifica as portas utilizadas pelo Service.
  15 │     - protocol: TCP     # Indica o protocolo de comunicação (TCP neste caso).
  16 │       port: 8080        # Define a porta no Service.
  17 └       targetPort: 8080   # Mapeia a porta no Pod para a qual o tráfego será encaminhado.
────────────────────────────────────────



internal-svc.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal-svc.yaml:9-13
────────────────────────────────────────
   9 ┌   selector:
  10 │     name: internal-service-po
  11 │     app: kubernetes-poc
  12 │   ports:
  13 └     - port: 8081
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion.yaml (kubernetes)
===================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion1.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion1.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion10.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion10.yaml:32
────────────────────────────────────────
  32 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion11.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion11.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion12.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion12.yaml:36
────────────────────────────────────────
  36 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion13.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion13.yaml:33
────────────────────────────────────────
  33 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion14.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion14.yaml:33
────────────────────────────────────────
  33 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion15.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion15.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion16.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion16.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion17.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion17.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion18.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion18.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion19.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion19.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion2.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion2.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion20.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion20.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion21.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion21.yaml:36
────────────────────────────────────────
  36 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion22.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion22.yaml:33
────────────────────────────────────────
  33 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion23.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion23.yaml:33
────────────────────────────────────────
  33 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion24.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion24.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion25.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion25.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion26.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion26.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion27.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion27.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion28.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion28.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion29.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion29.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion3.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion3.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion33.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion33.yaml:32
────────────────────────────────────────
  32 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion34.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion34.yaml:32
────────────────────────────────────────
  32 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion35.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion35.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion36.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion36.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion37.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion37.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion38.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion38.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion39.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion39.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion4.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion4.yaml:32
────────────────────────────────────────
  32 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion40.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion40.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion41.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion41.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion42.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion42.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion43.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion43.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion44.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion44.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion45.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion45.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion46.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion46.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion47.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion47.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion48.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion48.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion49.yaml (kubernetes)
=====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion49.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion5.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion5.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion6.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion6.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion7.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion7.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion8.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion8.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal.apiserver.k8s.io.v1alpha1.StorageVersion9.yaml (kubernetes)
====================================================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal.apiserver.k8s.io.v1alpha1.StorageVersion9.yaml:35
────────────────────────────────────────
  35 [ spec: {}
────────────────────────────────────────



internal_network.yaml (kubernetes)
==================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal_network.yaml:6-10
────────────────────────────────────────
   6 ┌   ports:
   7 │   - port: 5432
   8 │     targetPort: 5432
   9 │   selector:
  10 └     app: postgres
────────────────────────────────────────



internal_service_serverToDB.yaml (kubernetes)
=============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal_service_serverToDB.yaml:6-11
────────────────────────────────────────
   6 ┌   selector:
   7 │     name: db
   8 │   ports:
   9 │     - protocol: TCP
  10 │       port: 27017 
  11 └       targetPort: 27017
────────────────────────────────────────



internal_service_serverToDB1.yaml (kubernetes)
==============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 internal_service_serverToDB1.yaml:6-11
────────────────────────────────────────
   6 ┌   selector:
   7 │     name: db
   8 │   ports:
   9 │     - protocol: TCP
  10 │       port: 27017 
  11 └       targetPort: 27017
────────────────────────────────────────



invalid-metadata_1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 111, FAILURES: 4)
Failures: 4 (UNKNOWN: 0, LOW: 3, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-0020 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-metadata_1.yaml:24-80
────────────────────────────────────────
  24 ┌       - args:
  25 │         - --events-addr=http://notification-controller.invalid-meadata.svc.cluster.local./
  26 │         - --watch-all-namespaces
  27 │         - --log-level=info
  28 │         - --log-encoding=json
  29 │         - --enable-leader-election
  30 │         - --storage-path=/data
  31 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  32 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'manager' of Deployment 'source-controller' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-metadata_1.yaml:24-80
────────────────────────────────────────
  24 ┌       - args:
  25 │         - --events-addr=http://notification-controller.invalid-meadata.svc.cluster.local./
  26 │         - --watch-all-namespaces
  27 │         - --log-level=info
  28 │         - --log-encoding=json
  29 │         - --enable-leader-election
  30 │         - --storage-path=/data
  31 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  32 └         env:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-metadata_1.yaml:9-90
────────────────────────────────────────
   9 ┌   replicas: 1
  10 │   selector:
  11 │     matchLabels:
  12 │       app: source-controller
  13 │   strategy:
  14 │     type: Recreate
  15 │   template:
  16 │     metadata:
  17 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container manager in deployment source-controller (namespace: invalid-meadata) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-metadata_1.yaml:24-80
────────────────────────────────────────
  24 ┌       - args:
  25 │         - --events-addr=http://notification-controller.invalid-meadata.svc.cluster.local./
  26 │         - --watch-all-namespaces
  27 │         - --log-level=info
  28 │         - --log-encoding=json
  29 │         - --enable-leader-election
  30 │         - --storage-path=/data
  31 │         - --storage-adv-addr=source-controller.$(RUNTIME_NAMESPACE).svc.cluster.local.
  32 └         env:
  ..   
────────────────────────────────────────



invalid-metadata_2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-metadata_2.yaml:6-14
────────────────────────────────────────
   6 ┌   egress:
   7 │   - {}
   8 │   ingress:
   9 │   - from:
  10 │     - podSelector: {}
  11 │   podSelector: {}
  12 │   policyTypes:
  13 │   - Ingress
  14 └   - Egress
────────────────────────────────────────



invalid-metadata_3.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-metadata_3.yaml:10-17
────────────────────────────────────────
  10 ┌   ingress:
  11 │   - from:
  12 │     - namespaceSelector: {}
  13 │   podSelector:
  14 │     matchLabels:
  15 │       app: notification-controller
  16 │   policyTypes:
  17 └   - Ingress
────────────────────────────────────────



invalid-pod.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod1.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod1.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod1.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod1.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod1.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod10.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod10.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod10.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod10.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod10.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod11.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod11.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod11.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod11.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod11.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod12.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod12.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod12.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod12.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod12.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod13.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod13.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod13.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod13.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod13.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod14.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod14.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod14.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod14.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod14.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod15.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod15.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod15.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod15.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod15.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod16.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod16.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod16.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod16.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod16.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod17.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod17.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod17.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod17.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod17.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod18.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod18.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod18.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod18.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod18.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod19.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod19.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod19.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod19.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod19.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod2.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod2.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod2.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod2.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod2.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod20.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod20.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod20.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod20.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod20.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod21.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod21.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod21.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod21.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod21.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod24.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod24.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod24.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod24.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod24.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod25.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod25.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod25.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod25.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod25.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod26.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod26.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod26.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod26.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod26.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod27.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod27.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod27.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod27.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod27.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod28.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod28.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod28.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod28.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod28.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod29.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod29.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod29.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod29.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod29.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod3.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod3.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod3.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod3.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod3.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod30.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod30.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod30.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod30.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod30.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod31.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod31.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod31.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod31.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod31.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod32.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod32.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod32.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod32.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod32.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod33.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod33.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod33.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod33.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod33.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod34.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod34.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod34.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod34.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod34.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod35.yaml (kubernetes)
===============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod35.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod35.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod35.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod35.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod4.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod4.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod4.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod4.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod4.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod5.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod5.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod5.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod5.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod5.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod6.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod6.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod6.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod6.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod6.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-pod7.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 10, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod7.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod7.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod7.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container kubernetes-serve-hostname in pod invalid-pod (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-pod7.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: registry.k8s.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod8.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 99, FAILURES: 17)
Failures: 17 (UNKNOWN: 0, LOW: 10, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'kubernetes-serve-hostname' of 'pod' 'invalid-pod' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'kubernetes-serve-hostname' of Pod 'invalid-pod' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod8.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "kubernetes-serve-hostname" of pod "invalid-pod" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-pod in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod8.yaml:4
────────────────────────────────────────
   4 [   name: invalid-pod
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-pod in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod8.yaml:7-12
────────────────────────────────────────
   7 ┌   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-pod in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod8.yaml:6-12
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name: kubernetes-serve-hostname
   8 │     image: k8s.gcr.io/serve_hostname
   9 │     resources:
  10 │       limits:
  11 │         cpu: "3"
  12 └         memory: 100Mi
────────────────────────────────────────



invalid-pod9.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'null' of Pod 'test' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'null' of 'pod' 'test' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'null' of Pod 'test' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'null' of Pod 'test' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'null' of Pod 'test' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'null' of Pod 'test' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'null' of Pod 'test' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'null' of Pod 'test' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-pod9.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "null" of pod "test" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod test in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid-pod9.yaml:4
────────────────────────────────────────
   4 [   name: test
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container test in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod9.yaml:7-8
────────────────────────────────────────
   7 ┌   - name:
   8 └     image: nginx
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod test in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-pod9.yaml:6-8
────────────────────────────────────────
   6 ┌   containers:
   7 │   - name:
   8 └     image: nginx
────────────────────────────────────────



invalid-rc-with-empty-args.yaml (kubernetes)
============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args1.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args1.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args10.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args10.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args11.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args11.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args13.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args13.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args14.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args14.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args15.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args15.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args16.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args16.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args17.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args17.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args18.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args18.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args2.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args2.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args3.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args3.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args4.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args4.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args5.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args5.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args6.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args6.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args7.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args7.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args8.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args8.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-rc-with-empty-args9.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 11, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'carbon-relay' of 'replicationcontroller' 'kube-dns-v10' in 'kube-system' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'carbon-relay' of ReplicationController 'kube-dns-v10' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0037 (MEDIUM): ReplicationController 'kube-dns-v10' should not be set with 'kube-system' namespace
════════════════════════════════════════
ensure that user resources are not placed in kube-system namespace

See https://avd.aquasec.com/misconfig/no-user-pods-in-system-namespace
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:7-19
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     k8s-app: kube-dns
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         k8s-app: kube-dns
  14 │     spec:
  15 └       containers:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "carbon-relay" of replicationcontroller "kube-dns-v10" in "kube-system" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container kube-dns-v10 in kube-system namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): replicationcontroller kube-dns-v10 in kube-system namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:15-19
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container carbon-relay in replicationcontroller kube-dns-v10 (namespace: kube-system) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invalid-rc-with-empty-args9.yaml:16-19
────────────────────────────────────────
  16 ┌       - name: carbon-relay
  17 │         image: banno/carbon-relay
  18 │         args:
  19 └         -
────────────────────────────────────────



invalid-target-service.yaml (kubernetes)
========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid-target-service.yaml:7-12
────────────────────────────────────────
   7 ┌   selector:
   8 │     app: context
   9 │   ports:
  10 │     - name: http-alt
  11 │       port: 8080
  12 └       targetPort: mysql
────────────────────────────────────────



invalid9.yaml (kubernetes)
==========================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Pod 'invalid-nginx' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Pod 'invalid-nginx' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'pod' 'invalid-nginx' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Pod 'invalid-nginx' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Pod 'invalid-nginx' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Pod 'invalid-nginx' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Pod 'invalid-nginx' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Pod 'invalid-nginx' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Pod 'invalid-nginx' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Pod 'invalid-nginx' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Pod 'invalid-nginx' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalid9.yaml:6-10
────────────────────────────────────────
   6 ┌   containers:
   7 │     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of pod "invalid-nginx" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-nginx in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalid9.yaml:4
────────────────────────────────────────
   4 [   name: invalid-nginx
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod invalid-nginx in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-nginx in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid9.yaml:7-10
────────────────────────────────────────
   7 ┌     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-nginx in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalid9.yaml:6-10
────────────────────────────────────────
   6 ┌   containers:
   7 │     - name: nginx
   8 │       image: nginx:1.14.2
   9 │       ports:
  10 └         - containerPort: 80
────────────────────────────────────────



invalidPod.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidPod1.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod1.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod1.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod1.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod1.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidPod2.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod2.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod2.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod2.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod2.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidPod3.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod3.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod3.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod3.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod3.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidPod4.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod4.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod4.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod4.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod4.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod41.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod41.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod41.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod41.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod41.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod42.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod42.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod42.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod42.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod42.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod43.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod43.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod43.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod43.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod43.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod44.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod44.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod44.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod44.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod44.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod45.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod45.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod45.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod45.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod45.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod47.yaml (kubernetes)
==============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod47.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod47.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod47.yaml:9-14
────────────────────────────────────────
   9 ┌   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod47.yaml:8-14
────────────────────────────────────────
   8 ┌   containers:
   9 │   - image: gcr.io/fake_project/fake_image:fake_tag
  10 │     name: master
  11 │     args:
  12 │     -
  13 │     command:
  14 └     -
────────────────────────────────────────



invalidPod5.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod5.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod5.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod5.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod5.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidPod6.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod6.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod6.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod6.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod6.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidPod8.yaml (kubernetes)
=============================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'master' of Pod 'name' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'master' of 'pod' 'name' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'master' of Pod 'name' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'master' of Pod 'name' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'master' of Pod 'name' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'master' of Pod 'name' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'master' of Pod 'name' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidPod8.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "master" of pod "name" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod name in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidPod8.yaml:4-6
────────────────────────────────────────
   4 ┌   labels:
   5 │     name: redis-master
   6 └   name: name
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container name in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod8.yaml:9-11
────────────────────────────────────────
   9 ┌   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod name in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidPod8.yaml:8-11
────────────────────────────────────────
   8 ┌   containers:
   9 │   - args: "this is a bad command"
  10 │     image: gcr.io/fake_project/fake_image:fake_tag
  11 └     name: master
────────────────────────────────────────



invalidsvc.yaml (kubernetes)
============================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'nginx' of Pod 'invalid-svc' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'nginx' of Pod 'invalid-svc' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'nginx' of 'pod' 'invalid-svc' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'nginx' of Pod 'invalid-svc' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'nginx' of Pod 'invalid-svc' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'nginx' of Pod 'invalid-svc' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'nginx' of Pod 'invalid-svc' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'nginx' of Pod 'invalid-svc' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'nginx' of Pod 'invalid-svc' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'nginx' of Pod 'invalid-svc' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'nginx' of Pod 'invalid-svc' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'nginx' of Pod 'invalid-svc' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidsvc.yaml:9-14
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "nginx" of pod "invalid-svc" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0110 (LOW): pod invalid-svc in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 invalidsvc.yaml:4-7
────────────────────────────────────────
   4 ┌   labels:
   5 │     run: invalid-svc
   6 │   name: invalid-svc
   7 └   namespace: default
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): pod invalid-svc in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invalid-svc in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidsvc.yaml:10-14
────────────────────────────────────────
  10 ┌   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────


AVD-KSV-0118 (HIGH): pod invalid-svc in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invalidsvc.yaml:9-14
────────────────────────────────────────
   9 ┌   containers:
  10 │   - name: nginx
  11 │     image: nonexistingimage:latest
  12 │     ports:
  13 │     - containerPort: 80
  14 └       protocol: TCP
────────────────────────────────────────



invalidsvc_1.yaml (kubernetes)
==============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invalidsvc_1.yaml:9-16
────────────────────────────────────────
   9 ┌   ports:
  10 │   - port: 80
  11 │     protocol: TCP
  12 │     targetPort: 80
  13 │   selector:
  14 │     run: invalid-svc
  15 │   sessionAffinity: None
  16 └   type: NodePort
────────────────────────────────────────



inventory&booking-k8s.yaml (kubernetes)
=======================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'micro-demo-inventory-booking-deployment' of 'deployment' 'micro-demo-inventory-booking-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'micro-demo-inventory-booking-deployment' of Deployment 'micro-demo-inventory-booking-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory&booking-k8s.yaml:6-43
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: micro-demo-inventory-booking-deployment
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: micro-demo-inventory-booking-deployment
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "micro-demo-inventory-booking-deployment" of deployment "micro-demo-inventory-booking-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment micro-demo-inventory-booking-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory&booking-k8s.yaml:4
────────────────────────────────────────
   4 [   name: micro-demo-inventory-booking-deployment
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container micro-demo-inventory-booking-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment micro-demo-inventory-booking-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory&booking-k8s.yaml:15-43
────────────────────────────────────────
  15 ┌       containers:
  16 │       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 └           valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container micro-demo-inventory-booking-deployment in deployment micro-demo-inventory-booking-deployment (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory&booking-k8s.yaml:16-43
────────────────────────────────────────
  16 ┌       - name: micro-demo-inventory-booking-deployment
  17 │         imagePullPolicy: IfNotPresent
  18 │         image: irfan76k/micro-demo-inventory-booking
  19 │         env:
  20 │         - name: NATS_URL
  21 │           value: http://nats-srv:4222
  22 │         - name: NATS_CLIENT_ID
  23 │           valueFrom:
  24 └             fieldRef:
  ..   
────────────────────────────────────────



inventory&booking-k8s_1.yaml (kubernetes)
=========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory&booking-k8s_1.yaml:6-11
────────────────────────────────────────
   6 ┌   selector:
   7 │     app: micro-demo-inventory-booking-deployment
   8 │   ports:
   9 │   - protocol: TCP
  10 │     port: 8000
  11 └     targetPort: 8000
────────────────────────────────────────



inventory-db-deployment.yaml (kubernetes)
=========================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-db' of Deployment 'inventory-db' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-db' of 'deployment' 'inventory-db' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-db' of Deployment 'inventory-db' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-db' of Deployment 'inventory-db' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-db' of Deployment 'inventory-db' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-db-deployment.yaml:8-28
────────────────────────────────────────
   8 ┌   replicas: 1
   9 │   selector:
  10 │     matchLabels:
  11 │       app: inventory-db
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: inventory-db
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-db" of deployment "inventory-db" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-db in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-db-deployment.yaml:6
────────────────────────────────────────
   6 [   name: inventory-db
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-db in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-db-deployment.yaml:18-24
────────────────────────────────────────
  18 ┌       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 └           mountPath: /var/lib/mysql
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-db in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-db-deployment.yaml:17-28
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: inventory-db
  19 │         image: mysql:5.7  # Use the official MySQL image
  20 │         ports:
  21 │         - containerPort: 3306
  22 │         volumeMounts:
  23 │         - name: mysql-storage
  24 │           mountPath: /var/lib/mysql
  25 └       volumes:
  ..   
────────────────────────────────────────



inventory-db-service.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-db-service.yaml:8-14
────────────────────────────────────────
   8 ┌   selector:
   9 │     app: inventory-db
  10 │   ports:
  11 │   - protocol: TCP
  12 │     port: 3306
  13 │     targetPort: 3306
  14 └   type: ClusterIP
────────────────────────────────────────



inventory-deploy.yaml (kubernetes)
==================================
Tests: 116 (SUCCESSES: 95, FAILURES: 21)
Failures: 21 (UNKNOWN: 0, LOW: 12, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory' of 'deployment' 'inventory-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'inventory' of Deployment 'inventory-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-deploy.yaml:8-21
────────────────────────────────────────
   8 ┌   replicas: 1
   9 │   selector:
  10 │     matchLabels:
  11 │       app: inventory
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: inventory
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory" of deployment "inventory-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-deploy.yaml:4-6
────────────────────────────────────────
   4 ┌   name: inventory-deployment
   5 │   labels:
   6 └     app: inventory
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment inventory-deployment in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-deploy.yaml:17-21
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory in deployment inventory-deployment (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-deploy.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────



inventory-deploy1.yaml (kubernetes)
===================================
Tests: 116 (SUCCESSES: 95, FAILURES: 21)
Failures: 21 (UNKNOWN: 0, LOW: 12, MEDIUM: 6, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory' of 'deployment' 'inventory-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'inventory' of Deployment 'inventory-deployment' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory' of Deployment 'inventory-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-deploy1.yaml:8-21
────────────────────────────────────────
   8 ┌   replicas: 1
   9 │   selector:
  10 │     matchLabels:
  11 │       app: inventory
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: inventory
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory" of deployment "inventory-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-deploy1.yaml:4-6
────────────────────────────────────────
   4 ┌   name: inventory-deployment
   5 │   labels:
   6 └     app: inventory
────────────────────────────────────────


AVD-KSV-0117 (MEDIUM): deployment inventory-deployment in default namespace should not set spec.template.spec.containers.ports.containerPort to less than 1024
════════════════════════════════════════
The ports which are lower than 1024 receive and transmit various sensitive and privileged data. Allowing containers to use them can bring serious implications.

See https://avd.aquasec.com/misconfig/ksv117
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-deploy1.yaml:17-21
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory in deployment inventory-deployment (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-deploy1.yaml:18-21
────────────────────────────────────────
  18 ┌       - name: inventory
  19 │         image: clarusway/clarusshop-inventory
  20 │         ports:
  21 └         - containerPort: 80
────────────────────────────────────────



inventory-service-db-deploy.yaml (kubernetes)
=============================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'postgres' of 'deployment' 'inventory-service-db-deploy' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-db-deploy.yaml:6-39
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: inventory-service-db
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: inventory-service-db
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "postgres" of deployment "inventory-service-db-deploy" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service-db-deploy in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-db-deploy.yaml:4
────────────────────────────────────────
   4 [   name: inventory-service-db-deploy
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service-db-deploy in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-db-deploy.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service-db-deploy in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-db-deploy.yaml:15-39
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 └             - name: POSTGRES_USER
  ..   
────────────────────────────────────────



inventory-service-db-deploy1.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 98, FAILURES: 18)
Failures: 18 (UNKNOWN: 0, LOW: 12, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'postgres' of 'deployment' 'inventory-service-db-deploy' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'postgres' of Deployment 'inventory-service-db-deploy' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:6-39
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: inventory-service-db
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: inventory-service-db
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "postgres" of deployment "inventory-service-db-deploy" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service-db-deploy in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:4
────────────────────────────────────────
   4 [   name: inventory-service-db-deploy
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service-db-deploy in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:16-35
────────────────────────────────────────
  16 ┌         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 │             - name: POSTGRES_USER
  24 └               valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service-db-deploy in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-db-deploy1.yaml:15-39
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: postgres
  17 │           image: postgres:16-alpine
  18 │           ports:
  19 │             - containerPort: 5432
  20 │           env:
  21 │             - name: POSTGRES_DB
  22 │               value: inventory
  23 └             - name: POSTGRES_USER
  ..   
────────────────────────────────────────



inventory-service-db-np.yaml (kubernetes)
=========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-db-np.yaml:6-18
────────────────────────────────────────
   6 ┌   podSelector:
   7 │     matchLabels:
   8 │       app: inventory-service-db
   9 │   policyTypes:
  10 │     - Ingress
  11 │   ingress:
  12 │     - from:
  13 │         - podSelector:
  14 └             matchLabels:
  ..   
────────────────────────────────────────



inventory-service-db-np1.yaml (kubernetes)
==========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-db-np1.yaml:6-18
────────────────────────────────────────
   6 ┌   podSelector:
   7 │     matchLabels:
   8 │       app: inventory-service-db
   9 │   policyTypes:
  10 │     - Ingress
  11 │   ingress:
  12 │     - from:
  13 │         - podSelector:
  14 └             matchLabels:
  ..   
────────────────────────────────────────



inventory-service-db-svc.yaml (kubernetes)
==========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-db-svc.yaml:6-12
────────────────────────────────────────
   6 ┌   type: ClusterIP
   7 │   ports:
   8 │     - targetPort: 5432
   9 │       port: 5432
  10 │       protocol: TCP
  11 │   selector:
  12 └     app: inventory-service-db
────────────────────────────────────────



inventory-service-db-svc1.yaml (kubernetes)
===========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-db-svc1.yaml:6-12
────────────────────────────────────────
   6 ┌   type: ClusterIP
   7 │   ports:
   8 │     - targetPort: 5432
   9 │       port: 5432
  10 │       protocol: TCP
  11 │   selector:
  12 └     app: inventory-service-db
────────────────────────────────────────



inventory-service-deploy.yaml (kubernetes)
==========================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-service-container' of 'deployment' 'inventory-service-deploy' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-deploy.yaml:6-57
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: inventory-service
  10 │   strategy:
  11 │     rollingUpdate:
  12 │       maxSurge: 25%
  13 │       maxUnavailable: 25%
  14 └   template:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-service-container" of deployment "inventory-service-deploy" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service-deploy in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-deploy.yaml:4
────────────────────────────────────────
   4 [   name: inventory-service-deploy
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service-deploy in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service-deploy in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deploy.yaml:19-57
────────────────────────────────────────
  19 ┌       containers:
  20 │         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 └               path: /actuator/health
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-service-container in deployment inventory-service-deploy (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-service-deploy.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────



inventory-service-deploy1.yaml (kubernetes)
===========================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-service-container' of 'deployment' 'inventory-service-deploy' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-service-container' of Deployment 'inventory-service-deploy' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-deploy1.yaml:6-57
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: inventory-service
  10 │   strategy:
  11 │     rollingUpdate:
  12 │       maxSurge: 25%
  13 │       maxUnavailable: 25%
  14 └   template:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-service-container" of deployment "inventory-service-deploy" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service-deploy in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-deploy1.yaml:4
────────────────────────────────────────
   4 [   name: inventory-service-deploy
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service-deploy in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service-deploy in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deploy1.yaml:19-57
────────────────────────────────────────
  19 ┌       containers:
  20 │         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 └               path: /actuator/health
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-service-container in deployment inventory-service-deploy (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-service-deploy1.yaml:20-57
────────────────────────────────────────
  20 ┌         - name: inventory-service-container
  21 │           image: shaikrasheed99/inventory-service
  22 │           imagePullPolicy: IfNotPresent
  23 │           ports:
  24 │             - containerPort: 8084
  25 │           readinessProbe:
  26 │             httpGet:
  27 │               path: /actuator/health
  28 └               port: 8084
  ..   
────────────────────────────────────────



inventory-service-deployment.yaml (kubernetes)
==============================================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-service' of 'deployment' 'inventory-service-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-deployment.yaml:6-27
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: inventory-service
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: inventory-service
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-service" of deployment "inventory-service-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-deployment.yaml:4
────────────────────────────────────────
   4 [   name: inventory-service-deployment
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment.yaml:15-27
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 └           - name: PRODUCT_SERVICE_BASE_URL
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-service in deployment inventory-service-deployment (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-service-deployment.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────



inventory-service-deployment1.yaml (kubernetes)
===============================================
Tests: 116 (SUCCESSES: 97, FAILURES: 19)
Failures: 19 (UNKNOWN: 0, LOW: 12, MEDIUM: 4, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-service' of 'deployment' 'inventory-service-deployment' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-service' of Deployment 'inventory-service-deployment' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-deployment1.yaml:6-27
────────────────────────────────────────
   6 ┌   replicas: 1
   7 │   selector:
   8 │     matchLabels:
   9 │       app: inventory-service
  10 │   template:
  11 │     metadata:
  12 │       labels:
  13 │         app: inventory-service
  14 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-service" of deployment "inventory-service-deployment" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service-deployment in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-deployment1.yaml:4
────────────────────────────────────────
   4 [   name: inventory-service-deployment
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service-deployment in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service-deployment in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment1.yaml:15-27
────────────────────────────────────────
  15 ┌       containers:
  16 │         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 └           - name: PRODUCT_SERVICE_BASE_URL
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-service in deployment inventory-service-deployment (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-service-deployment1.yaml:16-27
────────────────────────────────────────
  16 ┌         - name: inventory-service
  17 │           image: saswatcloud/p10-ecommerce-inventory-service:11
  18 │           ports:
  19 │             - containerPort: 8080
  20 │           env:
  21 │           - name: MONGO_URL
  22 │             value: mongodb://mongodb-service:27017/billing
  23 │           - name: PRODUCT_SERVICE_BASE_URL
  24 └             valueFrom:
  ..   
────────────────────────────────────────



inventory-service-deployment2.yaml (kubernetes)
===============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-service' of 'deployment' 'inventory-service' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-deployment2.yaml:8-26
────────────────────────────────────────
   8 ┌   replicas: 2
   9 │   selector:
  10 │     matchLabels:
  11 │       app: inventory-service
  12 │   template:
  13 │     metadata:
  14 │       labels:
  15 │         app: inventory-service
  16 └     spec:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-service" of deployment "inventory-service" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-deployment2.yaml:6
────────────────────────────────────────
   6 [   name: inventory-service
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment2.yaml:17-26
────────────────────────────────────────
  17 ┌       containers:
  18 │       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-service in deployment inventory-service (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-service-deployment2.yaml:18-26
────────────────────────────────────────
  18 ┌       - name: inventory-service
  19 │         image: ificiency/inventory-management:latest
  20 │         ports:
  21 │         - containerPort: 5000
  22 │         env:
  23 │           - name: FLASK_APP
  24 │             value: "app.py"
  25 │           - name: DATABASE_URL
  26 └             value: "mysql+pymysql://ifiyemi:braceup@inventory-db-service:3306/inventory_db"
────────────────────────────────────────



inventory-service-deployment3.yaml (kubernetes)
===============================================
Tests: 116 (SUCCESSES: 96, FAILURES: 20)
Failures: 20 (UNKNOWN: 0, LOW: 12, MEDIUM: 5, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-service' of 'deployment' 'inventory-service' in 'default' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'inventory-service' of Deployment 'inventory-service' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-service' of Deployment 'inventory-service' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-deployment3.yaml:11-32
────────────────────────────────────────
  11 ┌   replicas: 1
  12 │   selector:
  13 │     matchLabels:
  14 │       io.kompose.service: inventory-service
  15 │   template:
  16 │     metadata:
  17 │       annotations:
  18 │         kompose.cmd: C:\ProgramData\chocolatey\lib\kubernetes-kompose\tools\kompose.exe convert -f docker-compose.yml
  19 └         kompose.version: 1.32.0 (765fde254)
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-service" of deployment "inventory-service" in "default" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0110 (LOW): deployment inventory-service in default namespace should set metadata.namespace to a non-default namespace
════════════════════════════════════════
Checks whether a workload is running in the default namespace.

See https://avd.aquasec.com/misconfig/ksv110
────────────────────────────────────────
 inventory-service-deployment3.yaml:4-9
────────────────────────────────────────
   4 ┌   annotations:
   5 │     kompose.cmd: C:\ProgramData\chocolatey\lib\kubernetes-kompose\tools\kompose.exe convert -f docker-compose.yml
   6 │     kompose.version: 1.32.0 (765fde254)
   7 │   labels:
   8 │     io.kompose.service: inventory-service
   9 └   name: inventory-service
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-service in default namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-service in default namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-service-deployment3.yaml:24-32
────────────────────────────────────────
  24 ┌       containers:
  25 │         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 │           name: inventory-service
  32 └       restartPolicy: Always
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-service in deployment inventory-service (namespace: default) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-service-deployment3.yaml:25-31
────────────────────────────────────────
  25 ┌         - env:
  26 │             - name: SPRING_DATASOURCE_URL
  27 │               value: jdbc:mysql://mysql-inventory:3306/inventory_service
  28 │             - name: SPRING_PROFILES_ACTIVE
  29 │               value: docker
  30 │           image: beko2001/inventory-service:latest
  31 └           name: inventory-service
────────────────────────────────────────



inventory-service-pv.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-pv.yaml:6-12
────────────────────────────────────────
   6 ┌   accessModes:
   7 │     - ReadWriteOnce
   8 │   capacity:
   9 │     storage: 10Mi
  10 │   hostPath:
  11 │     path: /mnt/data/inventory-service-db
  12 └   storageClassName: standard
────────────────────────────────────────



inventory-service-pv1.yaml (kubernetes)
=======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-pv1.yaml:6-12
────────────────────────────────────────
   6 ┌   accessModes:
   7 │     - ReadWriteOnce
   8 │   capacity:
   9 │     storage: 10Mi
  10 │   hostPath:
  11 │     path: /mnt/data/inventory-service-db
  12 └   storageClassName: standard
────────────────────────────────────────



inventory-service-pvc.yaml (kubernetes)
=======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-pvc.yaml:6-11
────────────────────────────────────────
   6 ┌   accessModes:
   7 │     - ReadWriteOnce
   8 │   resources:
   9 │     requests:
  10 │       storage: 10Mi
  11 └   storageClassName: standard
────────────────────────────────────────



inventory-service-pvc1.yaml (kubernetes)
========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-pvc1.yaml:6-11
────────────────────────────────────────
   6 ┌   accessModes:
   7 │     - ReadWriteOnce
   8 │   resources:
   9 │     requests:
  10 │       storage: 10Mi
  11 └   storageClassName: standard
────────────────────────────────────────



inventory-service-service.yaml (kubernetes)
===========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-service.yaml:6-12
────────────────────────────────────────
   6 ┌   selector:
   7 │     app: inventory-service
   8 │   ports:
   9 │     - protocol: TCP
  10 │       port: 8080
  11 │       targetPort: 8080
  12 └   type: ClusterIP
────────────────────────────────────────



inventory-service-service1.yaml (kubernetes)
============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-service1.yaml:6-12
────────────────────────────────────────
   6 ┌   selector:
   7 │     app: inventory-service
   8 │   ports:
   9 │     - protocol: TCP
  10 │       port: 8080
  11 │       targetPort: 8080
  12 └   type: ClusterIP
────────────────────────────────────────



inventory-service-service2.yaml (kubernetes)
============================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-service2.yaml:8-14
────────────────────────────────────────
   8 ┌   selector:
   9 │     app: inventory-service
  10 │   ports:
  11 │   - protocol: TCP
  12 │     port: 80
  13 │     targetPort: 5000
  14 └   type: LoadBalancer
────────────────────────────────────────



inventory-service-svc.yaml (kubernetes)
=======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-svc.yaml:6-12
────────────────────────────────────────
   6 ┌   type: ClusterIP
   7 │   ports:
   8 │     - targetPort: 8084
   9 │       port: 8084
  10 │       protocol: TCP
  11 │   selector:
  12 └     app: inventory-service
────────────────────────────────────────



inventory-service-svc1.yaml (kubernetes)
========================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service-svc1.yaml:6-12
────────────────────────────────────────
   6 ┌   type: ClusterIP
   7 │   ports:
   8 │     - targetPort: 8084
   9 │       port: 8084
  10 │       protocol: TCP
  11 │   selector:
  12 └     app: inventory-service
────────────────────────────────────────



inventory-service.yaml (kubernetes)
===================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service.yaml:8-14
────────────────────────────────────────
   8 ┌   type: NodePort
   9 │   selector:
  10 │     app: inventory
  11 │   ports:
  12 │     - protocol: TCP
  13 │       port: 80
  14 └       targetPort: 80
────────────────────────────────────────



inventory-service1.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service1.yaml:8-14
────────────────────────────────────────
   8 ┌   type: NodePort
   9 │   selector:
  10 │     app: inventory
  11 │   ports:
  12 │     - protocol: TCP
  13 │       port: 80
  14 └       targetPort: 80
────────────────────────────────────────



inventory-service2.yaml (kubernetes)
====================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-service2.yaml:9-16
────────────────────────────────────────
   9 ┌   ports:
  10 │   - name: 8082-8082
  11 │     port: 8082
  12 │     protocol: TCP
  13 │     targetPort: 8082
  14 │   selector:
  15 │     app: inventory-service
  16 └   type: ClusterIP
────────────────────────────────────────



inventory-svc.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-svc.yaml:11-17
────────────────────────────────────────
  11 ┌   ports:
  12 │   - protocol: TCP
  13 │     port: 80
  14 │     targetPort: 8080
  15 │   selector:
  16 │     app: inventory-svc
  17 └   type: ClusterIP
────────────────────────────────────────



inventory-svc_1.yaml (kubernetes)
=================================
Tests: 147 (SUCCESSES: 97, FAILURES: 50)
Failures: 50 (UNKNOWN: 0, LOW: 31, MEDIUM: 12, HIGH: 7, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'inventory-svc-cont' of 'deployment' 'inventory-svc-pods' in 'service' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'wait-for-cassandra' of 'deployment' 'inventory-svc-pods' in 'service' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'wait-for-postgres' of 'deployment' 'inventory-svc-pods' in 'service' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'inventory-svc-cont' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'wait-for-cassandra' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'wait-for-postgres' of Deployment 'inventory-svc-pods' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 inventory-svc_1.yaml:7-73
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app: inventory-svc
  11 │   strategy:
  12 │     type: RollingUpdate
  13 │     rollingUpdate:
  14 │       maxUnavailable: 25%
  15 └       maxSurge: 1
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "inventory-svc-cont" of deployment "inventory-svc-pods" in "service" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "wait-for-cassandra" of deployment "inventory-svc-pods" in "service" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "wait-for-postgres" of deployment "inventory-svc-pods" in "service" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-svc-pods in service namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-svc_1.yaml:29-34
────────────────────────────────────────
  29 ┌       - name: wait-for-cassandra
  30 │         image: cassandra
  31 │         command:
  32 │         - /bin/bash
  33 │         - -c
  34 └         - until echo exit | cqlsh cassandra.data; do echo waiting for cassandra; sleep
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-svc-pods in service namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container inventory-svc-pods in service namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-svc_1.yaml:22-27
────────────────────────────────────────
  22 ┌       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 └         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment inventory-svc-pods in service namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 inventory-svc_1.yaml:21-73
────────────────────────────────────────
  21 ┌       initContainers:
  22 │       - name: wait-for-postgres
  23 │         image: postgres
  24 │         command:
  25 │         - /bin/bash
  26 │         - -c
  27 │         - until pg_isready -h postgres.data; do echo waiting for postgres; sleep 2;
  28 │           done;
  29 └       - name: wait-for-cassandra
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container inventory-svc-cont in deployment inventory-svc-pods (namespace: service) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 inventory-svc_1.yaml:37-63
────────────────────────────────────────
  37 ┌       - name: inventory-svc-cont
  38 │         image: IMAGE_REGISTRY_PATH/services:REVISION_ID
  39 │         args:
  40 │         - inventory
  41 │         imagePullPolicy: Always
  42 │         ports:
  43 │         - containerPort: 8080
  44 │         volumeMounts:
  45 └         - name: log-data
  ..   
────────────────────────────────────────



inventory110_1.yaml (kubernetes)
================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'test1' in 'test' namespace stores sensitive contents in key(s) or value(s) '{"key"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



inventory21_1.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'test1' in 'test' namespace stores sensitive contents in key(s) or value(s) '{"key"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



inventory21_2.yaml (kubernetes)
===============================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0)

AVD-KSV-01010 (MEDIUM): ConfigMap 'test2' in 'test' namespace stores sensitive contents in key(s) or value(s) '{"key"}'
════════════════════════════════════════
Storing sensitive content such as usernames and email addresses in configMaps is unsafe

See https://avd.aquasec.com/misconfig/avd-ksv-01010
────────────────────────────────────────



invoice_deployment.yaml (kubernetes)
====================================
Tests: 128 (SUCCESSES: 97, FAILURES: 31)
Failures: 31 (UNKNOWN: 0, LOW: 17, MEDIUM: 9, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'init-ds' of Deployment 'invoice' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'invoice-app' of Deployment 'invoice' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'init-ds' of 'deployment' 'invoice' in 'production' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'invoice-app' of 'deployment' 'invoice' in 'production' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'init-ds' of Deployment 'invoice' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'invoice-app' of Deployment 'invoice' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invoice_deployment.yaml:9-101
────────────────────────────────────────
   9 ┌   replicas: 2
  10 │   selector:
  11 │     matchLabels:
  12 │       app: invoice
  13 │       version: "v1"
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 └         app: invoice
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "init-ds" of deployment "invoice" in "production" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "invoice-app" of deployment "invoice" in "production" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invoice in production namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invoice in production namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_deployment.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment invoice in production namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_deployment.yaml:21-101
────────────────────────────────────────
  21 ┌       affinity:
  22 │         podAntiAffinity:
  23 │           preferredDuringSchedulingIgnoredDuringExecution:
  24 │             - podAffinityTerm:
  25 │                 labelSelector:
  26 │                   matchExpressions:
  27 │                     - key: app
  28 │                       operator: In
  29 └                       values:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container invoice-app in deployment invoice (namespace: production) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invoice_deployment.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────



invoice_deployment_v2.yaml (kubernetes)
=======================================
Tests: 127 (SUCCESSES: 97, FAILURES: 30)
Failures: 30 (UNKNOWN: 0, LOW: 17, MEDIUM: 8, HIGH: 5, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0001 (MEDIUM): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'init-ds' of Deployment 'invoice' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'invoice-app' of Deployment 'invoice' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'init-ds' of 'deployment' 'invoice' in 'production' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'invoice-app' of 'deployment' 'invoice' in 'production' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0011 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.limits.cpu'
════════════════════════════════════════
Enforcing CPU limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv011
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0013 (MEDIUM): Container 'init-ds' of Deployment 'invoice' should specify an image tag
════════════════════════════════════════
It is best to avoid using the ':latest' image tag when deploying containers in production. Doing so makes it hard to track which version of the image is running, and hard to roll back the version.

See https://avd.aquasec.com/misconfig/ksv013
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0015 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.requests.cpu'
════════════════════════════════════════
When containers have resource requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv015
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0016 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.requests.memory'
════════════════════════════════════════
When containers have memory requests specified, the scheduler can make better decisions about which nodes to place pods on, and how to deal with resource contention.

See https://avd.aquasec.com/misconfig/ksv016
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0018 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'resources.limits.memory'
════════════════════════════════════════
Enforcing memory limits prevents DoS via resource exhaustion.

See https://avd.aquasec.com/misconfig/ksv018
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'init-ds' of Deployment 'invoice' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'invoice-app' of Deployment 'invoice' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invoice_deployment_v2.yaml:9-101
────────────────────────────────────────
   9 ┌   replicas: 2
  10 │   selector:
  11 │     matchLabels:
  12 │       app: invoice
  13 │       version: "v2"
  14 │   template:
  15 │     metadata:
  16 │       labels:
  17 └         app: invoice
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "init-ds" of deployment "invoice" in "production" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "invoice-app" of deployment "invoice" in "production" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invoice in production namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_deployment_v2.yaml:35-40
────────────────────────────────────────
  35 ┌         - name: init-ds
  36 │           image: busybox:latest
  37 │           command:
  38 │             - "/bin/sh"
  39 │             - "-c"
  40 └             - |
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invoice in production namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment invoice in production namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_deployment_v2.yaml:21-101
────────────────────────────────────────
  21 ┌       affinity:
  22 │         podAntiAffinity:
  23 │           preferredDuringSchedulingIgnoredDuringExecution:
  24 │             - podAffinityTerm:
  25 │                 labelSelector:
  26 │                   matchExpressions:
  27 │                     - key: app
  28 │                       operator: In
  29 └                       values:
  ..   
────────────────────────────────────────


AVD-KSV-0125 (MEDIUM): Container invoice-app in deployment invoice (namespace: production) uses an image from an untrusted registry.
════════════════════════════════════════
Ensure that all containers use images only from trusted registry domains.

See https://avd.aquasec.com/misconfig/ksv0125
────────────────────────────────────────
 invoice_deployment_v2.yaml:53-101
────────────────────────────────────────
  53 ┌         - name: invoice-app
  54 │           image: kamathadityaa/invoice-istio:v2
  55 │           env:
  56 │             - name: JHIPSTER_SPRING_PROFILES_ACTIVE
  57 │               value: prod
  58 │             - name: SECURITY_AUTHENTICATION_JWT_BASE64_SECRET
  59 │               valueFrom:
  60 │                 secretKeyRef:
  61 └                   name: jwt-secret
  ..   
────────────────────────────────────────



invoice_networkpolicy.yaml (kubernetes)
=======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invoice_networkpolicy.yaml:7-16
────────────────────────────────────────
   7 ┌   podSelector:
   8 │     matchLabels:
   9 │       app: invoice  
  10 │   policyTypes:
  11 │     - Ingress
  12 │   ingress:
  13 │     - from:
  14 │       - podSelector:
  15 │           matchLabels:
  16 └             app: store  
────────────────────────────────────────



invoice_postgresql_1.yaml (kubernetes)
======================================
Tests: 116 (SUCCESSES: 103, FAILURES: 13)
Failures: 13 (UNKNOWN: 0, LOW: 7, MEDIUM: 3, HIGH: 3, CRITICAL: 0)

AVD-KSV-0001 (MEDIUM): Container 'postgres' of Deployment 'invoice-postgresql' should set 'securityContext.allowPrivilegeEscalation' to false
════════════════════════════════════════
A program inside the container can elevate its own privileges and run as root, which might give the program control over the container and node.

See https://avd.aquasec.com/misconfig/ksv001
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0003 (LOW): Container 'postgres' of Deployment 'invoice-postgresql' should add 'ALL' to 'securityContext.capabilities.drop'
════════════════════════════════════════
The container should drop all default capabilities and add only those that are needed for its execution.

See https://avd.aquasec.com/misconfig/ksv003
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0004 (LOW): Container 'postgres' of 'deployment' 'invoice-postgresql' in 'production' namespace should set securityContext.capabilities.drop
════════════════════════════════════════
Security best practices require containers to run with minimal required capabilities.

See https://avd.aquasec.com/misconfig/ksv004
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0012 (MEDIUM): Container 'postgres' of Deployment 'invoice-postgresql' should set 'securityContext.runAsNonRoot' to true
════════════════════════════════════════
Force the running image to run as a non-root user to ensure least privileges.

See https://avd.aquasec.com/misconfig/ksv012
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0014 (HIGH): Container 'postgres' of Deployment 'invoice-postgresql' should set 'securityContext.readOnlyRootFilesystem' to true
════════════════════════════════════════
An immutable root file system prevents applications from writing to their local disk. This can limit intrusions, as attackers will not be able to tamper with the file system or write foreign executables to disk.

See https://avd.aquasec.com/misconfig/ksv014
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0020 (LOW): Container 'postgres' of Deployment 'invoice-postgresql' should set 'securityContext.runAsUser' > 10000
════════════════════════════════════════
Force the container to run with user ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv020
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0021 (LOW): Container 'postgres' of Deployment 'invoice-postgresql' should set 'securityContext.runAsGroup' > 10000
════════════════════════════════════════
Force the container to run with group ID > 10000 to avoid conflicts with the host’s user table.

See https://avd.aquasec.com/misconfig/ksv021
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0030 (LOW): Either Pod or Container should set 'securityContext.seccompProfile.type' to 'RuntimeDefault'
════════════════════════════════════════
According to pod security standard 'Seccomp', the RuntimeDefault seccomp profile must be required, or allow specific additional profiles.

See https://avd.aquasec.com/misconfig/ksv030
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invoice_postgresql_1.yaml:7-44
────────────────────────────────────────
   7 ┌   replicas: 1
   8 │   selector:
   9 │     matchLabels:
  10 │       app: invoice-postgresql
  11 │   template:
  12 │     metadata:
  13 │       labels:
  14 │         app: invoice-postgresql
  15 └       annotations:
  ..   
────────────────────────────────────────


AVD-KSV-0104 (MEDIUM): container "postgres" of deployment "invoice-postgresql" in "production" namespace should specify a seccomp profile
════════════════════════════════════════
A program inside the container can bypass Seccomp protection policies.

See https://avd.aquasec.com/misconfig/ksv104
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0106 (LOW): container should drop all
════════════════════════════════════════
Containers must drop ALL capabilities, and are only permitted to add back the NET_BIND_SERVICE capability.

See https://avd.aquasec.com/misconfig/ksv106
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): container invoice-postgresql in production namespace is using the default security context
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_postgresql_1.yaml:22-44
────────────────────────────────────────
  22 ┌       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 │           value: invoice
  27 │         - name: POSTGRES_PASSWORD
  28 │           valueFrom:
  29 │             secretKeyRef:
  30 └               name: invoice-postgresql
  ..   
────────────────────────────────────────


AVD-KSV-0118 (HIGH): deployment invoice-postgresql in production namespace is using the default security context, which allows root privileges
════════════════════════════════════════
Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access.

See https://avd.aquasec.com/misconfig/ksv118
────────────────────────────────────────
 invoice_postgresql_1.yaml:18-44
────────────────────────────────────────
  18 ┌       volumes:
  19 │       - name: data
  20 │         emptyDir: {}
  21 │       containers:
  22 │       - name: postgres
  23 │         image: postgres:14.2
  24 │         env:
  25 │         - name: POSTGRES_USER
  26 └           value: invoice
  ..   
────────────────────────────────────────



invoice_postgresql_2.yaml (kubernetes)
======================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invoice_postgresql_2.yaml:7-10
────────────────────────────────────────
   7 ┌   selector:
   8 │     app: invoice-postgresql
   9 │   ports:
  10 └   - port: 5432
────────────────────────────────────────



invoice_service.yaml (kubernetes)
=================================
Tests: 115 (SUCCESSES: 114, FAILURES: 1)
Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

AVD-KSV-0040 (LOW): A resource quota policy with hard memory and CPU limits should be configured per namespace
════════════════════════════════════════
Ensure that a ResourceQuota policy is configured to limit aggregate resource usage within a namespace

See https://avd.aquasec.com/misconfig/ksv040
────────────────────────────────────────
 invoice_service.yaml:11-16
────────────────────────────────────────
  11 ┌   selector:
  12 │     app: invoice
  13 │   ports:
  14 │     - name: http
  15 │       port: 80
  16 └       targetPort: 8082
────────────────────────────────────────


